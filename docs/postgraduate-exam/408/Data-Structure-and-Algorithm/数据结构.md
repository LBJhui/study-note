# 数据结构

## 第 1 章 绪论

```mermaid
graph LR

A[第1章 绪论] --> AA["数据结构(三要素)"]
AA --> AAA[逻辑结构]
AAA --> AAAA["线性结构：线性表、栈、队列"]
AAA --> AAAB["非线性结构：树、图、集合"]
AA --> AAB["存储结构（物理结构）"]
AA --> 数据的运算
A --> AB[五个特征]
AB --> 算法的定义
AB --> ABB[五个特性]
ABB --> ABBA["有穷性、确定性、可行性、输入、输出"]
AB --> ABC[效率的度量]
ABC --> 时间复杂度
ABC --> 空间复杂度
```

### 1.1 数据结构的基本概念

#### 1.1.1 基本概念和术语

**1. 数据**

数据（data）是信息的载体，是描述客观事物属性的数、字符及所有能输入到计算机中并被计算机程序识别和处理的符号的集合。数据是计算机程序加工的原料。

- 数值性数据
- 非数值性数据（多媒体信息处理）

**2. 数据元素**

数据元素（data element）是数据的基本单位，也称结点（node）或记录（record），通常作为一个整体进行考虑和处理。一个数据元素可由若干数据项（data item）组成，数据项是构成数据元素的不可分割的最小单位。例如，学生记录就是一个数据元素，它由学号、姓名、性别等数据项组成。

**3. 数据对象**

数据对象（Data Object）是具有相同性质的数据元素的集合，是数据的一个子集。

**4. 数据类型**

数据类型是一个值的集合和定义在此集合上的一组操作的总称

1）原子类型。其值不可再分的数据类型。

2）结构类型。其值可以再分解为若干成分（分量）的数据类型。

3）抽象数据类型。抽象数据组织及与之相关的操作。

**5. 数据结构**

数据结构（Data Structure）是相互之间存在一种或多种特定关系的数据元素的集合。在任何问题中，数据元素都不是孤立存在的，它们之间存在某种关系，这种数据元素相互之间的关系成为结构（Structure）。数据结构包括三方面的内容：逻辑结构、存储结构和数据的运算。

数据结构是带 “结构” 的数据元素的集合，“结构” 就是指数据元素之间存在的关系。

数据的逻辑结构和存储结构是密不可分的两个方面，一个算法的设计取决于所选定的逻辑结构，而算法的实现依赖于所采用的的存储结构。

#### 1.1.2 数据结构三要素

**1. 数据的逻辑结构**

逻辑结构是指数据元素之间的逻辑关系，即从逻辑关系上描述数据。它与数据的存储无关，是独立于计算机的，是从具体问题抽象出来的数学模型。数据的逻辑结构分为线性结构和非线性结构，线性表是典型的线性结构；集合、树和图是典型的非线性结构。数据的逻辑结构分类如图 1.1 所示。

```mermaid
graph TD
数据的逻辑结构 === A[线性结构]
A === 一般线性表
A === AB[受限线性表]
AB === 栈和队列
AB === 串
A === AC[线性表推广]
AC === 数组
数据的逻辑结构 === B[非线性结构]
B === 集合
B === BB[树形结构]
BB === 一般树
BB === 二叉树
B === BC[图形结构]
BC === 有向图
BC === 无向图
```

<center><font size=2>图1.1 数据的逻辑结构分类图</font></center>

集合。结构中的数据元素之间除“同属一个集合”外，别无其他关系。

线性结构。结构中的数据元素之间只存在一对一的关系。

树形结构。结构中的数据元素之间存在一对多的关系。

图状结构或网站结构。结构中的数据元素之间存在多对多的关系。

**2. 数据的存储结构**

存储结构是指数据结构在计算机中的表示（又称映像），也称物理结构。它包括数据元素的表示和关系的表示。数据的存储结构是用计算机语言实现的逻辑结构，它依赖于计算机语言。数据的存储结构主要有顺序存储、链式存储、索引存储和散列存储。

1）顺序存储。把逻辑上相邻的元素存储在物理位置上也相邻的存储单元中，元素之间的关系由存储单元的邻接关系来体现。其优点是可以实现**随机存取**，每个元素占用最少的存储空间；缺点是只能使用相邻的一整块存储单元，因此可能产生较多的外部碎片。

2）链式存储。不要求逻辑上相邻的元素在物理位置上也相邻，借助指示元素存储地址的指针来表示元素之间的逻辑关系。其优点是不会出现碎片现象，能充分利用所有存储单元；缺点是每个元素因存储指针而占用额外的存储空间，且只能实现顺序存取。

3）索引存储。在存储元素信息的同事，还建立附加的索引表。索引表中的每项称为索引项，索引项的一般形式是（关键字，地址）。其优点是检索速度快；缺点是附加的索引表额外占用存储空间。另外，增加和删除数据时也要修改索引表，因而会花费较多的时间。

4）散列存储。根据元素的关键字直接计算出该元素的存储地址，又称哈希（Hash）存储。其优点是检索、增加和删除结点的操作都很快；缺点是若散列函数不好，则可能出现元素存储单元的冲突，而解决冲突会增加时间和空间的开销。

**3. 数据的运算**

施加在数据上的运算包括运算的定义和实现。运算的定义是针对逻辑结构的，指出运算的功能；运算的实现是针对存储结构的，指出运算的具体操作步骤。

### 1.2 算法和算法评价

#### 1.2.1 算法的基本概念

算法（Algorithm）是对特定问题求解步骤的一种描述，它是指令的有限序列，其中的每条指令表示一个或多个操作。此外，一个算法还具有 5 个重要特性：

1）有穷性。一个算法必须总在执行有穷步之后结束，且每一步都可在有穷时间内完成。

2）确定性。算法中每条指令必须有确切的定义，对于相同的输入，只能得出相同的输出。

3）可行性。算法中描述的操作都可以通过已经实现的基本运算执行有限次来实现。

4）输入。一个算法中有零个或多个输入，这些输入取自于某个特定的对象的集合。

5）输出。一个算法有一个或多个输出，这些输出是与输入有着某种特定关系的量。

通常，设计一个 “好” 的算法应考虑达到以下目标：

1）正确性。算法应能够正确地解决求解问题。

2）可读性。算法应具有良好的可读性，以帮助人们理解。

3）健壮性。输入非法数据时，算法能够适当地做出反应或进行处理，而不会产生莫名其妙的输出结果。

4）高效率与低存储量需求。效率是指算法执行的时间，存储量需求是指算法执行过程中所需要的最大存储空间，这两者都与问题的规模有关。

#### 1.2.2 算法效率的度量

算法效率的度量是通过时间复杂度和空间复杂度来描述的。

**1. 时间复杂度**

一个语句的频度是指该语句在算法中被重复执行的次数。算法中所有语句的频度之和记为 $T(n)$，它是该算法问题规模 $n$ 的函数，时间复杂度主要分析 $T(n)$ 的数量级。算法中基本运算（最深层循环内的语句）的频度与 $T(n)$ 的数量级，因此通常采用算法中基本运算的频度 $f(n)$ 来分析算法的时间复杂度。因此，算法的时间复杂度记为

$$
T(n)=O(f(n))
$$

式中，$O$ 的含义是 $T(n)$ 的数量级，其严格的数学定义是：若 $T(n)$ 和 $f(n)$ 是定义在正整数集合上的两个函数，则存在正常数 $C$ 和 $n_0$，使得当 $n \geq n_0$ 时，都满足 $0 \leq T(n) \leq Cf(n)$。

算法的时间复杂度不仅依赖于问题的规模 $n$，也取决于待输入数据的性质（如输入数据元素的初始状态）。

最坏时间复杂度是指在最坏情况下，算法的时间复杂度。

平均时间复杂度是指所有可能输入实例在等概率出现的情况下，算法的期望运行时间。

最好时间复杂度是指在最好情况下，算法的时间复杂度。

一般总是考虑在最坏情况下的时间复杂度，以保证算法的运行时间不会比它更长。

在分析一个程序的时间复杂性时，有以下两条规则：

a）加法规则

$$
T(n) = T_1(n) + T_2(n) = O(f(n)) + O(g(n)) = O(max(f(n), g(n)))
$$

b）乘法规则

$$
T(n) = T_1(n) × T_2(n) = O(f(n)) × O(g(n)) = O(f(n)×g(n))
$$

常见的渐近时间复杂度为

$$
O(1) < O(log_2n) < O(n) < O(n \log _2n) < O(n^2) < O(n^3) < O(2^n) < O(n!) < O(n^n)
$$

**2. 空间复杂度**

算法的空间复杂度 $S(n)$ 定义为该算法所消耗的存储空间，它是问题规模 $n$ 的函数。记为

$$
S(n) = O(g(n))
$$

一个程序在执行时除需要存储空间来存放本身所用的指令、常数、变量和输入数据外，还需要一些对数据进行操作的工作单元和存储一些为实现计算所需信息的辅助空间。若输入数据所占空间只取决于问题本身，和算法无关，则只需分析除输入和程序之外的额外空间。

算法原地工作是指算法所需的辅助空间为常量，即$O(1)$。

## 第 2 章 线性表

```mermaid
graph LR
B["第2章 线性表"] --> BA[线性表]
BA --> BAA[顺序存储]
BAA --> 顺序表
BA --> BAB[链式存储]
BAB --> BABA[单链表]
BABA -.- 指针实现
BAB --> BABB[双链表]
BABB -.- 指针实现
BAB --> BABC[循环链表]
BABC -.- 指针实现
BAB --> BABD["静态链表（借助数组实现）"]
```

### 2.1 线性表的定义和基本操作

#### 2.1.1 线性表的定义

线性表是具有<u>相同</u>数据类型的 $n(n \geq 0)$ 个数据元素的<u>有限序列</u>，其中 $n$ 为表长，当 $n=0$ 时，线性表是一个空表。若用 $L$ 命名线性表，则其一般表示为

$$
L = (a_1, a_2,…,a_i, a_{i+1},…, a_n)
$$

式中，$a_1$是唯一的 “第一个” 数据元素，又称为表头元素；$a_n$ 是唯一的 “最后一个” 数据元素，又称为表尾元素。除第一个元素外，每个元素有且仅有一个直接前驱。除最后一个元素外，每个元素有且仅有一个直接后继（“直接前驱” 和 “前驱”、“直接后继” 和 “后继” 通常被视为同义词）。以上就是线性表的逻辑特性，这种线性有序的逻辑结构正是线性表名字的由来。

由此，我们得出线性表的特点如下。

- 表中元素的个数有限。
- 表中元素具有逻辑上的顺序性，表中元素有其先后次序。
- 表中元素都是数据元素，每个元素都是单个元素。
- 表中元素的数据类型都相同，这意味着每个元素占有相同大小的存储空间。
- 表中元素具有抽象性，即仅讨论元素间的逻辑关系，而不考虑究竟表示什么内容。

**注意**：线性表是一种逻辑结构，表示元素一对一的相邻关系。顺序表和链表是指存储结构，两者属于不同层面的概念，因此不要将其混淆。

#### 2.1.2 线性表的基本操作

一个数据结构的基本操作是指其最核心、最基本的操作。其他较复杂的操作可通过调用其基本操作来实现。线性表的主要操作如下：

`InitList(&L)`：初始化表。构造一个空的线性表。

`Length(L)`：求表长。返回线性表 $L$ 的长度，即 $L$ 中数据元素的个数。

`LocateElem(L, e)`：按值查找操作。在表 $L$ 中第 $i$ 个位置的元素的值。

`GetElem(L, i)`：按位查找操作。获取表 $L$ 中第 $i$ 个位置的元素的值。

`ListInsert(&L, i, e)`：插入操作。在表 $L$ 中第 $i$ 个位置上插入指定元素 $e$。

`ListDelete(&L, i, &e)`：删除操作。删除表 $L$ 中第 $i$ 个位置的元素，并用 $e$ 返回删除元素的值。

`PrintList(L)`：输出操作。按前后顺序输出线性表 $L$ 的所有元素值。

`Empty(L)`：判空操作。若 $L$ 为空表，则返回 true， 否则返回 false。

`DestroyList(&L)`：销毁操作。销毁线性表，并释放线性表 $L$ 所占用的内存空间。

**注意**：① 基本操作的实现取决于采用哪种存储结构，存储结构不同，算法的实现也不同。② “&” 表示 C++ 语言中的引用调用，在 C 语言中采用指针也可达到同样的效果。

### 2.2 线性表的顺序表示

#### 2.2.1 顺序表的定义

线性表的顺序存储又称顺序表。它是用一组地址连续的存储单元依次存储线性表中的数据元素，从而使得逻辑上相邻的两个元素在物理位置上也相邻。第 1 个元素存储在线性表的起始位置，第 $i$ 个元素的存储位置后面紧接着存储的是第 $i + 1$ 个元素，称 $i$ 为元素 $a_i$ 在线性表中的位序。因此，顺序表的特点是表中元素的<u>逻辑顺序与其物理顺序相同</u>。

假设线性 $L$ 存储的起始位置为 $LOC(A)$， $sizeof(ElemType)$ 是每个数据元素所占用存储空间的大小，则表 L 所对应的顺序存储如图 2.1 所示。

|  数组下标   | 顺序表 |                 内存地址                  |
| :---------: | :----: | :---------------------------------------: |
|      0      |  a~1~  |                  LOC(A)                   |
|      1      |  a~2~  |         LOC(A) + sizeof(ElemType)         |
|             |   …    |                                           |
|    i - 1    |  a~i~  |    LOC(A) + (i - 1) × sizeof(ElemType)    |
|             |   …    |                                           |
|    n - 1    |  a~n~  |    LOC(A) + (n - 1) × sizeof(ElemType)    |
|             |   …    |                                           |
| MaxSize - 1 |   …    | LOC(A) + (MaxSize - 1) × sizeof(ElemType) |

<center><font size=2>图2.1 线性表的顺序存储结构</font></center>

每个数据元素的存储位置都和线性表的起始位置相差一个和该数据元素的位序成正比的常数，因此，顺序表中的任一数据元素都可以随机存取，所以线性表的顺序存储结构是一种随机存取的存储结构。通常用高级程序设计语言中的数组来描述线性表的顺序存储结构。

**注意**：线性表中元素的位序是从 1 开始的，而数组中元素的下标是从 0 开始的。

假设线性表的元素类型为 ElemType，则线性表的顺序存储类型描述为

```c++
#define MaxSize 50					  //定义线性表的最大长度
typedef struct{
  ElemType data[MaxSize];			//顺序表的元素
  int length;								 //顺序表的当前长度
}SqList;										 //顺序表的类型定义
```

一维数组可以是静态分配的，也可以是动态分配的。在静态分配时，由于数组的大小和空间事先已经固定，一旦空间占满，再加入新的数据就会产生溢出，进而导致程序崩溃。

而在动态分配时，存储数组的空间是在 程序执行过程中通过动态存储分配语句分配的，一旦数组空间的目的，而不需要为线性表一次性地划分所有空间。

```c++
#define InitSize 100			//表长度的初始定义
typedef struct{
  ElemType *data;					//指示动态分配数据的指针
  int MaxSize, length;		//数组的最大容量和当前个数
}SeqList;								 //动态分配数组顺序表的类型定义
```

C 的初始动态分配语句为

`L.data=(ElemType*)malloc(sizeof(ElemType)*InitSize);`

C++的初始动态分配语句为

`L.data = new ElemType[InitSize];`

**注意**：动态分配并不是链式存储，它同样属于顺序存储结构，物理结构没有变化，依然是随机存取方式，只是分配的空间大小可以在运行时动态决定。

顺序表最主要的特点是随机访问，即通过首地址和元素序号可在时间 $O(1)$ 内找到指定的元素。

顺序表的存储密度高，每个结点只存储数据元素。

顺序表逻辑上相邻的元素物理上也相邻，所以插入和删除操作需要移动大量元素。

#### 2.2.2 顺序表上基本操作的实现

这里仅讨论顺序表的插入、删除和按值查找的算法，其他基本操作的算法都比较简单。

（1）插入操作

在顺序表 L 的第 $i（1 \leq i \leq L.length+1）$个位置插入新元素 $e$。若 $i$ 的输入不合法，则返回 false，表示插入失败；否则，将第 $i$ 个元素及其后的所有元素依次往后移动一个位置，腾出一个空位置插入新元素 $e$，顺序表长度增加 1，插入成功，返回 true。

```c++
bool ListInsert(SqList &L, int i, ElemType e){
  if(i < 1 || i > L.length+1)									//判断 i 的范围是否有效
    return false;
  if(L.length >= MaxSize)											//当前存储空间已满，不能插入
    return false;
  for(int j = L.length; j >= i; j--)					//将第 i 个元素及之后的元素后移
    L.data[j] = L.data[j-1];
  L.data[i-1] = e;														//在位置 i 处放入 e
  L.length++;																	//线性表长度加 1
  return true;
}
```

**注意**：区别顺序表的位序和数组下标。为何判断插入位置是否合法时 if 语句中用 length + 1，而移动元素的 for 语句中只用 length？

最好情况：在表尾插入（即 $i = n + 1$），元素后移语句将不执行，时间复杂度为$O(1)$。

最坏情况：在表头插入（即 $i = 1$），元素后移语句将执行 $n$ 次，时间复杂度为 $O(n)$。

平均情况：假设 $p_i(p_i = \frac{1}{n+1})$ 是在第 $i$ 个位置上插入一个结点的概率，则在长度为 $n$ 的线性表中插入一个结点时，所需移动结点的平均次数为

$$
\sum\limits_{i = 1}^{n+1}p_i(n-i+1) = \sum\limits_{i = 1}^{n+1}\frac{1}{n+1}(n-i+1) = \frac{1}{n+1}\sum\limits_{i = 1}^{n+1}(n-i+1) = \frac{1}{n+1}\frac{n(n+1)}{2} = \frac{n}{2}
$$

因此，线性表插入算法的平均时间复杂度为 $O(n)$

（2）删除操作

删除顺序表 $L$ 中第 $i（1 \leq i \leq L.length）$ 个位置的元素，引用变量 $e$ 返回。若 $i$ 的输入不合法，则返回 false；否则，将被删元素赋给引用变量 $e$，并将第 $i+1$ 个元素及其后的所有元素依次往前移动一个位置，返回 true。

```c++
bool ListDelete(SqList &L, int i, Elemtype &e){
  if(i < 1 || i > L.length)											//判断 i 的范围是否有效
    return false;
  e = L.data[i-1];															//将被删除的元素赋值给 e
  for(int j = i; j < L.length; j++)							//将第 i 个位置后的元素前移
    L.data[j-1] = L.data[j];
  L.length--;																		//线性表长度减1
  return true
}
```

最好情况：删除表尾元素（即 $i = n$），无须移动元素，时间复杂度为 $O(1)$。

最坏情况：删除表头元素（即 $i = 1$），需移动除表头元素外的所有元素，时间复杂度为 $O(n)$。

平均情况：假设 $p_i(p_i = \frac{1}{n})$ 是在第 $i$ 个位置上结点的概率，则在长度为 $n$ 的线性表中删除一个结点时，所需移动结点的平均次数为

$$
\sum\limits_{i = 1}^{n}p_i(n-i)=\sum\limits_{i = 1}^{n}\frac{1}{n}(n-i)=\frac{1}{n}\sum\limits_{i = 1}^{n}(n-i)=\frac{1}{n}\frac{n(n-1)}{2} = \frac{n-1}{2}
$$

因此，线性表删除算法的平均时间复杂度为 $O(n)$。

可见，顺序表中插入和删除操作的时间主要耗费在移动元素上，而移动元素的个数取决于插入和删除元素的位置。图 2.2 所示为一个顺序表在进行插入和删除操作前、后的状态，以及其数据元素在存储空间中的位置变化和表长变化。在图 2.2(a)中，将第 4 个至第 7 个元素从后往前依次后移一个位置，在图 2.2(b)中，将第 5 个至第 7 个元素从前往后依次前移一个位置。

![顺序表的插入和删除](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/00.png)

<center><font size=2>图2.2 顺序表的插入和删除</font></center>

（3）按值查找（顺序查找）

在顺序表 $L$ 中查找第一个元素值等于 $e$ 的元素，并返回其位序。

```c++
int LocateElem(SqList L, ElemType e){
  for(int i = 0; i< L.length; i++)
    if(L.data[i] == e)
      return i+1;										//下标为 i 的元素值等于 e，返回其位序 i+1
  return 0;													//退出循环，说明查找失败
}
```

最好情况：查找的元素就在表头，仅需比较一次，时间复杂度为 $O(1)$。

最坏情况：查找的元素在表尾（或不存在）时，需要比较 $n$ 次，时间复杂度为 $O(n)$。

平均情况：假设 $p_i(p_i = \frac{1}{n})$是查找的元素在第 $i（1 \leq i \leq L.length）$个位置上的概率，则在长度为 $n$ 的线性表中查找值为 $e$ 的元素所需比较的平均次数为

$$
\sum\limits_{i=1}^np_i × i = \sum\limits_{i=1}^n\frac1n × i = \frac1n\frac{n(n+1)}2 = \frac{n+1}2
$$

因此，线性表按值查找算法的平均时间复杂度为 $O(n)$。

### 2.3 线性表的链式表示

顺序表可以随时存取表中的任意一个元素，它的存储位置可以用一个简单直观的公式表示，但插入和删除操作需要移动大量元素。链式存储线性表时，不需要使用地址连续的存储单元，即不要求逻辑上相邻的元素在物理位置上也相邻，它通过 “链” 建立起数据元素之间的逻辑关系，因此插入和删除户操作不需要移动元素，而只需修改指针，但也会失去顺序表可随机存取的优点。

#### 2.3.1 单链表的定义

线性表的链式存储又称单链表，它是通过一组任意的存储单元来存储线性表中的数据元素。为了建立数据元素之间的线性关系，对每个链表结点，除存放元素自身的信息外，还需要存放一个指向其后继的指针。单链表结点结构如图 2.3 所示，其中 data 为数据域，存放数据元素；next 为指针域，存放其后继结点的地址。

<div style="display:flex;line-height:40px;width:200px;text-align:center;margin:0 auto;">
  <span style="border:1px solid #000;border-right:0px;flex:1;">data</span>
  <span style="border:1px solid #000;flex:1;">next</span>
</div>
<center><font size=2>图2.3 单链表结点结构</font></center>

单链表中结点类型的描述如下：

```c++
typeded struct LNode{			//定义单链表结点类型
  ElemType data;					//数据域
  struct LNode *next;			//指针域
}LNode, *LinkList;
```

利用单链表可以解决顺序表需要大量连续存储单元的缺点，但单链表附加指针域，也存在浪费存储空间的缺点。由于单链表的元素离散地分布在存储空间中，所以单链表是非随机存取的存储结构，即不能直接找到表中某个特定的结点。查找某个特定的结点时，需要从表头开始遍历，依次查找。

通常用头指针来标识一个单链表，如单链表 $L$，头指针为 NULL 时表示一个空表。此外，为了操作上的方便，在单链表第一个结点之前附加一个结点，称为头结点。头结点的数据域可以不设任何信息，也可以记录表长等信息。头结点的指针域指向线性表的第一个元素结点，如图 2.4 所示。

![带头结点的单链表](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/01.png)

<center><font size=2>图2.4 带头结点的单链表</font></center>

头结点和头指针的区分：不管带不带头结点，头指针都始终指向链表的第一个结点，而头结点是带头结点的第一个结点，结点内通常不存储信息。

引入头结点后，可以带来两个优点：

① 由于第一个数据结点的位置被存放在头结点的指针域中，因此在链表的第一个位置上的操作和在表的其他位置上的操作一致，无须进行特殊处理。

② 无论链表是否为空，其头指针都指向头结点的非空指针（空表中头结点的指针域为空），因此空表和非空表的处理也就得到了统一。

#### 2.3.2 单链表上基本操作的实现

**1. 采用头插法建立单链表**

该方法从一个空表开始，生成新结点，并将读取到的数据存放到新结点的数据域中，然后将新结点插入到当前链表的表头，即头结点之后，如图 2.5 所示。

![头插法建立单链表](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/02.png)

<center><font size=2>图2.5 头插法建立单链表</font></center>

头插法建立单链表的算法如下：

```c
LinkList List_HeadInsert(LinkList &L){	//逆向建立单链表
	LNode *s; int x;
	L = (LinkList)maclloc(sizeof(LNode));	//创建头结点
  L->next = NULL;												//初始为空链表
  scanf("%d", &x);											//输入结点的值
  while(x != 9999){											//输入9999表示结束
    s = (LNode*)malloc(sizeof(LNode));	//创建新结点
    s->data = x;
    s->next = L->next;
    L->next = s;												//将新结点插入表中，L为头指针
    scanf("%d", &x);
  }
  return L;
}

//malloc() 和free() 是 C 语言的两个标准函数，执行 s = (LNode*)malloc(sizeof(LNode))的作用是由系统生成一个LNode型的结点，同时该结点的起始位置赋给指针变量
```

采用头插法建立单链表时，读入数据的顺序与生成的链表中的顺序是相反的。每个结点插入的时间为 $O(1)$，设单链表长为 $n$，则总时间复杂度为 $O(n)$.

思考一下：若没有设立头结点，则上述代码需要在哪些地方修改？

<font size=2>主要修改处：因为在头部插入新结点，每次插入新结点后，需要将它的地址赋值给头指针 L。</font>

**2. 采用尾插法建立单链表**

头插法建立单链表的算法虽然简单，但生成的链表中结点的次序和输入数据的顺序不一致。若希望两者次序一致，则可采用尾插法。该方法将新结点插入到当前链表的表尾，为此必须增加一个尾指针 $r$，使其始终指向当前链表的尾结点，如图 2.6 所示。

![尾插法建立单链表](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/03.png)

<center><font size=2>图2.6 尾插法建立单链表</font></center>

尾插法建立单链表的算法如下：

```c
LinkList List_TailInsert(LinkList &L){		//正向建立单链表
  int x;																	//设元素类型为整型
  L = (LinkList)malloc(sizeof(LNode));
  LNode *s,*r = L;												//r为表尾指针
  scanf("%d", &x);												//输入结点的值
  while(x != 9999){												//输入9999表示结束
    s = (LNode *)malloc(sizeof(LNode));
    s->data = x;
    r->next = s;
    r = s;																//r指向新的表尾结点
    scanf("%d", &x);
  }
  r->next = NULL;													//尾结点指针置空
  return L;
}
```

因为附设了一个指向表尾结点的指针，故时间复杂度和头插法的相同。

**3. 按序号查找结点值**

在单链表中从第一个结点出发，顺指针 next 域逐个往下搜索，知道找到第 i 个结点为止，否则返回最后一个结点指针域 NULL。

按序号查找结点值的算法如下：

```c
LNode *GetElem(LinkList L, int i){
  if(i < 1)
  return NULL;										//若i无效，则返回NULL
  int j = 1;												//计数，初始为1
  LNode *p = L->next;								//头结点指针赋给p
  if(i == 0)
    return L;												//若i等于0，则返回NULL

  while(p ！= NULL && j<i){									//从第1个结点开始找，查找第i个结点
    p = p->next;
    j++;
  }
  return p;													//返回第i个结点的指针，若i大于表长，则返回NULL
}
```

按序号查找操作的时间复杂度为 $O(n)$。

**4. 按值查找表结点**

从单链表的第一个结点开始，由前往后依次比较表中各结点数据域的值，若某结点数据域的值等于给定值 e，则返回该结点的指针；若整个单链表中没有这样的结点，则返回 NULL。

按值查找表结点的算法如下：

```c
LNode *LocateElem(LinkList L, ElemType e){
  LNode *p = L->next;
  while(p != NULL && p->data !=e)						//从第1个结点开始查找data域为e的结点
    p = p->next;
  return p;																	//找到后返回该结点指针，否则返回NULL
}
```

按值查找操作的时间复杂度为 $O(n)$。

**5. 插入结点操作**

插入结点操作将值为 x 的新结点插入到单链表的第 i 个位置上。先检查插入位置的合法性，然后找到待插入位置的前驱结点，即第 i-1 个结点，再在其后插入新结点。

算法首先调用按序号查找算法 `GetElent(L, i-1)`，查找第 i-1 个结点。假设返回的第 i-1 个结点为 `*p`，然后令新结点 `*s` 的指针域指向 `*p` 的后继结点，再令结点 `*p` 的指针域指向新插入的结点 `*s`。其操作过程如图 2.7 所示。

![单链表的插入操作](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/04.png)

<center><font size=2>图2.7 单链表的插入操作</font></center>

实现插入结点的代码片段如下：

```c
①p = GetElem(L, i-1);			//查找插入位置的前驱结点
②s->next = p->next;				//图 2.7 中操作步骤1
③p->next = s;							//图 2.7 中操作步骤2
```

算法中，语法 ② 和 ③ 的顺序不能颠倒，否则，当先执行 `p->next = s` 后，指向其原后继的指针就不存在了，再执行 `s->next = p->next` 时，相当于执行了 `s->next = s`，显然是错误的。本算法主要的时间开销在于查找第 i-1 个元素，时间复杂度为 $O(n)$。若在给定的结点后面啊插入新结点，则时间复杂度仅为 $O(1)$。

**扩展：对某一结点进行前插操作**

前插操作是指在某结点的前面插入一个新结点，后插操作的定义刚好与之相反。在单链表插入算法中，通常都采用后插操作。

以上面的算法为为例，首先调用函数 `GetELem()` 找到第 i-1 个结点，即插入结点的前驱结点后，再对其执行后插操作。由此可知，对结点的前插操作均可转化为后插操作，前提是从单链表的头结点开始顺序查找到其前驱结点，时间复杂度为 $O(n)$。

此外，可采用另一种方式将其转化为后插操作来实现，设待插入结点为 `*s`，将 `*s` 插入到 `*p` 的前面。我们仍然将 `*s` 插入到 `*p` 的后面，然后将 `p -> data` 与 `s->data` 交换，这样既满足了逻辑关系，又能使得时间复杂度为 $O(1)$。算法的代码片段如下：

```c
//将*s结点插入到*p之前的主要代码片段
s->next = p->next;			//修改指针域，不能颠倒
p->next = s;
temp = p->data;					//交换数据域部分
p->data = s->data;
s->data = temp;
```

**6. 删除结点操作**

删除结点操作是将单链表的第 i 个节点删除。先检查删除位置的合法性，后查找表中第 i-1 个结点，即被删结点的前驱结点，再将其删除。其操作过程如图 2.8 所示。

![单链表结点的删除](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/05.png)

<center><font size=2>图2.8 单链表结点的删除</font></center>

假设结点 `*p` 为找到的被删结点的前驱结点，为实现这一操作后的逻辑关系的变化，仅需修改 `*p` 的指针域，即将 `*p` 的指针域 next 指向 `*q` 的下一结点。

实现删除结点的代码片段如下：

```c
p = GetElem(L, i-1);				//查找删除位置的前驱结点
q = p->next;								//令q指向被删除结点
p->next = q->next;					//将*q结点从链中“断开”
free(q);										//释放结点的存储空间
//执行free(q)的作用是由系统回收一个LNode型的结点，回收后的空间可供再次生成结点时间。
```

和插入算法一样，该算法的主要时间也耗费在查找操作上，时间复杂度为 $O(n)$。

**扩展：删除结点 `*p`**

要删除某个给定结点 `*p`，通常的做法是先从链表的头结点开始顺序找到其前驱结点，然后执行删除操作，算法的时间复杂度为 $O(n)$。

其实，删除结点 `*p` 的操作可用删除 `*p` 的后继结点操作来实现，实质就是将其后继结点的值赋予其自身，然后删除后继结点，也能使用时间复杂度为 $O(1)$。

实现上述操作的代码片段如下：

```c
q = p->next;								//令q指向*p的后继结点
p->data = p->next->data;		//和后继结点交换数据域
p->next = q->next;					//将*q结点从链中“断开”
free(q);										//释放后继结点的存储空间
```

**7. 求表长操作**

求表长操作就是计算单链表中数据结点（不含头结点）的个数，需要从第一个结点开始顺序依次访问表中的每个结点，为此需要设置一个计算器变量，每访问一个结点，计算器加 1，直到访问到空结点为止。算法的时间复杂度为 $O(n)$。

需要注意的是，因为单链表的长度是不包括头结点的，因此不带头结点的单链表在求表长操作上会略有不同。对不带头结点的单链表，当表为空时，要单独处理。

**注意**：单链表是整个链表的基础，读者一定要熟练掌握单链表的基本操作算法，在设计算法时，建议先通过图示的方法理清算法的思路，然后进行算法的编写。

#### 2.3.3 双链表

单链表结点中只有一个指向其后继的指针，使得单链表只能从头结点依次顺序地向后遍历。要访问某个结点的前驱结点（插入、删除操作时），只能从头开始遍历，访问后继结点的时间复杂度为 $O(1)$，访问前驱结点的时间复杂度为 $O(n)$。

为了克服单链表的上述缺点，引入了双链表，双链表结点中有两个指针 prior 和 next，分别指向其前驱结点和后继结点，如图 2.9 所示。

![双链表示意图](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/06.png)

<center><font size=2>图2.9 双链表示意图</font></center>

双链表中结点类型的描述如下：

```c
typedef struct DNode{							//定义双链表结点类型
  ElemType data;									//数据域
  struct DNode *prior, *next;			//前驱和后继指针
} DNode, *DLinkList;
```

双链表在单链表的结点中增加了一个指向其前驱的 prior 指针，因此双链表中的按值查找和按位查找的操作与单链表的相同。但双链表在插入和删除操作的实现上，与单链表有着较大的不同。这是因为“链”变化时也需要对 prior 指针做出修改，其关键是保证在修改的过程中不断链。此外，双链表可以很方便地找到其前驱结点，因此，插入、删除操作的时间复杂度仅为 $O(1)$。

**1. 双链表的插入操作**

在双链表中 p 所指的结点之后插入结点 `*s`，其指针的变化过程如图 2.10 所示。

![双链表插入结点过程](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/07.png)

<center><font size=2>图2.10 双链表插入结点过程</font></center>

插入操作的代码片段如下：

```c
①s->next = p->next;				//将结点*s插入到结点*p之后
②p->next->prior = s;
③s->prior = p;
④p->next = s;
```

上述代码的语句顺序不是唯一的，但也不是任意的，① 和 ② 两步必须在 ④ 步之前，否则`*p` 的后继结点的指针就会丢掉，导致插入失败。为了加深理解，读者可以在纸上画出示意图。若问题改成要求在结点 `*p` 之前插入结点 `*s`，请读者思考具体的操作步骤。

**2. 双链表的删除操作**

删除双链表中结点`*p` 的后继结点 `*q`，其指针的变化过程如图 2.11 所示。

![双链表删除结点过程](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/08.png)

<center><font size=2>图2.11 双链表删除结点过程</font></center>

删除操作的代码片段如下：

```c
p->next = q->next;					//图2.11中步骤①
q->next->prior = p;					//图2.11中步骤②
free(q);										//释放结点空间
```

若问题改成要求删除结点 `*q` 的前驱结点 `*p`，请读者思考具体操作步骤。

在建立双链表的操作中，也可采用如同单链表的头插法和尾插法，但在操作上需要注意指针的变化和单链表有所不同。

#### 2.3.4 循环链表

**1. 循环单链表**

循环单链表和单链表的区别在于，表中最后一个结点的指针不是 NULL，而改为指向头结点，从而整个链表形成一个环，如图 2.12 所示。

![循环单链表](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/09.png)

<center><font size=2>图2.12 循环单链表</font></center>

在循环单链表中，表尾结点 `*r` 的 next 域指向 L，故表中没有指针域为 NULL 的结点，因此，循环单链表的判空条件不是头结点的指针是否为空，而是它是否等于头指针。

循环单链表的插入、删除算法与单链表的几乎一样，所不同的是若操作是在表尾进行，则执行的操作不同，以让单链表继续保持循环的性质。当然，正是因为循环单链表是一个“环”，因此在任何一个位置上的插入和删除操作都是等价的，无需判断是否是表尾。

在单链表中只能从表头结点开始往后顺序遍历整个链表，而循环单链表可以从表中的任意一个结点开始遍历整个链表。有时对单链表常做的操作是在表头和表尾进行的，此时对循环单链表不设头指针而仅设尾指针，从而使得操作效率更高。其原因是，若设的是头指针，对表尾进行操作需要 $O(n)$ 的时间复杂度，而若设的是尾指针 r，`r->next` 即为头指针，对表头与表尾进行操作都只需要 $O(1)$ 的时间复杂度。

**2. 循环双链表**

由循环单链表的定义不能推出循环双链表。不同的是在循环双链表中，头结点的 prior 指针还要指向表尾结点，如图 2.13 所示。

![循环双链表](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/10.png)

<center><font size=2>图2.13 循环双链表</font></center>

在循环双链表 L 中，某结点 `*p` 为尾结点时，`p->next == L;` 当循环双链表为空表时，其头结点的 prior 域和 next 域都等于 L。

#### 2.3.5 静态链表

静态链表借助数组来描述线性表的链式存储结构，结点也有数据域 data 和指针域 next，与前面所讲的链表中指针不同的是，这里的指针是结点的相对地址（数组下标），又称游标。和顺序表一样，静态链表也要预先分配一块连续的内存空间。

静态链表和单链表的对应关系如图 2.14 所示。

![静态链表存储示意图](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/11.png)

<center><font size=2>图2.14 静态链表存储示意图</font></center>

静态链表结构类型的描述如下：

```c
#define MaxSize 50				//静态链表的最大长度
typedef struct{						//静态链表结构类型的定义
  ElemType data;					//存储数据元素
  int next;								//下一个元素的数组下标
}SLinkList[MaxSize];
```

静态链表以 `next == -1` 作为其结束的标志。静态链表的操作、删除操作与动态链表的相同，只需要修改指针，而不需要移动元素。总体来说，静态链表没有单链表使用起来方便，但在一些不支持指针的高级语言（如 Basic）中，这是一种非常巧妙的设计方法。

#### 2.3.6 顺序表和链表的比较

**1. 存取（读写）方式**

顺序表可以顺序存取，也可以随机存取，链表只能从表头顺序存取元素。例如在第 i 个位置上执行存或取的操作，顺序表仅需一次访问，而链表则需从表头开始依次访问 i 次。

**2. 逻辑结构与物理结构**

采用顺序存储时，逻辑上相邻的元素，对应的物理存储位置也相邻。而采用链式存储时，逻辑上相邻的元素，物理存储位置不一定相邻，对应的逻辑关系是通过指针链接来表示的。

**3. 查找、插入和删除操作**

对于按值查找，顺序表无序时，两者的时间复杂度均为 $O(n)$；顺序表有序时，可采用折半查找，此时的时间复杂度为 $O(\log_2n)$。

对于按序号查找，顺序表支持随机访问，时间复杂度仅为 $O(1)$，而链表的平均时间复杂度为 $O(n)$。顺序表插入、删除操作，平均需要移动半个表长的元素。链表的插入、删除操作，只需修改相关结点的指针域即可。由于链表的每个结点都带有指针域，故而存储密度不够大。

**4. 空间分配**

顺序存储在静态存储分配情形下，一旦存储空间装满就不能扩充，若再加入新元素，则会出现内存溢出，因此需要预先分配足够大的存储空间。预先分配过大，可能会导致顺序表后部大量闲置；预先分配过小，又会造成溢出。动态存储分配虽然存储空间可以补充，但需要移动大量元素，导致操作效率降低，而且若内存中没有更大块的连续存储空间，则会导致分配失败。链式存储的结点空间只在需要时申请分配，只要内存有空间就可以分配，操作灵活、高效。

在实际中应该怎样选取存储结构呢？

**1. 基于存储的考虑**

难以估计线性表的长度或存储规模时，不宜采用顺序表；链表不用事先估计存储规模，但链表的存储密度较低，显然链式存储结构的存储密度是小于 1 的。

**2. 基于运算考虑**

在顺序表中按序号访问 $a_i$ 的时间复杂度为 $O(1)$，而链表中按序号访问的时间复杂度为 $O(n)$，因此若经常做的运算是按序号访问数据元素，则显然顺序表优于链表。

在顺序表中进行插入、删除操作时，平均移动表中一半的元素，当数据元素的信息量较大且表较长时，这一点是不应忽视的；在链表中进行插入、删除操作时，显然也要找插入位置，但操作主要是比较操作，从这个角度考虑，显然后者优于前者。

**3. 基于环境的考虑**

顺序表容易实现，任何高级语言中都有数组类型；链表的操作是基于指针的，相对来讲，前者实现较为简单，这也是用户考虑的一个因素。

总之，两种存储结构各有长短，选择哪一种由实际问题的主要因素决定。通常较稳定的线性表选择顺序存储，而频繁进行插入、删除操作的线性表（即动态性较强）宜选择链式存储。

**注意**：只有熟练掌握顺序存储和链式存储，才能深刻理解它们各自的优缺点。

## 第 3 章 栈和队列

```mermaid
graph LR
C[线性表]
C --操作受限-->  CAA[ ]
CAA --> CAAA[栈]
CAAA --> 顺序栈
CAAA --> 链栈
CAAA --> 共享栈
CAA --> CAAB[队列]
CAAB --> 循环队列
CAAB --> 链式队列
CAAB --> 双端队列
C --推广-->  CAB[数组]
CAB --> CABA[一维数组]
CAB --> CABB["多维数组：压缩存储、稀疏矩阵"]
```

### 3.1 栈

#### 3.1.1 栈的基本概念

**1. 栈的定义**

栈（Stack）是只允许在一端进行插入或删除操作的线性表。首先栈是一种线性表，但限定这种线性表只能在某一端进行插入和删除操作，如图 3.1 所示。

![栈的示意图](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/12.png)

<center><font size=2>图3.1 栈的示意图</font></center>

栈顶（Top）。线性表允许进行插入删除的那一端。

栈底（Bottom）。固定的，不允许进行插入和删除的另一端。

空栈。不含任何元素的空表。

假设某个栈 $S = (a_1, a_2, a_3, a_4, a_5)$，如图 3.1 所示，则 $a_1$ 为栈底元素，$a_5$ 为栈顶元素。由于栈只能在栈顶进行插入和删除操作，进栈次序依次为 $a_1, a_2, a_3, a_4, a_5$，而出栈次序为 $a_5, a_4, a_3, a_2, a_1$。由此可见，栈的操作特性可以明显地概括为后进先出（Last In First Out， LIFO）。

**注意**：我们每接触到一种新的数据结构类型，都应该分别从其逻辑结构、存储结构和对数据的运算三个方面着手，以加深对定义的理解。

栈的数学性质：n 个不同元素进栈，出栈元素不同排列的个数为 $\frac1{n+1}C^n_{2n}$。上述公式称为卡特兰（Catalan）数，可采用数学归纳法证明，有兴趣的读者可以参考组合数学教材。

**2. 栈的基本操作**

各种辅导书中给出的基本操作的名称不尽相同，但所表达的意思大致是一样的。这里我们以严蔚敏编写的教材为准给出栈的基本操作，希望读者能熟记下面的基本操作。

`InitStack(&S)`：初始化一个空栈 S。

`StackEmpty(S)`：判断一个栈是否为空，若栈 S 为空则返回 true，否则返回 false。

`Push(&S, x)`：进栈，若栈 S 未满，则将 x 加入使之成为新栈顶。

`Pop(&S, &x)`：出栈，若栈 S 非空，则弹出栈顶元素，并用 x 返回。

`GetTop(S, &x)`：读栈顶元素，若栈 S 非空，则用 x 返回栈顶元素。

`DestroyStack(&S)`：销毁栈，并释放栈 S 占用的存储空间（“&”表示引用调用）。

在解答算法题时，若题干未做出限制，则可直接使用这些基本的操作函数。

#### 3.1.2 栈的顺序存储结构

栈是一种操作受限的线性表，类似于线性表，它也有对应的两种存储方式。

**1. 顺序栈的实现**

采用顺序存储的栈称为顺序栈，它利用一组地址的存储单元存放自栈底到栈顶的数据元素，同时附设一个指针（top）指示当前栈顶元素的位置。

栈的顺序存储类型可描述为

```c
#define MaxSize 50						//定义栈中元素的最大个数
typedef struct{
  Elemtype data[MaxSize];			//存放栈中元素
  int top;										//栈顶指针
}SqStack;
```

栈顶指针：`S.top`，初始时设置 `S.top = -1`；栈顶元素：`S.data[S.top]`。

<font size="2">有的教辅可能初始时将`S.top`定义为 0，相当于规定 top 指向栈顶元素的下一个存储单元。</font>

进栈操作：栈不满时，栈顶指针先加 1，再送值到栈顶元素。

出栈操作：栈非空时，先取栈顶元素值，再将栈顶指针减 1。

栈空条件：`S.top == -1`；栈满条件：`S.top == MaxSize-1`；栈长：`S.top+1`。

由于顺序栈的入栈操作受数组上界的约束，当对栈的最大使用空间估计不足时，有可能发生栈上溢，此时应及时向用户报告信息，以便及时处理，避免出错。

**注意**：栈和队列的判空、判满条件，会因实际给的条件不同而变化，上面提到的方法以及下面的代码实现只是在栈顶指针设定的条件下的相应方法，而其他情况则需要具体问题具体分析。

**2. 顺序栈的基本运算**

栈操作的示意图如图 3.2 所示，图 3.2(a) 是空栈，图 3.2(c) 是 A、B、C、D、E 共 5 个元素依次入栈后的结果，图 3.2(d) 是在图 3.2(c) 之后 E、D、C 的相继出栈，此时栈中还有 2 个元素，或许最近出栈的元素 C、D、E 仍在原先的单元存储着，但 top 指针已经指向了新的栈顶，元素 C、D、E 已不在栈中，读者应通过该示意图深刻理解栈顶指针的作用。

![栈顶指针和栈中元素之间的关系](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/13.png)

<center><font size=2>图3.2 栈顶指针和栈中元素之间的关系</font></center>

下面是顺序栈上常用的基本运算的实现。

（1）初始化

```c
void InitStack(SqStack &S){
  S.top = -1;								//初始化栈顶指针
}
```

（2）栈判空

```c
bool StackEmpty(SqStack S){
  if(S.top == -1)
    return true;						//栈空
  else
    return false;						//不空
}
```

（3）进栈

```c
bool Push(SqStack &S, ElemType x){
  if(S.top == MaxSize - 1)				//栈满，报错
    return false;
  S.data[++S.top] = x;						//指针先加 1，再入栈
  return true;
}
```

当栈不满时，top 先加 1，再入栈。若初始时将 top 定义为 0，函数 3 和 4 应如何改写？

（4）出栈

```c
bool Pop(SqStack &S, ElemType &x){
  if(S.top == -1)										//栈空，报错
    return false;
  x = S.data[S.top--];							//先出栈，指针再减 1
  return true;
}
```

（5）读栈顶元素

```c
bool GetTop(SqStack S, ElemType &x){
  if(S.top == -1)											//栈空，报错
    return false;
  x = S.data[S.top];									//x 记录栈顶元素
  return true;
}
```

仅为读取栈顶元素，并没有出栈操作，因此原栈顶元素依然保留在栈中。

**注意**：这里 top 指向的是栈顶元素，所以进栈操作为 `S.data[++S.top] = x`，出栈操作为 `x = S.data[S.top--]`。若栈顶指针初始化为 `S.top = 0`，即 top 指向栈顶元素的下一个位置，则入栈操作也变为 `S.data[S.top++] = x`；出栈操作变为 `x= S.data[--S.top]`。相应的栈空、栈满条件也会发生变化。请读者仔细体会其中的不同之处，做题时要灵活应变。

**3. 共享栈**

利用栈底位置相对不变的特性，可让两个顺序栈共享一个一维数组空间，将两个栈的栈底分别设置在共享空间的两端，两个栈顶共享空间的中间延伸，如图 3.3 所示。

![两个顺序栈共享存储空间](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/14.png)

<center><font size=2>图3.3 两个顺序栈共享存储空间</font></center>

两个栈的栈顶指针都指向栈顶元素，`top0 = -1`时 0 号栈为空，`top1 = MaxSize` 时 1 号栈为空；仅当两个栈顶指针相邻（top1 - top0 = 1）时，判断为栈满。当 0 号栈进栈时 top0 先加 1 再赋值，1 号栈进栈时 top1 先减 1 再赋值；出栈时则刚好相反。

共享栈是为了更有效地利用存储空间，两个栈的空间相互调节，只有在整个存储空间被占满时才发生上溢。其存取数据的时间复杂度均为 $O(1)$，所以对存取效率没有什么影响。

#### 3.1.3 栈的链式存储结构

采用链式存储的栈称为链栈，链栈的优点是便于多个栈共享存储空间和提高其效率，且不存在栈满上溢的情况。通常采用单链表实现，并规定所有操作都是在单链表的表头进行的。这里规定链栈没有头结点，Lhead 指向栈顶元素，如图 3.4 所示。

![栈的链式存储](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/15.png)

<center><font size=2>图3.4 栈的链式存储</font></center>

栈的链式存储类型可描述为

```c
typedef struct Linknode{
  ElemType data;							//数据域
  struct Linknode *next;			//指针域
}*LiStack;										//栈类型定义
```

采用链式存储，便于结点的插入与删除。链栈的操作与链表类似，入栈和出栈的操作都在链表的表头进行。需要注意的是，对于带头结点和不带头结点的链栈，具体的实现会有所不同。

### 3.2 队列

#### 3.2.1 队列的基本概念

**1. 队列的定义**

队列（Queue）简称队，也是一种操作受限的线性表，只允许在表的一端进行插入，而在表的另一端进行删除。向队列中插入元素成为入队或进队；删除元素称为出队或离队。这和我们日常生活中的排队是一致的，最早排队的也是最早离队的，其操作的特性是先进先出（First In First Out， FIFO），如图 3.5 所示。

![队列示意图](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/16.png)

<center><font size=2>图3.5 队列示意图</font></center>

队头（Front）。允许删除的一端，又称队首。

队尾（Rear）。允许插入的一端。

空队列。不含任何元素的空表。

**2. 队列常见的基本操作**

`InitQueue(&Q)`：初始化队列，构造一个空队列 Q。

`QueueEmpty(Q)`：判队列空，若队列 Q 为空返回 true，否则返回 false。

`EnQueue(&Q, x)`：入队，若队列 Q 未满，将 x 加入， 使之成为新的队尾。

`DeQueue(&Q, &x)`：出队，若队列 Q 非空，删除队头元素，并且 x 返回。

`GetHead(Q, &x)`：读队头元素，若队列 Q 非空，则将队头元素赋值给 x。需要注意的是，栈和队列是操作受限的线性表，因此不是任何对线性表的操作都可以作为栈和队列的操作。比如，不可以随便读取栈或队列中间的某个元素。

#### 3.2.2 队列的顺序存储结构

**1. 队列的顺序存储**

队列的顺序实现是指分配一块连续的存储单元存放队列中的元素，并附设两个指针：队头指针 front 指向队头元素，队尾指针 rear 指向队尾元素的下一个位置（不同教材对 front 和 rear 的定义可能不同，例如，可以让 rear 指向队尾元素、front 指向队头元素。对于不同的定义，出队入队的操作是不同的）。

队列的顺序存储类型可描述为

```c
#define MaxSize 50
typedef struct{
  ElemType data[MaxSize];
  int front, rear;
}SqQueue;
```

初始状态（队空条件）：`Q.front == Q.rear == 0`。

进队操作：队不满时，先送值到队尾元素，再将队尾指针加 1。

出队操作：队不空时，先取队头元素值，再将队头指针加 1。

图 3.6(a) 所示为队列的初始状态，有 `Q.front == Q.rear == 0` 成立，该条件可以作为队列判空的条件。但能否用 `Q.rear == MaxSize` 作为队列满的条件呢？显然不能，图 3.6(d) 中，队列中仅有一个元素，但仍满足该条件。这时入队出现“上溢出”，但这种溢出并不是真正的溢出，在 data 数组中依然存在可以存放元素的空位置，所以是一种“假溢出”。

![队列的操作](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/17.png)

<center><font size=2>图3.6 队列的操作</font></center>

**2. 循环队列**

前面已指出了顺序队列的缺点，这里引出循环队列的概念。将顺序队列臆造为一个环状的空间，即把存储队列元素的表从逻辑上视为一个环，称为循环队列。当队首指针 `Q.front = MaxSize -1` 后，再前进一个位置就自动到 0，这可以利用除法取余元素（%）来实现。

初始时：`Q.front = Q.rear = 0`。

队首指针进 1：`Q.front = (Q.front + 1) % MaxSize`。

队尾指针进 1：`Q.rear = (Q.rear + 1) % MaxSize`。

队列长度：`(Q.rear + MaxSize - Q.front) % MaxSize`。

出队入队时：指针都按顺时针方向进 1（如图 3.7 所示）。

那么，循环队列队空和队满的判断条件是什么呢？显然，队空的条件是 `Q.front == Q.rear`。若入队元素的速度快于出队元素的速度，则队尾指针很快就会赶上队首指针，如图 3.7(d1) 所示，此时可以看出队满时也有 `Q.front == Q.rear`。循环队列出入队示意图如图 3.7 所示。

![循环队列出入队示意图](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/18.png)

<center><font size=2>图3.7 循环队列出入队示意图</font></center>

为了区分是队空还是队满的情况，有三种处理方式：

1）牺牲一个单元来区分队空和队满，入队时少用一个队列单元，这是一种较为普遍的做法，约定以“队头指针在队尾指针的下一位置作为队满的标志”，如图 3.7(d2) 所示。

队满条件：`(Q.rear + 1) % MaxSize == Q.front`。

队空条件仍：``Q.front == Q.rear`。

队列中元素的个数：`(Q.rear- Q.front + MaxSize) % MaxSize`。

2）类型中增设表示元素个数的数据成员。这样，队空的条件为 `Q.size == 0`；队满的条件为 `Q.size == MaxSize`。这两种情况都有 `Q.front == Q.rear`。

3）类型中增设 tag 数据成员，以区分是队满还是队空。tag 等于 0 时，若因删除导致 `Q.front == Q.rear`，则为队空；tag 等于 1 时，若因插入导致 `Q.front == Q.rear`，则为队满。

**3. 循环队列的操作**

（1）初始化

```c
void InitQueue(SqQueue &Q){
  Q.rear = Q.front = 0;				//初始化队首、队尾指针
}
```

（2）判队空

```c
bool isEmpty(SqQueue Q){
  if(Q.rear == Q.front) return true;		//队空条件
  else return false;
}
```

（3）入队

```c
bool EnQueue(SqQueue &Q, ElemType x){
  if((Q,rear + 1) % MaxSize == Q.front) return false;				//队满则报错
  Q.data[Q.rear] = x;
  Q.rear = (Q.rear + 1) % MaxSize;													//队尾指针加 1 取模
  return true;
}
```

（4）出队

```c
bool DeQueue(SqQueue &Q, ElemType &x){
  if(Q.rear == Q.front) return false;			//队空则报错
  x = Q.data[Q.front];
  Q.front = (Q.front + 1) % MaxSize;			//队头指针加 1 取模
  return true;
}
```

#### 3.2.3 队列的链式存储结构

**1. 队列的链式存储**

队列的链式表示成为链队列，它实际上是一个同时带有队头指针和队尾指针的单链表。头指针指向队头结点，队尾指针指向队尾结点，即单链表的最后一个结点（注意与顺序存储的不同）。队列的链式存储如图 3.8 所示。

![不带头结点的链式队列](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/19.png)

<center><font size=2>图3.8 不带头结点的链式队列</font></center>

队列的链式存储类型可描述为

```c
typedef struct{								//链式队列结点
  ElemType data;
  struct LinkNode *next;
}LinkNode;
typedef struct{								//链式队列
  LinkNode *front, *rear;			//队列的队头和队尾指针
}LinkQueue;
```

当 `Q.front == NULL` 且 `Q.rear == NULL` 时，链式队列为空。

出队时，首先判断队是否为空，若不空，则取出队头元素，将其从链表中摘除，并让 `Q.front` 指向下一个结点（若该结点为最后一个结点，则置 `Q.front` 和 `Q.rear` 都为 `NULL`）。入队时，建立一个新结点，将新结点插入到链表的尾部，并改让 `Q.rear` 指向这个新插入的结点（若原队列为空队，则令 `Q.front` 也指向该结点）。

不难看出，不带头结点的链式队列在操作上往往比较麻烦，因此通常将链式队列设计成一个带头结点的单链表，这样插入和删除操作就统一了，如图 3.9 所示。

![带头结点的链式队列](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/20.png)

<center><font size=2>图3.9 带头结点的链式队列</font></center>

用单链表表示的链式队列特别适合于数据元素变动比较大的情形，而且不存在队列满且产生溢出的问题。另外，假如程序中要使用多个队列，与多个栈的情形一样，最好使用链式队列，这样就不会出现存储分配不合理和“溢出”的问题。

**2. 链式队列的基本操作**

（1）初始化

```c
void InitQueue(LinkQueue &Q){
  Q.front = Q.rear = (LinkNode*)malloc(sizeof(LinkNode));		//建立头结点
  Q.front->next = NULL;																			//初始为空
}
```

（2）判队空

```c
bool IsEmpty(LinkQueue Q){
  if(Q.front == Q.rear) return true;
  else return false;
}
```

（3）入队

```c
void EnQueue(LinkQueue &Q, ElemType &x){
  LinkNode *s = (LinkNode*)malloc(sizeof(LinkNode));
  s->data = x; s->next = NULL;         //创建新结点，插入到链尾
  Q.rear->next = s;
  Q.rear = s;
}
```

（4）出队

```c
bool DeQueue(LinkQueue &Q, ELemType &x){
  if(Q.front == Q.rear) return false;				//空队
  LinkNode *p = Q.front->next;
  x=p->data;
  Q.front->next = p->next;
  if(Q.rear == p)
    Q.rear = Q.front;												//若原队列中只有一个结点，删除后变空
  free(p);
  return true;
}
```

#### 3.2.4 双端队列

双端队列是指允许两端都可以进行入队和出队操作的队列，如图 3.10 所示。其元素的逻辑结构仍是线性结构。将队列的两端分别称为前端和后端，两端都可以入队和出队。

![双端队列](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/21.png)

<center><font size=2>图3.10 双端队列</font></center>

在双端队列进队时，前端进的元素排队在队列中后端进的元素的前面，后端进的元素排列在队列中前端进的元素后面。在双端队列出队时，无论是前端还是后端出队，先出的元素排列在后出的元素的前面。<u>思考：如何由入队序列 a, b, c, d 得出出队序列 d, c, a, b ？</u>

输出受限的双端队列：允许在一端进行插入和删除，但在另一端允许插入的双端队列称为输出受限的双端队列，如图 3.11 所示。

![输出受限的双端队列](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/22.png)

<center><font size=2>图3.11 输出受限的双端队列</font></center>

输入受限的双端队列：允许在一端进行插入和删除，但在另一端只允许删除的双端队列称为输入受限的双端队列，如图 3.12 所示。若限定双端队列从某个端点插入的元素只能从该端点删除，则该双端队列就蜕变为两个栈底相邻接的栈。

![输入受限的双端队列](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/23.png)

<center><font size=2>图3.12 输入受限的双端队列</font></center>

**例** 设有一个双端队列，输入序列为 1, 2, 3, 4，试分别求出以下条件的输出序列。

（1）能由输入受限的双端队列得到，但不能由输出受限的双端队列得到的输出序列。

（2）能由输出受限的双端队列得到，但不能由输入受限的双端队列得到的输出序列。

（3）既不能由输入受限的双端队列得到，又不能由输出受限的双端队列得到的输出序列。

**解** 先看输入受限的双端队列，如图 3.13 所示。假设 end1 端输入 1, 2, 3, 4，则 end2 端的输出相当于队列的输出，即 1, 2, 3, 4；而 end1 端的输出相当于栈的输出， n=4 时仅通过 end1 端有 14 种输出序列（由 Catalan 公式得出），仅通过 end1 端不能得到的输出序列有 4! - 14 = 10 种：

1, 4, 2, 3 2, 4, 1, 3 3, 4, 1, 2 3, 1, 4, 2 3, 1, 2, 4

4, 3, 1, 2 4, 1, 3, 2 4, 2, 3, 1 4, 2, 1, 3 4, 1, 2, 3

![输入受限的双端队列](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/24.png)

<center><font size=2>图3.13 输入受限的双端队列</font></center>

通过 end1 和 end2 端混合输出，可以输出这 10 种中的 8 种，参看下表。其中，S~L~ ，X~L~ 分别代表 end1 端的进队和出队，X~R~ 代表 end2 端的出队。

|  输出序列  |           进队出队顺序           |  输出序列  |           进队出队顺序           |
| :--------: | :------------------------------: | :--------: | :------------------------------: |
| 1, 4, 2, 3 | S~L~X~R~S~L~S~L~S~L~X~L~X~R~X~R~ | 3, 1, 2, 4 | S~L~S~L~S~L~X~L~S~L~X~R~X~R~X~R~ |
| 2, 4, 1, 3 | S~L~S~L~X~L~S~L~S~L~X~L~X~R~X~R~ | 4, 1, 2, 3 | S~L~S~L~S~L~S~L~S~L~X~R~X~R~X~R~ |
| 3, 4, 1, 2 | S~L~S~L~S~L~X~L~S~L~X~L~X~R~X~R~ | 4, 1, 3, 2 | S~L~S~L~S~L~S~L~S~L~X~R~X~L~X~R~ |
| 3, 1, 4, 2 | S~L~S~L~S~L~X~L~X~R~S~L~X~L~X~R~ | 4, 3, 1, 2 | S~L~S~L~S~L~S~L~S~L~X~L~X~R~X~R~ |

剩下两种是不能通过输入受限的双端队列输出的，即 4, 2, 3, 1 和 4, 2, 1, 3。

再看输出受限的双端队列，如图 3.14 所示。假设 end1 端和 end2 端都能输入，仅 end2 端可以输出。若都从 end2 端输入，就是一个栈了。交替从 end1 和 end2 端输入，还可以输出其中 8 种。设 S~L~ 代表 end1 端的输入，S~R~ 、X~R~ 分别代表 end2 端的输入和输出，则可能的输出序列见下表。

![输入受限的双端队列](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/25.png)

<center><font size=2>图3.14 输出受限的双端队列</font></center>

|  输出序列  |           进队出队顺序           |  输出序列  |           进队出队顺序           |
| :--------: | :------------------------------: | :--------: | :------------------------------: |
| 1, 4, 2, 3 | S~L~X~R~S~L~S~L~S~R~X~R~X~R~X~R~ | 3, 1, 2, 4 | S~L~S~L~S~R~X~R~X~R~S~L~X~R~X~R~ |
| 2, 4, 1, 3 | S~L~S~R~X~R~S~L~S~R~X~R~X~R~X~R~ | 4, 1, 2, 3 | S~L~S~L~S~L~S~R~X~R~X~R~X~R~X~R~ |
| 3, 4, 1, 2 | S~L~S~L~S~R~X~R~S~R~X~R~X~R~X~R~ | 4, 2, 1, 2 | S~L~S~R~S~L~S~R~X~R~X~R~X~R~X~R~ |
| 3, 1, 4, 2 | S~L~S~L~S~R~X~R~X~R~S~R~X~R~X~R~ | 4, 3, 1, 2 | S~L~S~L~S~R~S~R~X~R~X~R~X~R~X~R~ |

通过输出受限的双端队列不能得到的两种输出序列是 4, 1, 3, 2 和 4, 2, 3, 1。

综上所述：

1）能由输入受限的双端队列得到，但不能由输出受限的双端队列得到的是 4, 1, 3, 2。

（2）能由输出受限的双端队列得到，但不能由输入受限的双端队列得到的是 4, 2, 1, 3。

（3）既不能由输入受限的双端队列得到，又不能由输出受限的双端队列得到的是 4, 2, 3, 1。

实际双端队列的考题不会这么复杂，通常仅判断序列是否满足题设条件，代入验证即可。

### 3.3 栈和队列的应用

要熟练掌握栈和队列，必须学习栈和队列的应用，把握其中的规律，然后举一反三。接下来将简单介绍栈和队列的一些常见应用。

#### 3.3.1 栈在括号匹配中的应用

假设表达式中允许包含两种括号：圆括号和方括号，其嵌套的顺序任意即 `([]())`或 `[([][])]` 等均为正确的格式，`[(])` 或 `([())` 或 `(()]` 均为不正确的格式。

考虑下列括号序列：

$$
\begin{align}
&[\quad&(\qquad&[\quad&]\qquad&[\quad&]\qquad&)\quad&] 						\\
&1\quad&2\qquad&3\quad&4\qquad&5\quad&6\qquad&7\quad&8
\end{align}
$$

分析如下：

1）计算机接收第 1 个括号 “[” 后，期待与之匹配的第 8 个括号 “]” 出现。

2）获得第 2 个括号 “(”，此时第 1 个括号 “[” 暂时放在一边，而急迫期待与之匹配的第 7 个括号 “)” 出现。

3）获得了第 3 个括号 “[”，此时第 2 个括号 “(” 暂时放在一边，而急迫期待与之匹配的第 4 个括号 “]” 出现。第 3 个括号的期待得到满足，消解之后，第 2 个括号的期待匹配又成为当前最急迫的任务。

4）以此类推，可见该处理过程与栈的思想吻合。

算法的思想如下：

1）初始设置一个空栈，顺序读入括号。

2）若是右括号，则或者使置于栈顶的最急迫期待得以消解，或者是不合法的情况（括号序列不匹配，退出程序）。

3）若是左括号，则作为一个新的更急迫的期待压入栈中，自然使原有的在栈中的所有未消解的期待的急迫性降了一级。算法结束时，栈为空，否则括号序列不匹配。

#### 3.3.2 栈在表达式求值中的应用

表达式求值是程序设计语言编译中一个最基本的问题，它的实现是栈应用的一个典型范例。中缀表达式不仅依赖运算符的优先级，而且还要处理括号。后缀表达式的运算符在操作数后面，在后缀表达式中已考虑了运算符的优先级，没有括号，只有操作数和运算符。中缀表达式 `A+B*(C-D)-E/F` 所对应的后缀表达式为 `ABCD-*+EF/-`。

读者也可将后缀表达式与运算式对应的表达式树（用来表示算术表达式的二元树，见图 3.15）的后序遍历进行比较，可以发现它们有异曲同工之妙。

```mermaid
graph TD
A(("-")) --- AA(("+"))
AA --- AAA((A))
AA --- AAB((*))
AAB --- AABA((B))
AAB --- AABB(("-"))
AABB --- AABBA((C))
AABB --- AABBB((D))
A(("-")) --- AB(("/"))
AB --- ABA(("E"))
AB --- ABB(("F"))
```

<center><font size=2>图3.15 A+B*(C-D)-E/F 对应的表达式</font></center>

通过后缀表示计算表达式值的过程为：顺序扫描表达式的每一项，然后根据它的类型做如下相应操作：若该项是操作数，则将其压入栈中；若该项是操作符<op>，则连续从栈中退出两个操作数 Y 和 X，形成运算指令 X<op>Y，并将计算结果重新压入栈中。当表达式的所有项都扫描并处理完后，栈顶存放的就是最后的计算结果。

例如，后缀表达式 `abcd-*+ef/-` 求值的过程需要 12 步，见表 3.1。

<center><font size=2>表3.1 后缀表达式 ABCD-*+EF/-求值的过程</font></center>

| 步  | 扫描项 | 项类型 | 动作                                                | 栈中内容  |
| :-: | :----: | :----: | :-------------------------------------------------- | :-------: |
|  1  |        |        | 置空栈                                              |    空     |
|  2  |   A    | 操作数 | 进栈                                                |     A     |
|  3  |   B    | 操作数 | 进栈                                                |    A B    |
|  4  |   C    | 操作数 | 进栈                                                |   A B C   |
|  5  |   D    | 操作数 | 进栈                                                |  A B C D  |
|  6  |   -    | 操作符 | D、C 退栈，计算 C-D，结果 R~1~ 进栈                 | A B R~1~  |
|  7  |   \*   | 操作符 | R~1~ 、B 退栈，计算 B×R~1~ ，结果 R~2~ 进栈         |  A R~2~   |
|  8  |   +    | 操作符 | R~2~ 、A 退栈，计算 A+R~2~ ，结果 R~3~ 进栈         |   R~3~    |
|  9  |   E    | 操作数 | 进栈                                                |  R~3~ E   |
| 10  |   F    | 操作数 | 进栈                                                | R~3~ E F  |
| 11  |   /    | 操作符 | F、E 退栈，计算 E/F，结果 R~4~ 进栈                 | R~3~ R~4~ |
| 12  |   -    | 操作符 | R~4~ 、R~3~ 退栈，计算 R~3~ - R~4~ ，结果 R~5~ 进栈 |   R~5~    |

#### 3.3.3 栈在递归中的应用

递归是一种重要的程序设计方法。简单地说，若在一个函数、过程或数据结构的定义中又应用了它自身，则这个函数、过程或数据结构称为是递归定义的，简称递归。

它通常把一个大型的复杂问题层层转化为一个与原问题相似的规模较小的问题来求解，递归策略只需少量的代码就可以描述出解题过程所需要的多次重复计算，大大减少了程序的代码量。但在通常情况下，它的效率并不是太高。

以斐波那契数列为例，其定义为

$$
Fib(n)=
\begin{cases}
Fib(n-1) + Fib(n-2),&n > 1\\
1, &n = 1\\
0, &n = 0
\end{cases}
$$

这就是递归的一个典型例子，用程序实现时如下

```c
int Fib(int n){												//斐波那契数列的实现
  if(n == 0)
    return 0;													//边界条件
  else if(n == 1)
    return 1;													//边界条件
  else
    return Fib(n-1) + Fib(n-2);				//递归表达式
}
```

必须注意递归模型不能是循环定义的，其必须满足下面的两个条件：

- 递归表达式（递归体）。
- 边界条件（递归出口）。

递归的精髓在于能否将原始问题转换为属性相同但规模较小的问题。

在递归调用的过程中，系统为每一层的返回点、局部变量、传入实参等开辟了递归工作栈来进行数据存储，递归次数过多容易造成栈溢出等。而其效率不高的原因是递归调用过程中包含很多重复的计算。下面以 $n=5$ 为例，列出递归调用执行过程，如图 3.16 所示。

```mermaid
graph TB
A["Fib(5)"]  --- AA["Fib(4)"]
AA --- AAA["Fib(3)"]
AAA --- AAAA["Fib(2)"]
AAAA --- AAAAA["Fib(1)"]
AAAA --- AAAAB["Fib(0)"]
AAA --- AAAB["Fib(1)"]
AA --- AAB["Fib(2)"]
AAB --- AABA["Fib(1)"]
AAB --- AABB["Fib(0)"]
A ---AB["Fib(3)"]
AB --- ABA["Fib(2)"]
ABA --- ABAA["Fib(1)"]
ABA --- ABAB["Fib(0)"]
AB --- ABB["Fib(1)"]
```

<center><font size=2>图3.16 Fib(5)的递归执行过程</font></center>

显然，在递归调用的过程中，Fib(3) 被计算了 2 次，Fib(2) 被计算了 3 次。Fib(1) 被调用了 5 次，Fib(0) 被调用了 3 次。所以，递归的效率低下，但优点是代码简单，容易理解。在第 4 章的树中利用了递归的思想，代码变得十分简单。通常情况下，初学者很难理解递归的调用过程，若读者想具体了解递归是如何实现的，可以参阅编译原理教材中的相关内容。

可以将递归算法转换为非递归算法，通常需要借助栈来实现这种转换。

#### 3.3.4 队列在层次遍历中的应用

在信息处理中有一大类问题需要逐层或逐行处理。这类问题的解决方法往往是在处理当前层或当前行时就对下一层或下一行做预处理，把处理顺序安排好，等到当前层或当前行处理完毕，就可以处理下一层或下一行。使用队列是为了保存下一步的处理顺序。下面用二叉树（见图 3.17）层次遍历的例子，说明队列的应用。表 3.2 显示了层次遍历二叉树的过程。

该过程的简单描述如下：

① 根结点入队。

② 若队空（所有结点都已处理完毕），则结束遍历；否则重复 ③ 操作。

③ 队列中第一个结点出队，并访问之。若其有左孩子，则将左孩子入队；若其有右孩子，则将右孩子入队，返回 ②。

```mermaid
graph TB
A((A)) --- B((B))
B --- D((D))
D --- G((G))
A --- C((C))
C --- E((E))
C --- F((F))
E --- H((H))
E --- I((I))
```

<center><font size=2>图3.17 二叉树</font></center>

<center><font size=2>表3.2 层序遍历二叉树的过程</font></center>

| 序  |    说明     | 队内 |   队外    |
| :-: | :---------: | :--: | :-------: |
|  1  |    A 入     |  A   |           |
|  2  | A 出，BC 入 |  BC  |  BCDEFA   |
|  3  | B 出，D 入  |  CD  |    AB     |
|  4  | C 出，EF 入 | DEF  |    ABC    |
|  5  | D 出，G 入  | EFG  |   ABCD    |
|  6  | E 出，HI 入 | FGHI |   ABCDE   |
|  7  |    F 出     | GHI  |  ABCDEF   |
|  8  |   GHI 出    |      | ABCDEFGHI |

#### 3.3.5 队列在计算机系统中的应用

队列在计算机系统中的应用非常广泛，以下仅从两个方面来简述队列在计算机系统中的作用：第一个方面是解决主机与外部设备之间速度不匹配的问题，第二个方面是解决由多用户引起的资源竞争问题。

对于第一个方面，仅以主机和打印机之间速度不匹配的问题为例做简要说明。主机输出数据给打印机打印，输出数据的速度比打印数据的速度要快得多，由于速度不匹配，若直接把输出的数据送给打印机打印显然是不行的。解决的方法是设置一个打印数据缓冲区，主机把要打印输出的数据依次写入这个缓冲区，写满后就暂停输出，转去做其他的事情。打印机就从缓冲区中按照先进先出的原则依次取出数据并打印，打印完后再向主机发出请求。主机接到请求后再向缓冲区写入打印数据。这样做既保证了打印数据的正确，又使主机提高了效率。由此可见，打印数据缓冲区中所存储的数据就是一个队列。

对于第二个方面，CPU（即中央处理器，它包括运算器和控制器）资源的竞争就是一个典型的例子。在一个带有多终端的计算机系统上，有多个用户需要 CPU 各自运行自己的程序，它们分别通过各自的终端向操作系统提出占用 CPU 的请求。操作系统通常按照每个请求在时间上的先后顺序，把它们排成一个队列，每次把 CPU 分配给队首请求的用户使用。当相应的程序运行结束或用完规定的时间间隔后，令其出队，再把 CPU 分给给新的队首请求的用户使用。这样既能满足每个用户的请求，又使 CPU 能够正常运行。

### 3.4 数组和特殊矩阵

矩阵在计算机图形学、工程计算中占有举足轻重的地位。在数据结构中考虑的是如何用最小的内存空间来存储同样的一组数据。所以，我们不研究矩阵及其运算等，而把精力放在如何将矩阵更有效地存储在内存中，并能方便地提取矩阵中的元素。

#### 3.4.1 数组的定义

数组是由 $n(n \geq 1)$ 个相同类型的数据元素构成的有限序列，每个元素称为一个数组元素，每个元素在 $n$ 个线性关系中的序号称为该元素的下标，下标的取值范围称为数组的维界。

数组与线性表的关系：数组是线性表的推广。一维数组可视为一个线性表；二维数组可视为其元素也是定长线性表的线性表以此类推。数组一旦被定义，其维数和维界就不再改变。因此，除结构的初始化和销毁外，数组只会有存取元素和修改元素的操作。

#### 3.4.2 数组的存储结构

大多数计算机语言都提供了数组数据类型，逻辑意义上的数组可采用计算机语言中的数组数据类型进行存储，一个数组的所有元素在内存中占用一段连续的存储空间。

以一维数组 A[0...n-1] 为例，其存储结构关系式为

$$
LOC(a_i) = LOC(a_0) + i \times L (0 \leq i \leq n)
$$

其中，L 是每个数组元素所占的存储单元。

对于多维数组，有两种映射方法：按行优先和按列优先。以二维数组为例，按行优先存储的基本思想是：先行后列，先存储行号较小的元素，行号相等先存储列号较小的元素。设二维数组的行下标与列下标的范围分别为 [0, h~1~] 与 [0, h~2~]，则存储关系结构关系式为

$$
LOC(a_{i,j}) = LOC(a_{0,0}) + [i \times (h_2 + 1) + j] \times L
$$

例如，对于数组 $A_{2 \times 3}$，它按行优先在内存中存储的形式如图 3.19 所示

$$
A_{2 \times 3} =
\left[
\begin{matrix}
a_{00} & a_{01} & a_{02}\\
a_{10} & a_{11} & a_{12}
\end{matrix}
\right]

\qquad

\underbrace{a_{00} \quad a_{01}\quad  a_{02}}_{第 1 行}\quad\underbrace{a_{10} \quad a_{11}\quad  a_{12}}_{第 2 行}
$$

<center><font size=2>图3.19 二维数组按行优先顺序存放</font></center>

当以列优先方式存储时，得出存储结构关系式为

$$
LOC(a_{i,j}) = LOC(a_{0,0}) + [j \times (h_1 + 1) + i] \times L
$$

例如，对于数组 $A_{2 \times 3}$，它按列优先在内存中存储的形式如图 3.20 所示。

$$
A_{2 \times 3} =
\left[
\begin{matrix}
a_{00} & a_{01} & a_{02}\\
a_{10} & a_{11} & a_{12}
\end{matrix}
\right]
\qquad
\underbrace{a_{00} \quad a_{10}}_{第 1 列}\quad\underbrace{a_{01} \quad a_{11}}_{第 2 列}\quad\underbrace{a_{02} \quad a_{12}}_{第 3 列}
$$

<center><font size=2>图3.19 二维数组按行优先顺序存放</font></center>

#### 3.4.3 特殊矩阵的压缩存储

压缩存储：指为多个值相同的元素只分配一个存储空间，对零元素不分配存储空间。其目的是节省存储空间。

特殊矩阵；指具有许多相同矩阵元素或零元素，并且这些相同矩阵元素或零元素的分布有一定规律性的矩阵。常见的特殊矩阵有对称矩阵、上（下）三角矩阵、对角矩阵等。

特殊矩阵的压缩存储方法：找出特殊矩阵中值相同的矩阵元素的分布规律，把那些呈现规律性分布的、值相同的多个矩阵元素压缩存储到一个存储空间中。

**1. 对称矩阵**

若对一个 n 阶方阵 $A[1...n][1...n]$ 中的任意一个元素 $a_{i,j}$ 都有 $a_{i,j} = a_{j,i}(1 \leq i,j \leq n)$，则称其为

对称矩阵。对于一个 n 阶方阵，其中的元素可以划分为 3 个部分，即上三角区、主对角线和下三角区，如图 3.21 所示。

![n阶方阵的划分](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/26.png)

<center><font size=2>图3.21 n阶方阵的划分</font></center>

对于 n 阶对称矩阵，上三角区的所有元素和下三角区的对应元素相同，若仍采用二维数组存放，则会浪费机会一半的空间，为此将对称矩阵 $A[1...n][1...n]$ 存放在一维数组 $B[n(n+1)/2]$ 中，即元素 $a_{i,j}$ 存放在 b~k~ 中。只存放下三角部分（含主对角）的元素。

在数组 B 中，位于元素 $a_{i,j}(i \geq j)$ 前面的元素个数为

- 第 1 行：1 个元素（a~1,1~）。
- 第 2 行： 2 个元素（a~2,1~ ，a~2,2~）。
- ……
- 第 i - 1 行：i - 1 个元素（a~i-1,1~，a~i-1,2~，…，a~i-1,i-1~）。
- 第 i 行：j - 1 个元素（a~i,1~， a~i,2~， …， a~i,j-1~）。

因此，元素 a~i,j~ 在数组 B 中的下标 $k = 1+2+\dots+(i-1)+j-1 = \frac{i(i-1)}2+j-1$ （数组下标从 0 开始）。因此，元素下标之间的对应关系如下：

$$
k=
\begin{cases}
\frac{i(i-1)}2+j-1,\quad &i \geq j(下三角区和主对角线元素) \\
\frac{j(j-1)}2+i-1,\quad &i < j(上三角元素 a_{ij} = a_{ji})
\end{cases}
$$

当数组下标从 1 开始时，可以采用同样的推导方法，请读者自行思考。

**2. 三角矩阵**

$$
&\left[
\begin{matrix}
a_{1,1} \\
a_{2,1} & a_{2,2} \\
\vdots & \vdots & \ddots \\
a_{n,1} & a_{n,2} & \cdots & a_{n,n}
\end{matrix}
\right]

\qquad

&\left[
\begin{matrix}
a_{1,1} & a_{1,2} &\cdots  & a_{1,n} \\
        & a_{2,2} &\cdots  & a_{2,n} \\
        &         &\ddots  &\vdots   \\
        &         &        & a_{n,n}
\end{matrix}
\right]
\\
&(a)下三角矩阵
&(b)上三角矩阵
$$

<center><font size=2>图3.22 三角矩阵</font></center>

下三角矩阵 [见图 3.22(a)] 中，上三角区所有元素均为同一常量。其存储思想与对称矩阵类似，不同之处在于存储完下三角区和主对角线上的元素之后，紧接着存储对角线上方的常量一次，故可以将下三角矩阵 $A[1...n][1...n]$ 压缩存储在 $B[n(n+1)/2+1]$ 中。

元素下标之间的对应关系为

$$
k =
\begin{cases}
\frac{i(i-1)}2+j-1,\quad &i\geq j(下三角区和主对角线元素) \\
\frac{n(n+1)}2, \quad & i < j(上三角区元素)
\end{cases}
$$

下三角矩阵在内存中的压缩存储形式如图 3.22 所示。

![下三角矩阵的压缩存储](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/27.png)

<center><font size=2>图3.23 下三角矩阵的压缩存储</font></center>

上三角矩阵 [见图 3.22(b)] 中，下三角区的所有元素均为同一常量。只需存储主对角线、上三角区上的元素和下三角区的常量一次，可将其压缩存储在 $B[n(n+1)/2+1]$ 中。

在数组 B 中，位于元素 $a_{i,j}(i \leq j)$ 前面的元素个数为

- 第 1 行：n 个元素
- 第 2 行： n - 1 个元素
- ……
- 第 i - 1 行：n - i + 2 个元素
- 第 i 行：j - i 个元素

因此，元素 a~i,j~ 在数组 B 中的下标 $k=n+(n-1)+\dots+(n-i+2)+(j-i+1)=\frac{(i-1)(2n-i+2)}2+(j-i)$。因此，元素下标之间的对应关系如下：

$$
k=
\begin{cases}
\frac{(i-1)(2n-i+2)}2+(j-i),\quad & i \leq j(上三角区和主对角线元素)  \\
\frac{n(n+1)}2, &i > j(下三角区元素)
\end{cases}
$$

上三角矩阵在内存中的压缩存储形式如图 3.24 所示。

![上三角矩阵的压缩存储](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/28.png)

<center><font size=2>图3.24 上三角矩阵的压缩存储</font></center>

以上推到均假设数组的下标从 0 开始，若题设有具体要求，则应该灵活应对。

**3. 三对角矩阵**

对角矩阵也称带状矩阵。对于 n 阶方阵 A 中的任一元素 a~i,j~ ，当 $\lvert i-j \rvert \gt 1$ 时，有 $a_{i,j}=0(1 \leq i,j \leq n)$，则称为三对角矩阵，如图 3.25 所示。在三对角矩阵中，所有非零元素都集中在以主对角线为中心的三条对角线的区域，其他区域的元素都为零。

$$
\left[
\begin{matrix}
a_{1,1} &a_{1,2}\\
a_{2,1} &a_{2,2} &a_{2,3} &          & 0      \\
        &a_{3,2} &a_{3,3} &a_{3,4}   	        \\
        &        &\ddots  &\ddots 	 &\ddots  \\
        &0       &        &a_{n-1,n-2} & &a_{n-1,n-1}  &a_{n-1,n}\\
& & & & &a_{n,n-1}   & a_{n,n}
\end{matrix}
\right]
$$

<center><font size=2>图3.25 三对角矩阵A</font></center>

三对角矩阵 A 也可以采用压缩存储，将 3 条对角线上的元素按行优先方式存放在一维数组 B 中，且 a~1,1~ 存放于 B[0] 中，其存储形式如图 3.26 所示。

![三对角矩阵的压缩存储](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/29.png)

<center><font size=2>图3.26 三对角矩阵的压缩存储</font></center>

由此可以计算矩阵 A 中 3 条对角线上的元素 $a_{i,j}(1 \leq i,j \leq n, \lvert i-j \rvert \leq 1)$ 在一维数组 B 中存放的下标为 $k=2i+j-3$。

反之，若已知三对角线矩阵中某元素 a~i,j~ 存放于一维数组 B 的第 k 个位置，则可得 $i = \lfloor(k+1)/3+1\rfloor,j=k-2i+3$。例如，当 k = 0 时，$i=\lfloor (0+1)/3+1 \rfloor=1,j=0-2 \times 1+3=1$，存放的是 a~1,1~ ;当 k = 2 时，$i=\lfloor (2+1)/3+1 \rfloor=2,j=2-2 \times 2+3=1$，存放的是 a~2,1~ ;当 k = 4 时，$i=\lfloor (4+1)/3+1 \rfloor=2,j=4-2 \times 2+3=3$，存放的是 a~2,3~ 。

#### 3.4.4 稀疏矩阵

矩阵中非零元素的个数 t，相对矩阵元素的个数 s 来说非常少，即 $s \gg t$ 的矩阵称为稀疏矩阵。例如，一个矩阵的阶为 100 × 100，该矩阵中只有少于 100 个非零元素。

若采用常规的方法存储稀疏矩阵，则相当浪费存储空间，因此仅存储非零元素。但通常零元素分布没有规律，所以仅存储非零元素的值是不够的，还要存储它所在的行和列。因此，将非零元素及其相应的行和列构成一个三元组（行标，列标，值），如图 3.27 所示。然后按照某种规律存储这些三元组。稀疏矩阵压缩存储后便失去了随机存取特性。

$$
M =
\left[
\begin{matrix}
4 &0 &0 &0 \\
0 &0 &6 &0 \\
0 &9 &0 &0 \\
0 &23 &0 &0
\end{matrix}
\right]
\quad 对应的三元组\quad


\left\{
\begin{matrix}
i	\quad	&j	\quad	&v \\
0	\quad	&0	\quad	&4 \\
1	\quad	&2	\quad &6 \\
2	\quad	&1	\quad	&9 \\
3	\quad	&1	\quad	&23\\
\end{matrix}
\right\}
$$

<center><font size=2>图3.27 稀疏矩阵及其对应的三元组</font></center>

稀疏矩阵的三元组既可以采用数组存储，也可以采用十字链表法存储。

## 第 4 章 串

```mermaid
graph LR
数据结构 --> D[第4章 串]
D --> DA["基本概念：主串、子串、串长"]
D --> DB[存储结构]
DB --> 定长顺序存储
DB --> 堆分配存储
DB --> 块链存储
D --> DC[模式匹配算法]
DC --> DCA[暴力匹配法]
DC --> DCB[KMP 算法]
DCB --> DBBA["部分匹配值表"]
DCB --> DBBB["next 数组"]
DCB --> DBBC["next 函数的推理过程"]
DC --> DCC["KMP算法的进一步改进——nextval数组"]
```

### 4.1 串的定义和实现

字符串简称串，计算机上非数值处理的对象基本都是字符串数据。我们常见的信息检索系统（如搜索引擎）、文本编辑程序（如 Word）、问答系统、自然语言翻译系统等，都是以字符串数据作为处理对象的。本章详细介绍字符串的存储结构及相应的操作。

#### 4.1.1 串的定义

串（string）是由零个或多个字符组成的有限序列。一般记为

$$
S = 'a_1a_2 \dots a_n'\quad (n \geq 0)
$$

其中，S 是串名，单引号括起来的字符序列是串的值；$a_i$ 可以是字母、数字或其他字符；串中字符的个数 n 称为串的长度。n = 0 时的串称为空串（用 $\emptyset$表示）。

串中任意多个连续的字符组成的子序列称为该串的子串，相应地，包含子串的串称为主串。某个字符在串中的序号称为该字符在串中的位置。子串在主串中的位置以子串的第一个字符在主串中的位置来表示。当两个串的长度相等且每个对应位置的字符都相等时，称这两个串是相等的。

例如，有串 `A='China Beijing'`，`B='Beijing'`，`C='China'`，则它们的长度分别为 13，7 和 5。B 和 C 是 A 的子串，B 在 A 中国的位置是 7，C 在 A 中的位置是 1。

需要注意的是，由一个或多个空格（空格是特殊字符）组成的串称为空格串（注意，空格串不是空串），其长度为串中空格字符的个数。

串的逻辑结构和线性表极为相似，区别仅在于串的数据对象仅限定为字符集。在基本操作上，串和线性表有很大差别。线性表的基本操作主要以单个元素作为操作对象，如查找、插入或删除某个元素等；而串的基本操作通常以子串作为操作对象，如查找、插入或删除一个子串等。

#### 4.1.2 串的存储结构

**1. 定长顺序存储表示**

类似于线性表的顺序存储结构，用一组地址连续的存储单元存储串值的字符序列。在串的定长顺序存储结构中，为每个串变量分配一个固定长度的存储区，即定长数组。

```c
#define MAXLEN 255				//预定义最大串长为255
typedef struct{
  char ch[MAXLEN];				//每个分量存储一个字符
  int length;							//串的实际长度
}SString;
```

串的实际长度只能小于等于 MAXLEN，超过预定义长度的串值会被舍去，称为截断。串长有两种表示方法：一是如上述定义描述的那样，用一个额外的变量 len 来存放串的长度；二是在串值后面加一个不计入串长的结束标记字符 “`\0`”，此时的串长为隐含值。

在一些串的操作（如插入、联接等）中，若串值序列的长度超过上界 MAXLEN，约定用 “截断” 法处理，要克服这种弊端，只能不限定串长的最大长度，即采用动态分配的方式。

**2. 堆分配存储表示**

堆分配存储表示仍然以一组地址连续的存储单元存放串值的字符序列，但它们的存储空间是程序执行过程中动态分配得到的。

```c
typedef struct{
  char *ch;							//按串长分配存储区，ch指向串的基地址
  int length;						//串的长度
}HString;
```

在 C 语言中，存在一个称之为 “堆” 的自由存储区，并用 `malloc()` 和 `free()` 函数来完成动态存储管理。利用 `malloc()` 为每个新产生的串分配一块实际串长所需的存储空间，若分配成功，则返回一个指向起始地址的指针，作为串的基地址，这个串由 ch 指针来指示；若分配失败，则返回 NULL。已分配的空间可用 `free()` 释放掉。

上述两种存储表示通常为高级程序设计语言所采用。块链存储表示仅做简单介绍。

**3. 块链存储表示**

类似于线性表的链式存储结构，也可采用链表方式存储串值。由于串的特殊性（每个元素只有一个字符），在具体实现时，每个结点既可以存放一个字符，也可以存放多个字符。每个结点称为块，整个链表称为块链结构。如图 4.1(a) 是结点大小为 4（即每个结点存放 4 个字符） 链表，最后一个结点占不满时通常用 “#” 补上；图 4.1(b) 是结点大小为 1 的链表。

![串值的链式存储方式](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/30.png)

<center><font size=2>图4.1 串值的链式存储方式</font></center>

#### 4.1.3 串的基本操作

- `StrAssign(&T, chars)`：赋值操作。把串 T 赋值为 chars。
- `StrCopy(&T, S)`：复制操作。由串 S 复制得到串 T。
- `StrEmpty(S)`：判空操作。若 S 为空串，则返回 TRUE，否则返回 FALSE。
- `StrCompare(S, T)`：比较操作。若 S > T，则返回值 >0；若 S=T，则返回值 =0；若 S<T，则返回值 <0。
- `StrLength(S)`：求串长。返回串 S 的元素个数。
- `SubString(&Sub, S, pos, len)`：求子串。用 Sub 返回串 S 的第 pos 个字符起长度为 len 的子串。
- `Concat(&T, S1, S2)`：串联接。用 T 返回由 S1 和 S2 联接而成的新串。
- `Index(S, T)`：定位操作。若主串 S 中存在与串 T 值相同的子串，则返回它在主串中第一次出现的位置；否则函数值为 0。
- `ClearString(&S)`：清空操作。将 S 清为空串。
- `DestroyString(&S)`：销毁串。将串 S 销毁。

不同的高级语言对串的基本操作集可以有不同的定义方法。在上述定义的操作中，串赋值 `StrAssign`、串比较 `StrCompare`、求串长 `StrLength`、串联接 `Concat` 及求子串 `SubString` 五种操作构成串类型的最小操作子集，即这些操作不可能利用其他串操作来实现；反之，其他串操作（除串清除 `ClearString` 和串销毁 `DestroyString` 外）均可在该最小操作子集上实现。

例如，可利用判等、求串长和求子串等操作实现的定位函数 `Index(S, T)`。算法思想为：在主串 S 中取从第一个字符起、长度和串 T 相等的子串，与串 T 比较，若相等则求得函数值为 i，否则 i 值增 1，直至串 S 中不存在和串 T 相等的子串为止。

```c
int Index(String S, String T){
  int i = 1, n = StrLength(S), m = StrLength(T);
  while(i <= n-m+1){
    SubString(sub, S, i, m);
    if(StrCompare(sub, T) != 0) ++i;
    else return i;																//返回子串在主串中的位置
  }
  return 0;																				//S中不存在与T相等的子串
}
```

### 4.2 串的模式匹配

#### 4.2.1 简单的模式匹配算法

子串的定位操作通常称为串的模式匹配，它求的是子串（常称模式串）在主串中的位置。这里采用定长顺序存储结构，给出一种不依赖于其他串操作的暴力匹配算法。

```c
int Index(SString S, SString T){
  int i = 1, j = 1;
  while(i <= S.length && j <= T.length){
    if(S.ch[i] == T.ch[j]){
      ++i; ++j;									//继续比较后续字符
    }
    else{
      i = i-j+2; j = 1;					//指针后退重新开始匹配
    }
  }
  if(j > T.length) return i - T.length;
  else return 0;
}
```

在上述算法中，分别用计数指针 i 和 j 指示主串 S 和模式串 T 中当前正待比较的字符位置。算法思想为：从主串 S 的第一个字符起，与模式 T 的第一个字符比较，若相等，则继续逐个比较后续字符；否则从主串的下一个字符起，重新和模式的字符比较；以此类推，直至模式 T 中的每个字符依次和主串 S 中的一个连续的字符序列相等，则称匹配成功，函数值为与模式 T 中第一个字符相等的字符在主串 S 中的序号，否则称匹配不成功，函数值为零。图 4.2 展示了模式 T='abcac' 和主串 S 的匹配过程，每次匹配失败后，都把模式 T 后移一位。

![简单模式匹配算法举例](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/31.png)

<center><font size=2>图4.2 简单模式匹配算法举例</font></center>

简单模式匹配算法的最坏时间复杂度为 $O(nm)$，其中 $n$ 和 $m$ 分别为主串和模式串的长度。

#### 4.2.2 改进的模式匹配算法——KMP 算法

图 4.2 的匹配过程，在第三趟匹配中，i=7、j=5 的字符比较不等，于是又从 i=4、j=1 重新开始比较。然而，仔细观察会发现，i=4 和 j=1，i=5 和 j=1 及 i=6 和 j=1 这三次比较都是不必进行的。从第三趟部分匹配的结果可知，主串中第 4、5 和 6 个字符是 'b'、'c' 和 'a'（即模式中第 2、3 和 4 个字符），因为模式中第一个字符是 'a'，因此它无须再和这 3 个字符进行比较，而仅需将模式向右滑动 3 个字符的位置，继续进行 i=7、j=2 时的比较即可。

在暴力匹配中，每趟匹配失败都是模式后移一位再从头开始比较。而某趟已匹配相等的字符序列是模式的某个前缀，这种频繁的重复比较相当于模式串在不断地进行自我比较，这就是其低效率的根源。因此，可以从分析模式本身的结构着手，如果已匹配相等的前缀序列中有某个后缀正好是模式的前缀，那么就可以将模式向后滑动到与这些相等字符对齐的位置，主串 i 指针无须回溯，并从该位置开始继续比较。而模式向后滑动位数的计算仅与模式本身的结构有关，与主串无关（这里理解起来会比较困难，没关系，带着这个问题继续往后看）。

**1. 字符串的前缀、后缀和部分匹配值**

要了解子串的结构，首先要弄清楚几个概念：前缀、后缀和部分匹配值。前缀指除最后一个字符以外，字符串的所有头部子串；后缀指除第一个字符外，字符串的所有尾部子串；部分匹配值则为字符串的前缀和后缀的最长相等前后缀长度。下面以 'ababa' 为例进行说明：

- 'a' 的前缀和后缀都为空集，最长相等前后缀长度为 0.
- 'ab' 的前缀为 {a}，后缀为 {b}，$\lbrace a \rbrace \cap \lbrace b \rbrace = \emptyset $，最长相等前后缀前度为 0.
- 'aba'的前缀为 {a, ab}，后缀为 {a, ba}，$\lbrace a,ab\rbrace \cap \lbrace a,ba\rbrace = \lbrace a\rbrace$，最长相等前后缀长度为 1。
- 'abab' 的前缀为 {a, ab, aba} $\cap$ 后缀 {b, ab, bab} = {ab}，最长相等前后缀长度为 2.
- 'ababa' 的前缀 {a, ab, aba, abab} $\cap$ 后缀 {b, ba, aba, baba} = {a, aba}，公共元素有两个，最长相等前后缀长度为 3。

故字符串 'ababa' 的部分匹配值为 00123。

这个部分匹配值有什么作用呢？

回到最初的问题，主串为 a b a b c a b c a c b a b，子串为 a b c a c。

利用上述方法容易写出子串 'abcac' 的部分匹配值为 00010，将部分匹配值写成数组形式，就得到了部分匹配值（Partial Match，PM）的表。

<table  style="text-align:center;">
  <tbody>
    <tr>
      <td style="font-weight:600;">编号</td>
      <td>1</td>
      <td>2</td>
      <td>3</td>
      <td>4</td>
      <td>5</td>
    </tr>
    <tr>
      <td style="font-weight:600;">S</td>
      <td>a</td>
      <td>b</td>
      <td>c</td>
      <td>a</td>
      <td>c</td>
    </tr>
    <tr>
      <td style="font-weight:600;">PM</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
  </tobdy>
</table>

下面用 PM 表进行字符串匹配：

$$
&主串 \qquad &a \quad &b \quad &a \quad &b \quad &c \quad &a \quad &b \quad &c \quad &a \quad &c \quad &b \quad &a \quad &b \\
&子串 \qquad &a \quad &b \quad &c \quad &
$$

第一趟匹配过程：

发现 c 与 a 不匹配，前面的 2 个字符 'ab' 是匹配的，查表可知，最后一个匹配字符 b 对应的部分匹配值为 0，因此按照下面的公式算出子串需要向后移动的位数：

$$
移动位数=已匹配的字符数-对应的部分匹配值
$$

因为 2 - 0 = 2，所以将子串向后移动 2 位，如下进行第二趟匹配：

$$
&主串 \qquad &a \quad &b \quad &a \quad &b \quad &c \quad &a \quad &b \quad &c \quad &a \quad &c \quad &b \quad &a \quad &b \\
&子串 \qquad & \quad & \quad  &a \quad &b \quad &c \quad &a \quad &c \quad & \quad & \quad & \quad
$$

第二趟匹配过程：

发现 c 与 b 不匹配，前面 4 个字符 'abca' 是匹配的，最后一个匹配字符 a 对应部分匹配值为 1, 4-1=3, 将子串向后移动 3 位，如下进行第三趟匹配：

$$
&主串 \qquad &a \quad &b \quad &a \quad &b \quad &c \quad &a \quad &b \quad &c \quad &a \quad &c \quad &b \quad &a \quad &b \\
&子串 \qquad & \quad & \quad & \quad & \quad & \quad  &a \quad &b \quad &c \quad &a \quad &c \quad
$$

第三趟匹配过程：

子串全部比较完成，匹配成功。整个匹配过程中，主串始终没有回退，故 KMP 算法可以在 $O(n+m)$ 的时间数量级上完成串的模式匹配操作，大大提高了匹配效率。

某趟发生失配时，如果对应的部分匹配值为 0，那么表示已匹配相等序列中没有相等的前后缀，此时移动的位数最大，直接将子串首字符后移到主串 i 位置进行下一趟比较；如果已匹配相等序列中存在最大相等前后缀（可理解为首尾重合）那么将子串向右滑动和该相等前后缀对齐（这部分字符下一趟显然不需要比较），然后从主串 i 位置进行下一趟比较。

**2. KMP 算法的原理是什么？**

我们刚刚学会了怎样计算字符串的部分匹配值、怎样利用子串的部分匹配值快速地进行字符匹配操作，但公式 “移动位数 = 已匹配的字符数 - 对应的部分匹配值” 的意义是什么呢？

如图 4.3 所示，当 c 与 b 不匹配时，已匹配 'abca' 的前缀 a 和后缀 a 为最长公共元素。已知前缀 a 与 b、c 均不同，与后缀 a 相同，故无须比较，直接将子串移动 “已匹配的字符数 - 对应的部分匹配值”，用子串前缀后面的元素与主串匹配失败的元素开始比较即可，如图 4.4 所示。

$$
&主串 \qquad &a \quad &b \quad &a \quad &b \quad &c \quad &a \quad &b \quad &c \quad &a \quad &c \quad &b \quad &a \quad &b \\
& \qquad & \quad &  \quad &a  \quad &b \quad &c \quad &a \quad &c  \quad \\
& \qquad &  \quad & \quad & \quad &a \quad &b \quad &c \quad &a \quad &c \quad \\
& \qquad &  \quad & \quad & \quad & \quad &a \quad &b \quad &c \quad &a \quad &c \quad \\
& \qquad &  \quad & \quad & \quad & \quad & \quad &a \quad &b \quad &c \quad &a \quad &c \quad
$$

<center><font size=2>图4.3 失配后移动情况</font></center>

$$
&主串 \qquad &a \quad &b \quad &a \quad &b \quad &c \quad &a \quad &b \quad &c \quad &a \quad &c \quad &b \quad &a \quad &b \\
& \qquad & \quad &  \quad &a  \quad &b \quad &c \quad &a \quad &c  \quad \\
& \qquad &  \quad & \quad & \quad & \quad & \quad &a \quad &b \quad &c \quad &a \quad &c \quad
$$

<center><font size=2>图4.4 直接移动到合适位置</font></center>

对算法的改进方法：

已知：右移位数 = 已匹配的字符数 - 对应的部分匹配值

写成：$Move=(j-1)-PM[j-1]$。

使用部分匹配值时，每当匹配失败，就去找它前一个元素的部分匹配值，这样使用起来有些不方便，所以将 PM 表右移一位，这样哪个元素匹配失败，直接看它自己的部分匹配值即可。

将上例中字符串 'abcac' 的 PM 表右移一位，就得到了 next 数组：

<table  style="text-align:center;">
  <tbody>
    <tr>
      <td style="font-weight:600;">编号</td><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td>
    </tr>
    <tr>
      <td style="font-weight:600;">S</td><td>a</td><td>b</td><td>c</td><td>a</td><td>c</td>
    </tr>
    <tr>
      <td style="font-weight:600;">next</td><td>-1</td><td>0</td><td>0</td><td>0</td><td>1</td>
    </tr>
  </tobdy>
</table>

我们注意到：

1）第一个元素右移以后空缺的用 -1 来填充，因为若是第一个元素匹配失败，则需要将子串向右移动一位，而不需要计算子串移动的位数。

2）最后一个元素在右移的过程中溢出，因为原来的子串中，最后一个元素的部分匹配值是其下一个元素使用的，但显然已没有下一个元素，故可以舍去。

这样，上式就改写为

$$
Move=(j-1)-next[j]
$$

相当于将子串的比较指针 j 回退到

$$
j=j-Move=j-((j-1)-next[j])=next[j]+1
$$

有时为了使公式更加简洁、计算简单，将 next 数组整体 +1.

因此，上述子串的 next 数组也可以写成

<table  style="text-align:center;">
  <tbody>
    <tr>
      <td style="font-weight:600;">编号</td><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td>
    </tr>
    <tr>
      <td style="font-weight:600;">S</td><td>a</td><td>b</td><td>c</td><td>a</td><td>c</td>
    </tr>
    <tr>
      <td style="font-weight:600;">next</td><td>0</td><td>1</td><td>1</td><td>1</td><td>2</td>
    </tr>
  </tobdy>
</table>

最终得到子串指针变化公式 $j=next[j]$。在实际匹配过程中子串在内存里是不会移动的，而是指针在变化，书中画图举例只是为了让问题描述得更加形象。<u>next[j] 的含义是：在子串的第 j 个字符与主串发生失配时，则跳到子串的 next[j] 位置重新与主串当前位置进行比较</u>。

如何推理 next 数组的一般公式？设主串为 's~1~ s~2~ ... s~n~'，模式串为 'p~1~ p~2~ ... p~m~'，当主串中第 i 个字符与主串发生失配时，子串应向右滑动多远，然后与模式中的哪个字符比较？

假设此时应与模式中第 $k(k \lt j)$ 个字符继续比较，则模式中前 k - 1 个字符的子串必须满足下列条件，且不可能存在 $k' \gt k$ 满足下列条件：

$$
'{p_1p_2 \dots p_{k-1}}' = '{p_{j-k+1}p_{j-k+2} \dots p_{j-1}}'
$$

若存在满足如上条件的子串，则发生失配时，仅需将模式向右滑动至模式中第 k 个字符和主串第 i 个字符对齐，此时模式中前 k - 1 个字符的子串必定与主串中第 i 个字符之前的长度为 k - 1 的子串相等，由此，只需从模式第 k 个字符与主串第 i 个字符继续比较即可，如图 4.5 所示。

<table  style="text-align:center;">
  <tbody>
    <tr>
      <td style="font-weight:600;">主串</td>
      <td>s<sub>1</sub></td>
      <td>...</td>
      <td style="background:rgba(0,0,0,0.3);">...</td>
      <td style="background:rgba(0,0,0,0.3);">...</td>
      <td style="background:rgba(0,0,0,0.3);">...</td>
      <td>...</td>
      <td style="background:rgba(0,0,0,0.3);">s<sub>i-k+1</sub></td>
      <td style="background:rgba(0,0,0,0.3);">...</td>
      <td style="background:rgba(0,0,0,0.3);">s<sub>i-1</sub></td>
      <td><u>s<sub>i</sub></u></td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>s<sub>n</sub></td>
    </tr>
    <tr>
      <td style="font-weight:600;">子串</td>
      <td></td>
      <td>...</td>
      <td style="background:rgba(0,0,0,0.3);">p<sub>1</sub></td>
      <td style="background:rgba(0,0,0,0.3);">...</td>
      <td style="background:rgba(0,0,0,0.3);">p<sub>k-1</sub></td>
      <td>...</td>
      <td style="background:rgba(0,0,0,0.3);">p<sub>j-k+1</sub></td>
      <td style="background:rgba(0,0,0,0.3);">...</td>
      <td style="background:rgba(0,0,0,0.3);">p<sub>j-1</sub></td>
      <td><u>p<sub>j</sub></u></td>
      <td>...</td>
      <td>p<sub>m</sub></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td style="font-weight:600;">右移</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
      <td style="background:rgba(0,0,0,0.3);">p<sub>1</sub></td>
      <td style="background:rgba(0,0,0,0.3);">...</td>
      <td style="background:rgba(0,0,0,0.3);">p<sub>k-1</sub></td>
      <td>p<sub>k</sub></td>
      <td>...</td>
      <td>...</td>
      <td>p<sub>m</sub></td>
      <td></td>
      <td></td>
    </tr>
  </tobdy>
</table>

<center><font size=2>图4.5 模式串右移到合适位置（阴影对齐部分表示上下字符相等）</font></center>

当模式串已匹配相等序列中不存在满足上述条件的子串时（可以看成 k = 1），显然应该将模式串右移 j - 1 位，让主串第 i 个字符和模式第一个字符进行比较，此时右移位数最大。

当模式串第一个字符（j=1）与主串第 i 个字符发生失配时，规定 next[1] = 0(<font size=2>可理解为将主串第 i 个字符和模式串第一个字符的前面空位置对齐，也即模式串右移一位。</font>)。将模式串右移一位，从主串的下一个位置（i + 1）和模式串的第一个字符继续比较。

通过上述分析可以得出 next 函数的公式：

$$
next[j]=
\begin{cases}
0, \quad &j=1 \\
max \lbrace k \vert 1 \lt k \lt j \quad且\quad'{p_1 \cdots p_{k-1}}'='{p_{j-k+1} \cdots p_{j-1}}'\rbrace,\quad &当此集合不空时 \\
1, \quad &其他情况
\end{cases}
$$

上述公式不难理解，实际做题求 next 值时，用之前的方法也很好求，但如果想用代码来实现，貌似难度还不小，我们来尝试推理求解的科学步骤。

首先由公式可知

$$
next[1]=0
$$

设 next[j] = k，此时 k 应满足的条件在上文中已描述。

此时 next[j+1] = ? 可能有两种情况：

（1）若 $p_k=p_j$，则表明在模式串中

$$
'{p_1 \dots p_{k-1}p_k}' = '{p_{j-k+1} \dots p_{j-1}p_j}'
$$

并且不可能存在 k' > k 满足上述条件，此时 next[j+1]=k+1，即

$$
next[j+1]=next[j]+1
$$

（2）若 $p_k \neq p_j$，则表明在模式串中

$$
'{p_1 \dots p_{k-1}p_k}' \neq '{p_{j-k+1} \dots p_{j-1}p_j}'
$$

此时可以把求 next 函数值的问题视为一个模式匹配的问题。用前缀 $p_1 \dots p_k$ 去跟后缀 $p_{j-k+1} \dots p_{j}$ 匹配，则当 $p_k \neq p_j$ 时应将 $p_1 \dots p_k$ 向右滑动至以第 next[k] 个字符与 p~j~ 比较，如果 p~next[k]~ 与 p~j~ 还是不匹配，那么需要寻找长度更短的相等前后缀，下一步继续用 p~next[next[k]]~ 与 p~j~ 比较，以此类推，直到找到某个更小的 $k'=next[next	\dots [k]](1 \lt k' \lt k \lt j)$，满足条件

$$
'{p_1 \dots p_k}'='{p_{j-k'+1} \dots p_j}'
$$

则 next[j+1] = k' + 1。

也可能不存在任何 k’ 满足上述条件，即不存在长度更短的相等前缀后缀，令 next[j+1] = 1。

理解起来有一点费劲？下面举一个简单的例子。

<table style="text-align:center;">
  <tr>
  	<td style="font-weight:600;">j</td><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td><td>6</td><td>7</td><td>8</td><td>9</td>
  </tr>
  <tr>
  	<td style="font-weight:600;">模式</td><td>a</td><td>b</td><td>a</td><td>a</td><td>b</td><td>c</td><td>a</td><td>b</td><td>a</td>
  </tr>
  <tr>
  	<td style="font-weight:600;">next[j]</td><td>0</td><td>1</td><td>1</td><td>2</td><td>2</td><td>3</td><td>?</td><td>?</td><td>?</td>
  </tr>
</table>

<center><font size=2>图4.6 求模式串的 next 值</font></center>

图 4.6 的模式串中已求得 6 个字符的 next 值，现求 next[7]，因为 next[6] = 3，又 $p_6 \neq p_3$，则需比较 p~6~ 和 p~1~ （因 next[3] = 1），由于 $p_6 \neq p_1$，而 next[1] = 0，所以 next[7] = 1；求 next[8]，因 p~7~ = p~1~ ，则 next[8] = next[7] + 1 = 2；求 next[9]，因 p~8~ = p~2~，则 next[9] = 3。

通过上述分析写出求 next 值的程序如下：

```c
void get_next(String T, int next[]){
  int i = 1, j = 0;
  next[1] = 0;
  while(i < T.length){
    if(j == 0 || T.ch[i] == T.ch[j]){
      ++i; ++j;
      next[i] = j;		//若 p_i = p_j，则next[j+1]=next[j]+1
    }
    else
      j = next[j];		//否则令j=next[j]，循环继续
  }
}
```

计算机执行起来效率很高，但对于我们手工计算来说会很难。因此，当我们需要手工计算时，还是用最初的方法。

与 next 数组的求解相比， KMP 的匹配算法相对要简单很多，它在形式上与简单的模式匹配算法很相似。不同之处在于当匹配过程产生失配时，指针 i 不变，指针 j 退回到 next[j] 的位置并重新进行比较，并且当指针 j 为 0 时，指针 i 和 j 同时加 1。即若主串的第 i 个位置和模式串的第一个字符不等，则应从主串的第 i + 1 个位置开始匹配。具体代码如下：

```c
int Index_KMP(String S, String T, int next[]){
  int i = 1, j = 1;
  while(i < S.length && j <= T.length){
    if(j == 0 || S.ch[i] == T.ch[j]){
      ++i; ++j;								//继续比较后继字符
    }
    else
      j = next[j];						//模式串向右移动
  }
  if(j > T.length)
    return i - T.length;			//匹配成功
  else
    return 0;
}
```

尽管普通模式匹配的时间复杂度是 $O(mn)$，KMP 算法的时间复杂度是 $O(m+n)$，但在一般情况下，普通模式匹配的实际执行时间近似为 $O(m+n)$，因此至今仍被采用。KMP 算法仅在主串与子串有很多 “部分匹配” 时才显得比普通算法快得多，其主要优点是主串不回溯。

#### 4.2.3 KMP 算法的进一步优化

前面定义的 next 数组在某些情况下尚有缺陷，还可以进一步优化。如图 4.7 所示，模式 'aaaab' 在和主串 'aaabaaaaab' 进行匹配时：

<table style="text-align:center;">
  <tr>
  	<td>主串</td><td>a</td><td>a</td><td>a</td><td style="background:rgba(0,0,0,0.3);">b</td><td>a</td><td>a</td><td>a</td><td>a</td><td>a</td><td>b</td>
  </tr>
  <tr>
  	<td>模式</td><td>a</td><td>a</td><td>a</td><td style="background:rgba(0,0,0,0.3);">a</td><td>b</td><td></td><td></td><td></td><td></td><td></td>
  </tr>
  <tr>
  	<td>j</td><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td><td></td><td></td><td></td><td></td><td></td>
  </tr>
  <tr>
  	<td>next[j]</td><td>0</td><td>1</td><td>2</td><td>3</td><td>4</td><td></td><td></td><td></td><td></td><td></td>
  </tr>
  <tr>
  	<td>nextval[j]</td><td>0</td><td>0</td><td>0</td><td>0</td><td>4</td><td></td><td></td><td></td><td></td><td></td>
  </tr>
</table>

当 i=4、j=4 时，s~4~ 跟 p~4~ （$b \neq a$）失配，如果用之前的 next 数组还需要进行 s~4~ 与 p~3~ 、s~4~ 与 p~2~ 、s~4~ 与 p~1~ 这 3 次比较。事实上，因为 p~next[4]=3~ = p~4~ = a、p~next[3]=2~ = p~3~ = a、p~next[2]=1~ = p~2~ = a，显然后面 3 次 用一个和 p~4~ 相同的字符跟 s~4~ 比较毫无意义，必然失配。那么问题出在哪里呢？

问题在于不应该出现 p~j~ = p~next[j]~ 。理由是：当 $p_j \neq s_j$ 时，下次匹配必然是 p~next[j]~ 跟 s~j~ 比较，如果 p~j~ = p~next[j]~ ，那么相当于拿一个和 p~j~ 相等的字符跟 s~j~ 比较，这必然导致继续失配，这样的比较毫无意义。那么如果出现了 p~j~ = p~next[j]~ 应该如何处理呢？

如果出现了，则需要再次递归，将 next[j] 修正为 next[j] 修正为 next[next[j]]，直至两者不相等为止，更新后的数组命名为 nextval。计算 next 数组修正值的算法如下，此时匹配算法不变。

```c
void get_nextval(String T, int nextval[]){
  int i = 1, j = 0;
  nextval[1] = 0;
  while(i < T.length){
    if(j == 0 || T.ch[i] == T.ch[j]){
      ++i; ++j;
      if(T.ch[i] != T.ch[j]) nextval[i] = j;
      else nextval[i] = nextval[j];
    }
    else
      j = nextval[j];
  }
}
```

KMP 算法对于初学者来说可能不太容易理解，读者可以尝试多读几遍本章的内容，并参考一些其他教材的相关内容来巩固这个知识点。

## 第 5 章 树与二叉树

```mermaid
graph LR
数据结构 --> E[第5章 树与二叉树]
E --> EA[树形结构]
EA --> EAA[二叉树]
EAA --> EAAA["概念：定义、存储结构"]
EAA --> EAAB[操作]
EAAB --> EAABA[三种遍历]
EAAB --> EAABB[线索二叉树]
EAA --> EAAC[应用]
EAAC --> EAACA["排序二叉树——平衡二叉树"]
EAAC --> EAACB[哈夫曼树]
EA --> EAB[树和森林]
EAB --> EABA["概念：定义、存储结构"]
EAB --> EABB[操作]
EABB --> EABBA[与二叉树的转换]
EABB --> EABBB[遍历]
EAB --> EABC["应用：并查集"]
```

### 5.1 树的基本概念

#### 5.1.1 树的定义

树是 $n(n \geq 0)$ 个结点的有限集。当 n = 0 时，称为空树。在任意一棵非空树中应满足：

1）有且仅有一个特定的称为根的结点。

2）当 $n \gt 1$ 时，其余结点可分为 $m(m \gt 0)$ 个互不相交的有限集 $T_1,T_2,\cdots ,T_m$，其中每个集合本身又是一棵树，并且称为根的子树。

显然，树的定义是递归的，即在树的定义中又用到了其自身，树是一种递归的数据结构。树作为一种逻辑结构，同时也是一种分层结构，具有以下两个特点：

1）树的根结点没有前驱，除根结点外的所有结点有且只有一个前驱。

2）树中所有结点可以有零个或多个后继。

树适合于表示具有层次结构的数据。树中的某个结点（除根结点外）最多只和上一层的一个结点（即其父节点）有直接关系，根结点没有直接上层结点，因此在 n 个结点的树中有 n - 1 条边。而树中每个结点与其下一层的零个或多个结点（即其子女结点）有直接关系。

#### 5.1.2 基本术语

下面结合图 5.1 中的树来说明一些基本术语和概念。

![树的树形表示](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/32.png)

<center><font size=2>图5.1 树的树形表示</font></center>

1）考虑结点 K。根 A 到结点 K 的唯一路径上的任意结点，称为结点 K 的祖先。如结点 B 是结点 K 的祖先，而结点 K 是结点 B 的子孙。路径上最接近结点 K 的结点 E 称为 K 的双亲，而 K 为结点 E 的孩子。根 A 是树中唯一没有双亲的结点。有相同双亲的结点称为兄弟，如结点 K 和结点 L 有相同的双亲 E，即 K 和 L 为兄弟。

2）树中一个结点的孩子个数称为该结点的度，树中结点的最大度数称为树的度。如结点 B 的度为 2，结点 D 的度为 3，树的度为 3。

3）度大于 0 的结点称为分支结点（又称非终端结点）；度为 0（没有子女结点）的结点称为叶子结点（又称终端结点）。在分支结点中，每个结点的分支数就是该结点的度。

4）结点的深度、高度和层次。

结点的层次从树根开始定义，根结点为第 1 层，它的子结点为第 2 层，以此类推。双亲在同一层的结点互为堂兄弟，图 5.1 中结点 G 与 E，F，H，I，J 互为堂兄弟

结点的深度是从根结点开始自顶向下逐层累加的。

结点的高度是从叶结点开始自底下上逐层累加的。

树的高度（或深度）是树中结点的最大层数。图 5.1 中树的高度为 4。

5）有序树和无序树。树中结点的各子树从左到右是有次序的，不能互换，称该树为有序树，否则称为无序树。假设图 5.1 为有序树，若将子结点位置互换，则变成一棵不同的树。

6）路径和路径长度。树中两个结点之间的路径是由这两个结点之间所经过的结点序列构成的，而路径长度是路径上所经过的边的个数。**注意**：由于树中的分支是有向的，即从双亲指向孩子，所以树中的路径是从上向下的，同一双亲的两个孩子之间不存在路径。

7）森林。森林是 $m(m \geq 0)$ 棵互不相交的树的集合。森林的概念与树的概念十分相近，因为只要把树的各结点删去就成了森林。反之，只要给 m 棵独立的树加上一个根结点，并把这 m 棵树作为该结点的子树，则森林就变成了树。

**注意**：上述概念无须刻意记忆，根据实例理解即可。考研不大可能直接考查概念，而都是结合具体的题目考查。做题时，遇到不熟悉的概念可以翻书，练习得多自然就记住了。

#### 5.1.3 树的性质

树具有如下最基本的性质：

1）树中的结点数等于所有结点的度数之和加 1。

2）度为 m 的树中第 $i$ 层上至多有 $m^{i-1}$ 个结点（$i \geq 1$）。

3）高度为 h 的 m 叉树至多有 $(m^h-1)/(m-1)$ 个结点。

> 推导公式 $S=mh-1+mh-2+mh-3+ \cdots +m-1=\frac{mh-1}{m-1}$

4）具有 n 个结点的 m 叉树的最小高度为 $\lceil \log_m(n(m-1)+1) \rceil$。

### 5.2 二叉树的概念

#### 5.2.1 二叉树的定义及其主要特性

**1.二叉树的定义**

二叉树是另一种树形结构，其特点是每个结点至多只有两棵子树（即二叉树中不存在度大于 2 的结点），并且二叉树的子树有左右之分，其次序不能任意颠倒。

与树相似，二叉树也以递归的形式定义。二叉树是 $n(n \geq 0)$ 个结点的有限集合：

① 或者为空二叉树，即 n = 0。

② 或者由一个根结点和两个互不相交的被称为根的左子树和右子树组成。左子树和右子树又分别是一棵二叉树。

二叉树是有序树，若将其左、右子树颠倒，则成为另一棵不同的二叉树。即使树中结点只有一棵子树，也要区分它是左子树还是右子树。二叉树的 5 种基本形态如图 5.2 所示。

![二叉树的5种基本形态](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/33.png)

<center><font size=2>图5.2 二叉树的5种基本形态</font></center>

二叉树与度为 2 的有序树的区别：

① 度为 2 的树至少有 3 个结点，而二叉树可以为空。

② 度为 2 的有序树的孩子的左右次序是相对于另一孩子而言的，若某个结点只有一个孩子，则这个孩子就无须区分其左右次序，而二叉树无论其孩子数是否为 2，均需确定其左右次序，即二叉树的结点次序不是相对于另一结点而言，而是确定的。

**2. 几个特殊的二叉树**

![两种特殊形态的二叉树](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/34.png)

<center><font size=2>图5.3 两种特殊形态的二叉树</font></center>

1）满二叉树。一棵高度为 h，且含有 2^h^ - 1 个结点的二叉树称为满二叉树，即树中的每层都含有最多的结点，如图 5.3(a) 所示。满二叉树的叶子结点都集中在二叉树的最下一层，并且除叶子结点之外的每个结点度数均为 2。

可以对满二叉树按层序编号：约定编号从根结点（根结点编号为 1）起，自上而下，自左向右。这样，每个结点对应一个编号，对于编号为 i 的结点，若有双亲，则其双亲为 $\lfloor \frac i2 \rfloor$，若有左孩子，则左孩子为 $2i$；若有右孩子，则右孩子为 $2i+1$。

2）完全二叉树。高度为 h、有 n 个结点的二叉树，当且仅当其每个结点都与高度为 h 的满二叉树中编号为 1~n 的结点一一对应时，称为完全二叉树，如图 5.3(b) 所示。其特点如下：

① 若 $i \leq \lfloor \frac n2 \rfloor$，则结点 i 为分支结点，否则为叶子结点。

② 叶子结点可能在层次最大的两层上出现。对于最大层次中的叶子结点，都依次排列在该层最左边的位置上。

③ 若有度为 1 的结点，则只可能有一个，且该结点只有左孩子而无右孩子（重要特征）。

④ 按层序编号后，一旦出现某结点（编号为 i）为叶子结点或只有左孩子，则编号大于 i 的结点均为叶子结点。

⑤ 若 n 为奇数，则每个分支结点都有左孩子和右孩子；若 n 为偶数，则编号最大的分支结点（编号为 $\frac n2$）只有左孩子，没有右孩子，其余分支结点左、右孩子都有。

3）二叉排序树。左子树上所有结点的关键字均小于根结点的关键字；右子树上的所有结点的关键字均大于根结点的关键字；左子树和右子树又各是一棵二叉排序树。

4）平衡二叉树。树上任一结点的左子树和右子树的深度之差不超过 1。

**3. 二叉树的性质**

1）非空二叉树上的叶子结点数等于度为 2 的结点数加 1，即 $n_0=n_2+1$。

**证明**：设度为 0，1 和 2 的结点个数分别为 n~0~ ，n~1~ 和 n~2~ ，结点总数 $n=n_0+n_1+n_2$。

再看二叉树中的分支数，除根结点外，其余结点都有一个分支进入，设 B 为分支总数，则 $n=B+1$。由于这些分支是由度为 1 或 2 的结点射出的，所以又有 $B=n_1+2n_2$。

于是 $n_0+n_1+n_2=n_1+2n_2+1$，则$n_0=n_2+1$。

**注意**：该结论经常在选择题中用到，希望考试牢记并灵活应用。拓展到任意一棵树，若结点数量为 n，则边的数量为 n - 1。

2）非空二叉树上第 k 层上至多有 2^k-1^ 个结点（$k \geq 1$）。

第 1 层至多有 2^1-1^ = 1 个结点（根），第 2 层至多有 2^2-1^ = 2 个结点，以此类推，可以证明其为一个公比为 2 的等比数列 2^k-1^。

3）高度为 h 的二叉树至多有 2^h^ - 1 个结点（$h \geq 1$）。

该结论利用性质 2 求前 h 项的和，即等比数列求和的结果。

4）对完全二叉树按从上到下、从左到右的顺序依次编号 1,2，…，n，则有以下关系：

① 当 $n \gt 1$ 时，结点 i 个双亲的编号为 $\lfloor \frac i2 \rfloor$，即当 i 为偶数时，其双亲的编号为 $\frac i2$，它是双亲的左孩子；当 i 为奇数时，其双亲的编号为 $\frac {i-1}2$，它是双亲的右孩子。

② 当 $2i \leq n$ 时，结点 i 的左孩子编号为 2i，否则无左孩子。

③ 当 $2i+1 \leq n$ 时，结点 i 的右孩子编号为 2i + 1，否则无右孩子。

④ 结点 i 所在层次（深度）为 $\lfloor \log_2i \rfloor +1$。

5）具有 n 个（$n \gt 0$）结点的完全二叉树的高度为 $\lceil \log_2(n+1) \rceil$ 或 $\lfloor \log_2n \rfloor +1$。

设高度为 h，根据性质 3 和完全二叉树的定义有

$$
2^{h-1} \lt n \leq 2^h-1 \quad 或 \quad 2^{h-1} \leq n \lt 2^h
$$

得 $2^{h-1} \lt n+1 \leq 2^h$，即 $h-1 \lt \log_2(n+1) \leq h$，因为 h 为正整数，所以 $h=\lceil \log_2(n+1) \rceil$。或得 $h-1 \leq \log_2n \lt h$，所以 $h=\lfloor \log_2n \rfloor +1$。

#### 5.2.2 二叉树的存储结构

**1. 顺序存储结构**

二叉树的顺序存储是指用一组地址连续的存储单元依次自上而下、自左至右存储完全二叉树上的结点元素，即将完全二叉树上编号为 i 的结点元素存储在一维数组下标为 i - 1 的分量中。

依据二叉树的性质，完全二叉树和满二叉树采用顺序存储比较合适，树中结点的序号可以唯一地反映结点之间的逻辑关系，这样既能最大可能地节省存储空间，又能利用数组元素的下标值确定结点在二叉树中的位置，以及结点之间的关系。

但对于一般的二叉树，为了让数组下标能反映二叉树中结点之间的逻辑关系，只能添加一些并不存在的空结点，让其每个结点与完全二叉树上的结点相对照，再存储到一维数组的相应分量中。然而，在最坏情况下，一个高度为 h 且只有 h 个结点的单支树却需要占据近 2^h^ - 1 个存储单元。二叉树的顺序存储结构如图 5.4 所示，其中 0 表示并不存在的空结点。

![二叉树的顺序存储结构](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/35.png)

<center><font size=2>图5.4 二叉树的顺序存储结构</font></center>

**注意**：这种存储结构建议从数组下标 1 开始存储树中的结点，若从数组下标 0 开始存储，则不满足性质 4 的描述（比如结点 A 存储在 0 下标的位置上时，无法根据性质 4 来计算出其孩子结点在数组中的位置），这是考生在书写程序时容易忽略的。

**2. 链式存储结构**

由于顺序存储的空间利用率较低，因此二叉树一般都采用链式存储结构，用链表结点来存储二叉树中的每个结点。在二叉树中，结点结构通常包括若干数据域和若干指针域，二叉链表至少包含 3 个域：数据域 data、左指针域 lchild 和右指针域 rchild，如图 5.5 所示。

<div style="display:flex;line-height:40px;width:200px;text-align:center;margin:0 auto;">
  <span style="border:1px solid #000;border-right:0px;flex:1;">lchild</span>
  <span style="border:1px solid #000;border-right:0px;flex:1;">data</span>
  <span style="border:1px solid #000;flex:1;">rchild</span>
</div>
<center><font size=2>图5.5 二叉树链式存储的结点结构</font></center>

![二叉树的顺序存储结构](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/36.png)

<center><font size=2>图5.6 二叉链表的存储结构</font></center>

图 5.6 所示为常用的二叉链表的存储结构。而实际上在不同的应用中，还可以增加某些指针域，如增加指向父结点的指针后，变为三叉链表的存储结构。

二叉树的链式存储结构描述如下：

```c
tyedef struct BiTNode{
  ElemType data;										//数据域
  struct BiTNode *lchild,*rchild;		//左、右孩子指针
}BiTNode,*BiTree;
```

使用不同的存储结构时，实现二叉树操作的算法也会不同，因此要根据实际应用场合（二叉树的形态和需要进行运算）来选择合适的存储结构。

容易验证，在含有 n 个结点的二叉链表中，含有 n + 1 个空链域（重要结论，经常出现在选择题中）。在下一节中，我们将利用这些空链域来组成另一种链表结构——线索链表。

### 5.3 二叉树的遍历和线索二叉树

#### 5.3.1 二叉树的遍历

二叉树的遍历是指按某条搜索路径访问树中每个结点，使得每个结点均被访问一次，而且仅被访问一次。由于二叉树是一种非线性结构，每个结点都可能有两棵子树，因而需要寻找一种规律，以便使二叉树上的结点能排列在一个线性队列上，进而便于遍历。

由二叉树的递归定义可知，遍历一棵二叉树便要决定对根结点 N、左子树 L 和右子树 R 的访问顺序。按照先序遍历左子树再遍历右子树的原则，常见的遍历次序有先序（NLR）、中序（LNR）和后序（LRN）三种遍历算法，其中 “序” 指的是根结点在何时被访问。

**1. 先序遍历**

先序遍历（PreOrder）的操作过程如下。

若二叉树为空，则什么也不做；否则，

1）访问根结点；

2）先序遍历左子树；

3）先序遍历右子树。

对应的递归算法如下：

```c
void PreOrder(BiTree T){
  if(T != NULL){
    visit(T);								//访问根结点
    PreOrder(T->lchild);		//递归遍历左子树
    PreOrder(T->rchild);		//递归遍历右子树
  }
}
```

对于图 5.4 所示的二叉树，先序遍历所得到的结点序列为 1 2 4 6 3 5。

**2. 中序遍历**

中序遍历（InOrder）的操作过程如下。

若二叉树为空，则什么也不做；否则，

1）中序遍历左子树；

2）访问根结点；

3）中序遍历右子树。

对应的递归算法如下：

```c
void InOrder(BiTree T){
  if(T != NULL){
    InOrder(T->lchild);
    visit(T);
    InOrder(T->rchild);
  }
}
```

对于图 5.4 所示的二叉树，中序遍历所得到的结点序列为 2 6 4 1 3 5。

**3. 后序遍历**

后序遍历（PostOrder）的操作过程如下。

若二叉树为空，则什么也不做；否则，

1）后序遍历左子树；

2）后序遍历右子树；

3）访问根结点。

对应的递归算法如下：

```c
void PostOrder(BiTree T){
  if(T != NULL){
    PostOrder(T->lchild);
    PostOrder(T->rchild);
    visit(T);
  }
}
```

对于图 5.4 所示的二叉树，后序遍历所得到的结点序列为 6 4 2 5 3 1。

三种遍历算法中，递归遍历左、右子树的顺序是固定的，只是访问根结点的顺序不同。不管采用哪种遍历算法，每个结点都访问一次且仅访问一次，故时间复杂度都是 $O(n)$。在递归遍历中，递归工作栈的栈深恰好为树的深度，所以在最坏情况下，二叉树是有 n 个结点且深度为 n 的单支树，遍历算法的空间复杂度为 $O(n)$。

**注意**：以上三种遍历方式及算法描述是简单易懂的，读者需要将它们作为模板来记忆，考研中的很多题目都是基于这 3 个模板延伸出来的。

**4. 递归算法和非递归算法的转换**

在上节介绍的 3 种遍历算法中，暂时抹去和递归无关的 visit 语句，则 3 个遍历算法完全相同，因此，从递归执行过程的角度看先序、中序和后序遍历也是完全相同的。

图 5.7 用带箭头的虚线表示了这 3 种遍历算法的递归执行过程。其中，向下的箭头表示更深一层的递归调用，向上的箭头表示从递归代用退出返回；虚线旁的三角形、圆形和方形内的字符分别表示在先序、中序和后序遍历的过程中访问结点时输出的信息。例如，由于中序遍历中访问结点是在左子树之后、遍历右子树之前进行的，则带圆形的字符标在向左递归返回和向右递归调用之间。由此，只要沿虚线从 1 出到 2 结束，将沿途所见的三角形（或圆形或方形）内的字符记下，便得到遍历二叉树的先序（或中序或后序）序列。例如在图 5.7 中，沿虚线游走可以分别得到先序序列为 A B D E C、中序序列为 D B E A C、后序序列为 D E B C A。

![三种遍历过程示意图](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/37.png)

<center><font size=2>图5.7 三种遍历过程示意图</font></center>

借助栈，我们来分析中序遍历的访问过程。

① 沿着根的左孩子，依次入栈，直到左孩子为空，说明已找到可以输出的结点，此时栈内元素依次为 A B D。

② 栈顶元素出栈并访问：若其右孩子为空，继续执行 ②；若其右孩子不空，将右子树转执行 ①。栈顶 D 出栈并访问，它是中序序列的第一个结点；D 右孩子为空，栈顶 B 出栈并访问；B 右孩子不空，将其右孩子 E 入栈，E 左孩子为空，栈顶 E 出栈并访问；E 右孩子为空，栈顶 A 出栈并访问；A 右孩子不空，将其右孩子 C 入栈，C 左孩子为空，栈顶 C 出栈并访问。由此得到中序序列 D B E A C。读者可根据上述分析画出遍历过程的出入栈示意图。

根据分析可以写出中序遍历的非递归算法如下：

```c
void InOrder2(BiTree T){
  InitStack(S); BiTree p = T;	//初始化栈S；p是遍历指针
  while(p || !isEmpty(S)){		//栈不空或p不空时循环
    if(p){										//一路向左
      Push(S, p);							//当前结点入栈
      p = p->lchild;					//左孩子不空，一直向左走
    }
    else{											//出栈，并转向出栈结点的右子树
      Pop(S, p); visit(p);		//栈顶元素出栈，访问出栈结点
      p = p->rchild;					//向右子树走，p赋值为当前结点的右孩子
    }													//返回while循环继续进入if-else语句
  }
}
```

先序遍历和中序遍历的基本思想是类似的，只需把访问结点操作放在入栈操作的前面，读者可以参考中序遍历的过程说明自行模拟出入栈示意图。先序遍历的非递归算法如下：

```c
vodi PreOrder2(BiTree T){
  InitStack(S); BiTree p = T;	//初始化栈S；p是遍历指针
  while(p || !isEmpyt(S)){		//栈不空或p不空时循环
    if(p){										//一路向左
      visit(p); Push(S,p);		//访问当前结点，并入栈
      p = p->lchild;					//左孩子不空，一直向左走
    }
    else{											//出栈，并转向出栈结点的右子树
      Pop(S,p);								//栈顶元素出栈
      p = p->rchild;					//向右子树走，p赋值为当前结点的右孩子
    }													//返回while循环继续进入if-else语句
  }
}
```

后序遍历的非递归实现是三种遍历方法中最难的。因为在后序遍历中，要保证左孩子和右孩子都已被访问并且左孩子在右孩子前访问才能访问根结点，这就为流程的控制带来了难题。

后序非递归遍历算法的思路分析：从根结点开始，将其入栈，然后沿其左子树一直往下搜索，直到搜索到没有左孩子的结点，但是此时不能出栈并访问，因为如果其右子树，还需按相同的规则对其右子树进行处理。直至上述操作进行不下去，若栈顶元素想要出栈被访问，要么右子树为空，要么右子树刚被访问完（此时左子树早已访问完），这样就保证了正确的访问顺序。

```c
void PostOrder2(BiTree T){
  InitStack(S);
  BiTree p, r;
  p = T;
  r = NULL;
  while(p || !IsEmpty(S)){
    if(p){														//走到最左边
      Push(S, p);
      p = p->lchild;
    }
    else{															//向右
      GetTop(S, p);										//读栈顶结点（非出栈）
      if(p->rchild && p->rchild != r)//若右子树存在，且未被访问过
        p = p->rchild;								//转向右
      else{														//否则，弹出结点并访问
        Pop(S, p);										//将结点弹出
        visit(p->data);								//访问该结点
        r = p;												//记录最近访问过的结点
        p = NULL;											//结点访问完后，重置p指针
      }
    }
  }
}
```

**注意**：每次出栈访问完一个结点就相当于遍历完以该结点为根的子树，需将 p 置 NULL。

按后序非递归算法遍历图 5.7(a) 中的二叉树，当访问到 E 时，A，B，D 都已入过栈，对于后序非递归遍历，当一个结点的左右子树都被访问后才会出栈，图中 D 已出栈，此时栈内还有 A 和 B，这是 E 的全部祖先。实际上，访问一个结点 p 时，栈中结点恰好是 p 结点的所有祖先，从栈底到栈顶结点再加上 p 结点，刚好构成从根结点到 p 结点的一条路径。在很多算法设计中都可以利用这一思路来求解，如求根到某结点的路径、求两个结点的最近公共祖先等。

**5. 层次遍历**

图 5.8 所示为二叉树的层次遍历，即按照箭头所指方向，按照 1，2，3，4 的层次顺序，对二叉树中的各个结点进行访问。

![二叉树的层次遍历](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/38.png)

<center><font size=2>图5.8 二叉树的层次遍历</font></center>

要进行层次遍历，需要借助一个队列。先将二叉树根结点入队，然后出队，访问出队结点，若它有左子树，则将左子树根结点入队；若它有右子树，则将右子树根结点入队。然后出队，访问出队结点……如此反复，直至队列为空。

二叉树的层次遍历算法如下：

```c
void LevelOrder(BiTree T){
  InitQueue(Q);								//初始化辅助队列
  BiTree p;
  EnQueue(Q, T);							//将根结点入队
  while(!IsEmpty(Q)){					//队列不空则循环
    DeQueue(Q, p);						//队头结点出队
    visit(p);									//访问出队结点
    if(p->lchild != NULL)
      EnQueue(Q, p->lchild);	//左子树不空，则左子树根结点入队
    if(p->rchild != NULL)
      EnQueue(Q, p->rchild);	//右子树不空，则右子树根结点入队
  }
}
```

上述二叉树层次遍历的算法，读者在复习过程中应将其作为一个模板，在熟练掌握其执行过程的基础上来记忆，并达到熟练手写的程序。这样才能将层次遍历模板应用于各种题目之中。

**注意**：遍历是二叉树各种操作的基础，可以在遍历的过程中对结点进行各种操作，例如，对于一棵已知树求结点的双亲、求结点的孩子结点、求二叉树的深度、求二叉树的叶子结点个数、判断两棵二叉树是否相同等。所有这些操作都建立在二叉树遍历的基础上，因此必须掌握二叉树的各种遍历过程，并能灵活运用以解决各种问题。

**6. 由遍历序列构造二叉树**

由二叉树的先序序列和中序序列可以唯一地确定一棵二叉树。

在先序遍历序列中，第一个结点一定是二叉树的根结点；而在中序遍历中，根结点必然将中序序列分割成两个子序列，前一个子序列是根结点的左子树的中序序列，后一个子序列是根结点的右子树的中序序列。根据这两个子序列，在先序序列中找到对应的左子序列和右子序列。在先序序列中，左子序列的第一个结点是左子树的根结点，右子序列的第一个结点是右子树的根结点。如此递归地进行下去，便能唯一地确定这棵二叉树。

同理，由二叉树的后序序列和中序序列也可以唯一地确定一棵二叉树。

因为后序序列的最后一个结点就如同先序序列的第一个结点，可以将中序序列分割成两个子序列，然后采用类似的方法递归地进行划分，进而得到一棵二叉树。

由二叉树的层序序列和中序序列也可以唯一地确定一棵二叉树，实现方法留给读者思考。需要注意的是，若只知道二叉树的先序序列和后序序列，则无法唯一确定一棵二叉树。

例如，求先序序列（ABCDEFGHI）和中序序列（BCAEDGHFI）所确定的二叉树。

首先，由先序序列可知 A 为二叉树的根结点。中序序列中 A 之前的 BC 为左子树的中序序列，EDGHFI 为右子树的中序序列。然后由先序序列可知 B 是左子树的根结点，D 是右子树的根结点。以此类推，就能将剩下的结点继续分解下去，最后得到二叉树如图 5.9(c) 所示。

![一棵二叉树的构造过程](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/39.png)

<center><font size=2>图5.9 一棵二叉树的构造过程</font></center>

#### 5.3.2 线索二叉树

**1. 线索二叉树的基本概念**

遍历二叉树是以一定的规则将二叉树中的结点排列成一个线性序列，从而得到几种遍历序列，使得该序列中的每个结点（第一个和最后一个结点除外）都有一个直接前驱和直接后继。

传统的二叉链表存储仅能体现一种父子关系，不能直接得到结点在遍历中的前驱或后继。前面提到，在含 $n$ 个结点的二叉树中，有 $n+1$ 个空指针。这是因为每个叶结点有 2 个空指针，每个度为 1 的结点有 1 个空指针，空指针总数为 $2n_0+n_1$，又 $n_0=n_2+1$，所以空指针总数为 $n_0+n_1+n_2+1=n+1$。由此设想能否利用这些空指针来存放指向其前驱或后继的指针？这样就可以像遍历单链表那样方便地遍历二叉树。引入线索二叉树正是为了加快查找结点前驱和后继的速度。

规定：若无左子树，令 lchild 指向其前驱结点；若无右子树，令 rchild 指向其后继结点。如图 5.10 所示，还需增加两个标志域标识指针域是指向左（右）孩子还是指向前驱（后继）。

<div style="display:flex;line-height:40px;width:400px;text-align:center;margin:0 auto;">
  <span style="border:1px solid #000;border-right:0px;flex:1;">lchild</span>
  <span style="border:1px solid #000;border-right:0px;flex:1;">ltag</span>
  <span style="border:1px solid #000;border-right:0px;flex:1;">data</span>
  <span style="border:1px solid #000;border-right:0px;flex:1;">rtag</span>
  <span style="border:1px solid #000;flex:1;">rchild</span>
</div>
<center><font size=2>图5.10 线索二叉树的结点结构</font></center>

其中，标志域的含义如下：

$$
ltag
\begin{cases}
0,\qquad lchild域指示结点的左孩子 \\
1,\qquad lchild域指示结点的前驱
\end{cases}
\\
rtag
\begin{cases}
0,\qquad rchild域指示结点的右孩子 \\
1,\qquad rchild域指示结点的后继
\end{cases}
$$

以这种结点结构构成的二叉链表作为二叉树的存储结构，称为线索链表，其中指向结点前驱和后继的指针称为线索。加上线索的二叉树称为线索二叉树。

**2. 中序线索二叉树的构造**

二叉树的线索化是将二叉链表中的空指针改为指向前驱或后继的线索。而前驱或后继的信息只有在遍历时才能得到，因此线索化的实质就是遍历一次二叉树。

以中序线索二叉树的建立为例。附设指针 pre 指向刚刚访问过的结点，指针 p 指向正在访问的结点，即 pre 指向 p 的前驱。在中序遍历的过程中，检查 p 的左指针是否为空，若为空就将它指向 pre；检查 pre 的右指针是否为空，若为空就将它指向 p，如图 5.11 所示。

![中序线索二叉树及其二叉链表示](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/40.png)

<center><font size=2>图5.11 中序线索二叉树及其二叉链表示</font></center>

通过中序遍历对二叉树线索化的递归算法如下：

```c
void InThread(ThreadTree &p, ThreadTree &pre){
  if(p != NULL){
    InThread(p->lchild, pre);										//递归，线索化左子树
    if(p->lchild == NULL){											//左子树，建立前驱线索
      p->lchild = pre;
      p->ltag = 1;
    }
    if(pre != NULL && pre->rchild == NULL){
      pre->rchild = p;													//建立前驱结点的后继线索
      pre->rtag = 1;
    }
    pre = p;																		//标记当前结点成为刚刚访问过的结点
    InThread(p->rchild, pre);										//递归，线索化右子树
  }//if(p != NULL)
}
```

通过中序遍历建立中序线索二叉树的主过程算法如下：

```c
void CreateInThread(ThreadTree T){
  ThreadTree pre = NULL;
  if(T != NULL){					//非空二叉树，线索化
    InThread(T, pre);			//线索化二叉树
    pre->rchild = NULL;		//处理遍历的最后一个结点
    pre->rtag = 1;
  }
}
```

为了方便，可以在二叉树的线索链表上也添加一个头结点，令其 lchild 域的指针指向二叉树的根结点，其 rchild 域的指针指向中序遍历时访问的最后一个结点；令二叉树中序序列中的第一个结点的 lchild 域指针和最后一个结点的 rchild 域指针均指向头结点。这好比为二叉树建立了一个双向线索链表，方便从前往后或从后往前对线索二叉树进行遍历，如图 5.12 所示。

![带头结点的中序线索二叉树](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/41.png)

<center><font size=2>图5.12 带头结点的中序线索二叉树</font></center>

**3. 中序线索二叉树的遍历**

中序线索二叉树的结点中隐含了线索二叉树的前驱和后继信息。在对其进行遍历时，只要先找到序列中的第一个结点，然后依次找结点的后继，直至其后继为空。在中序线索二叉树中找结点后继的规律是：若其右标志为 “1”，则右链为线索，指示其后继，否则遍历右子树中第一个访问的结点（右子树中最左下的结点）为其后继。不含头结点的线索二叉树的遍历算法如下。

1）求中序线索二叉树中中序序列下的第一个结点：

```c
ThreadNode *Fristnode(ThreadNode *p){
  while(p->ltag == 0)
    p = p->lchild;		//最左下结点（不一定是叶结点）
  return p;
}
```

2）求中序线索二叉树中结点 p 在中序序列下的后继：

```c
ThreadNode *Nextnode(ThreadNode *p){
  if(p->rtag == 0)
    return Firstnode(p->rchild);
  else
    return p->rchild;		//rtag==1 直接返回后继线索
}
```

请读者自行分析并完成求中序线索二叉树的最后一个结点和结点 p 前驱的运算。

<font size=2>将程序 1 中的 ltag 和 lchild 换成 rtag 和 rchild，即为求中序线索二叉树的最后一个结点，将程序 2 中的 rtag 和 rchild 换成 ltag 和 lchild，即为求中序线索二叉树中结点 p 的前驱。</font>

3）利用上面两个算法，可以写出不含头结点的中序线索二叉树的中序遍历的算法：

```c
void Inorder(ThreadNode *T){
  for(ThreadNode *p = Firstnode(T); p != NULL; p = Nextnode(p))
    visit(p);
}
```

**4. 先序线索二叉树和后序线索二叉树**

上面给出了建立中序线索二叉树的代码，建立先序线索二叉树和后序线索二叉树的代码类似，只需变动线索化改造的代码段与调用线索化左右子树递归函数的位置。

以图 5.13(a) 的二叉树为例，给出手动求先序线索二叉树的过程：先序序列为 A B C D F，然后依次判断每个结点的左右链域，如果为空则将其改造为线索。结点 A，B 均有左右孩子；结点 C 无左孩子，将左链域指向前驱 B，无右孩子，将右链域指向后继 D；结点 D 无左孩子，将左链域指向前驱 C，无右孩子，将右链域指向后继 F；结点 F 无左孩子，将左链域指向前驱 D，无右孩子，也无后继故置空，得到的先序线索二叉树如图 5.13(b) 所示。求后序线索二叉树的过程：后序序列为 C D B F A，结点 C 无左孩子，也无前驱故置空，无右孩子，将右链域指向后继 D；结点 D 无左孩子，将左链域指向前驱 C，无右孩子，将右链域指向后继 B；结点 F 无左孩子，将左链域指向前驱 B，无右孩子，将右链域指向后继 A，得到的后续线索二叉树如图 5.13(c) 所示。

![先序线索二叉树和后序线索二叉树](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/42.png)

<center><font size=2>图5.13 先序线索二叉树和后序线索二叉树</font></center>

如何在先序线索二叉树中找结点的后继？如果有左孩子，则左孩子就是其后继；如果无左孩子但有右孩子，则右孩子就是其后继；如果为叶结点，则右链域直接指示了结点的后继。

在后序线索二叉树中找结点的后继较为复杂，可分 3 种情况：① 若结点 x 是二叉树的根，则其后继为空；② 若结点 x 是其双亲的右孩子，或是其双亲的左孩子且其双亲没有右子树，则其后继即为双亲；③ 若结点 x 是其双亲的左孩子，且其双亲有右子树，则其后继为双亲的右子树上按后序遍历列出的第一个结点。图 5.13(c) 中找结点 B 的后继无法通过链域找到，可见在后序线索二叉树上找后继时需知道结点双亲，即需采用带标志域的三叉链表作为存储结构。

### 5.4 树、森林

#### 5.4.1 树的存储结构

树的存储方式有多种，既可采用顺序存储结构，又可采用链式存储结构，但无论采用何种存储方式，都要求能唯一地反映树中各结点之间的逻辑关系，这里介绍 3 种常用的存储结构。

**1. 双亲表示法**

这种存储方式采用一组连续空间来存储每个结点，同时在每个结点中增设一个伪指针，指示其双亲结点在数组中的位置。如图 5.14 所示，根结点下标为 0，其伪指针域为 -1。

![树的双亲表示法](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/43.png)

<center><font size=2>图5.14 树的双亲表示法</font></center>

双亲表示法的存储结构描述如下：

```c
#define MAX_TREE_SIZE 100				//树中最多结点数
typedef struct{									//树的结点定义
  ElemType data;								//数据元素
  int parent;										//双亲位置域
}PTNode;
typedef struct{									//树的类型定义
  PTNode nodes[MAX_TREE_SIZE];	//双亲表示
  int n;												//结点数
}PTree;
```

该存储结构利用了每个结点（根结点除外）只有唯一双亲的性质，可以很快得到每个结点的双亲结点，但求结点的孩子时需要遍历整个结构。

**注意**：区别树的顺序存储结构与二叉树的顺序存储结构。在树的顺序存储结构中，数组下标代表结点的编号，下标中所存的内容指示了结点之间的关系。而在二叉树的顺序存储结构中，数组下标既代表了结点的编号，又指示了二叉树中各结点之间的关系。当然，二叉树属于树，因此二叉树都可以用树的存储结构来存储，但树却不都能用二叉树的存储结构来存储。

**2. 孩子表示法**

孩子表示法是将每个结点的孩子结点都用单链表链接起来形成一个线性结构，此时 n 个结点就有 n 个孩子链表（叶子结点的孩子链表为空表），如图 5.15(a) 所示。

这种存储方式寻找子女的操作非常直接，而寻找双亲的操作需要遍历 n 个结点中孩子链表指针域所指向的 n 个孩子链表。

![树的孩子表示法和孩子兄弟表示法](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/44.png)

<center><font size=2>图5.15 树的孩子表示法和孩子兄弟表示法</font></center>

**3. 孩子兄弟表示法**

孩子兄弟表示法又称二叉树表示法，即以二叉链表作为树的存储结构。孩子兄弟表示法使每个结点包括三部分内容：结点值、指向结点第一个孩子结点的指针，及指向结点下一个兄弟结点的指针（沿此域可以找到结点的所有兄弟结点），如图 5.15(b) 所示。

孩子兄弟表示法的存储结构描述如下：

```c
typedef struct CSNode{
  ElemType data;														//数据域
  struct CSNode *firstchild, *nextsibling;	//第一个孩子和右兄弟指针
}CSNode, *CSTree;
```

这种存储表示法比较灵活，其最大的优点是可以方便地实现树转换为二叉树的操作，易于查找结点的孩子等，但缺点是从当前结点查找其双亲结点比较麻烦。若为每个结点增设一个 parent 域指向其父结点，则查找结点的父结点也很方便。

#### 5.4.2 树、森林与二叉树的转换

由于二叉树和树都可以用二叉链表作为存储结构，因此以二叉链表作为媒介可以导出树与二叉树的一个对应关系，即给定一棵树，可以找到唯一的一棵二叉树与之对应。从物理结构上看，它们的二叉链表是相同的，只是解释不同而已。

树转换为二叉树的规则：每个结点左指针指向它的第一个孩子，右指针指向它在树中的相邻有兄弟，这个规律又称“左孩子右兄弟”。由于根结点没有兄弟，所以对应的二叉树没有右子树，如图 5.16 所示。

![树与二叉树的对应关系](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/45.png)

<center><font size=2>图5.16 树与二叉树的对应关系</font></center>

树转换成二叉树的画法：① 在兄弟结点之间加一连线；② 对每个结点，只保留它与第一个孩子的连线，而与其他孩子的连线全部抹掉；③ 以树根为轴心，顺时针旋转 45°。

将森林转换为二叉树的规则与树类似。先将森林中的每棵树转换为二叉树，由于任何一棵和树对应的二叉树的右子树必空，若把森林中第二棵树根视为第一棵树根的右兄弟，即将第二棵树对应的二叉树当作第一课二叉树根的右子树，将第三棵树对应的二叉树当作第二棵二叉树根的右子树……以此类推，就可以将森林转换为二叉树。

森林转换成二叉树的画法：① 将森林中的每棵树转换成对应的二叉树；② 每棵树的根也可视为兄弟关系，在每棵树的根之间加一根连线；③ 以第一棵树的根为轴心顺时针旋转 45°。

二叉树转换为森林的规则：若二叉树非空，则二叉树的根及其左子树为第一棵树的二叉树形式，故将根的右链断开，二叉树根的右子树可视为一个由除第一棵树外的森林转换后的二叉树，应用同样的方法，直到最后只剩一棵没有右子树的二叉树为止，最后再讲每棵二叉树依次转换成树，就得到了原森林，如图 5.17 所示。二叉树转换为树或森林是唯一的。

![森林与二叉树的对应关系](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/46.png)

<center><font size=2>图5.17 森林与二叉树的对应关系</font></center>

#### 5.4.3 树和森林的遍历

树的遍历是指用某种方式访问树中的每个结点，且仅访问一次。主要有两种方式：

1）先根遍历。若树非空，先访问根结点，再依次遍历根结点的每棵子树，遍历子树时仍遵循先根后子树的规则。其遍历序列与这棵树对应二叉树的先序序列相同。

2）后根遍历。若树非空，先依次遍历根结点的每棵子树，再访问根结点，遍历子树时仍遵循先子树后根的规则。其遍历序列与这棵树相应二叉树的中序序列相同。

图 5.16 的树先根遍历序列为 A B E F C D G，后根遍历序列为 E F B C G D A。

另外，树也有层次遍历，与二叉树的层次遍历思想基本相同，即按层序依次访问各结点。

按照森林和树相互递归的定义，可得到森林的两种遍历方法。

1）先序遍历森林。若森林非空，则按如下规则进行遍历：

- 访问森林中第一棵树的根结点。
- 先序遍历第一棵树中根结点的子树森林。
- 先序遍历除去第一棵树之后剩余的树构成的森林。

2）中序遍历森林。森林为非空时，按如下规则进行遍历：

- 中序遍历森林中第一棵树的根结点的子树森林。
- 访问第一棵树的根结点。
- 中序遍历除去第一棵树之后剩余的树构成的森林。

图 5.17 的森林先序遍历序列为 A B C D E F G H I，中序遍历序列为 B C D A F E H I G。

当森林转换成二叉树时，其第一棵树的子树森林转换成左子树，剩余树的森林转换成右子树，可知森林的先序和中序遍历即为其对应二叉树的先序和中序遍历。

树和森林的遍历与二叉树的遍历关系见表 5.1。

<center><font size=2><b>表5.1 树和森林的遍历与二叉树遍历的对应关系</b></font></center>

|    树    |   森林   |  二叉树  |
| :------: | :------: | :------: |
| 先根遍历 | 先序遍历 | 先序遍历 |
| 后根遍历 | 中序遍历 | 中序遍历 |

### 5.5 树与二叉树的应用

#### 5.5.1 哈夫曼树和哈夫曼编码

**1. 哈夫曼树的定义**

在许多应用中，树中结点常常被赋予一个表示某种意义的数值，称为该结点的权。从树的根到任意结点的路径长度（经过的边数）与该结点上权值的乘积，称为该结点的带权路径长度。树中所有叶结点的带权路径长度之和称为该树的带权路径长度，记为

$$
WPL=\sum\limits_{i=1}^nw_il_i
$$

式中，w~i~ 是第 i 个叶结点所带的权值，l~i~ 是该叶结点到根结点的路径长度。

在含有 n 个带权叶结点的二叉树中，其中带权路径长度（WPL）最小的二叉树称为哈夫曼树，也称最优二叉树。例如，图 5.34 中的 3 棵二叉树都有 4 个叶子结点 a, b, c, d，分别带权 7, 5, 2, 4，它们的带权路径长度分别为

$$
(a)WPL=7 \times 2+5 \times 2+2 \times 2+4 \times 2 =36。\\
(b)WPL=4 \times 2+7 \times 3+5 \times 3+2 \times 1 =46。\\
(c)WPL=7 \times 1+5 \times 2+2 \times 3+4 \times 3 =35。\\
$$

其中，图 5.34(c) 树的 WPL 最小。可以验证，它恰好为哈夫曼树。

![具有不同带权长度的二叉树](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/63.png)

<center><font size=2>图5.34 具有不同带权长度的二叉树</font></center>

**2. 哈夫曼树的构造**

给定 n 个权值分别为 $w_1,w_2,\cdots ,w_n$ 的结点，构造哈夫曼树的算法描述如下：

1）将这 n 个结点分别作为 n 棵仅含一个结点的二叉树，构成森林 F。

2）构造一个新结点，从 F 中选取两棵根结点权值最小的树作为新结点的左、右子树，并且将新结点的权值置为左、右子树上根结点的权值之和。

3）从 F 中删除刚才选出的两棵树，同时将新得到的树加入 F 中。

4）重复步骤 2）和 3），直至 F 中只剩下一棵树为止。

从上述构造过程中可以看出哈夫曼树具有如下特点：

1）每个初始结点最终都成为叶结点，且权值越小的结点到根结点的路径长度越大。

2）构造过程中共新建了 n-1 个结点（双分支结点），因此哈夫曼树的结点总数为 2n-1。

3）每次构造都选择 2 棵树作为新结点的孩子，因此哈夫曼树中不存在度为 1 的结点。

例如，权值 {7, 5, 2, 4} 的哈夫曼树的构造过程如图 5.35 所示。

![哈夫曼树的构造过程](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/64.png)

<center><font size=2>图5.35 哈夫曼树的构造过程</font></center>

**3. 哈夫曼编码**

在数据通信中，若对每个字符用相等长度的二进制位表示，称这种编码方式为固定长度编码。若允许对不同字符用不等长的二进制位表示，则这种编码方式称为可变长度编码。可变长度编码比固定长度编码要好得多，其特点是对频率高的字符赋以短编码，而对频率较低的字符则赋以较长一些的编码，从而可以使字符的平均编码长度减短，起到压缩数据的效果。哈夫曼编码是一种被广泛应用而且非常有效的数据压缩编码。

若没有一个编码是另一个编码的前缀，则称这样的编码为前缀编码。举例：设计字符 A，B 和 C 对应的编码 0，101 和 100 是前缀编码。对前缀编码的编码很简单，因为没有一个编码是其他编码的前缀。所以识别出第一个编码，将它翻译为原码，再对余下的编码文件重复同样的解码操作。例如，码串 00101100 可被唯一地翻译为 0,0,101 和 100。另举反例：如果再将字符 D 的编码设计为 00，此时 0 是 00 的前缀，那么这样的码串的前两位就无法唯一翻译。

由哈夫曼树得到哈夫曼编码是很自然的过程。首先，将每个出现的字符当作一个独立的结点，其权值为它出现的频度（或次数），构造出对应的哈夫曼树。显然，所有字符结点都出现在叶结点中。我们可将字符的编码解释为从根至该字符的路径上边标记的序列，其中边比较为 0 表示“转向左孩子”，标记为 1 表示“转向右孩子”。图 5.36 所示为一个由哈夫曼树构造哈夫曼编码的示例，矩阵方块表示字符及其出现的次数。

![由哈夫曼树构造哈夫曼编码](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/65.png)

<center><font size=2>图5.36 由哈夫曼树构造哈夫曼编码</font></center>

这棵哈夫曼树的 WPL 为

$$
WPL=1\times45+3\times(13+12+16)+4\times(5+9)=224
$$

此处的 WPL 可视为最终编码得到二进制编码的长度，共 224 位。若采用 3 位固定长度编码，则得到的二进制编码长度为 300 位，因此哈夫曼编码共压缩了 25% 的数据。利用哈夫曼树可以设计出总长度最短的二进制前缀编码。

**注意**：0 和 1 究竟是表示左子树还是右子树没有明确规定。左、右孩子结点的顺序是任意的，所以构造出的哈夫曼树并不唯一，但各哈夫曼树的带权路径长度 WPL 相同且为最优。此外，如有若干权值相同的结点，则构造出的哈夫曼树更可能不同，但 WPL 必然相同且是最优的。

#### 5.5.2 并查集

并查集是一种简单的集合表示，它支持以下 3 中操作：

1）Union(S, Root1, Root2)：把集合 S 中的子集合 Root2 并入子集合 Root1.要求 Root1 和 Root2 互不相交，否则不执行合并。

2）Find(S, x)：查找集合 S 中单元数 x 所在的子集合，并返回该子集合的名字。

3）Initial(S)：将集合 S 中的每个元素都初始化为只有一个单元素的子集合。

通常用树（森林）的双亲表示作为并查集的存储结构，每个子集合以一棵树表示。所有表示子集合的树，构成表示全集合的森林，存放在双亲表示数组内。通常用数组元素的下标代表元素名，用根结点的下标代表子集合名，根结点的双亲结点为负数。

例如，若设有一个全集合为 $S = \lbrace 0,1,2,3,4,5,6,7,8,9\rbrace$，初始化时每个元素自成一个单元素子集合，每个子集合的数组值为 -1，如图 5.18 所示。

![并查集的初始化](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/47.png)

<center><font size=2>图5.18 并查集的初始化</font></center>

经过一段时间的计算，这些子集合合并为 3 个更大的子集合 $S_1=\lbrace 0,6,7,8 \rbrace$，$S_2=\lbrace 1,4,9 \rbrace$，$S_3= \lbrace 2,3,5 \rbrace$，此时并查集的树形表示和存储结构如图 5.19 所示。

![用树表示并查集](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/48.png)

<center><font size=2>图5.19 用树表示并查集</font></center>

为了得到两个子集合的并，只需将其中一个子集合根结点的**双亲**指针指向另一个集合的根结点。因此，$S_1 \cup S_2$ 可以具有如图 5.20 所示的表示。

![图5.20](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/49.png)

<center><font size=2>图5.20 S<sub>1</sub>∪S<sub>2</sub>可能的表示方法</font></center>

在采用树的双亲指针数组表示作为并查集的存储表示时，集合元素从 0 到 size - 1。其中 size 是最大元素的个数。下面是并查集主要运算的实现。

并查集的结构定义如下：

```c
#define SIZE 100
int UFSets[SIZE];   //集合元素数组（双亲指针数组）
```

并查集的初始化操作（S 即为并查集）：

```c
void Initial(int S[]){
  for(int i=0; i<size; i++)		//每个自成单元素集合
    S[i] = -1;
}
```

Find 操作（函数在并查集 S 中查找并返回包含元素 x 的树的根）：

```c
int Find(int S[], int x){
  while(S[x] >= 0)				//循环寻找x的根
    x = S[x];
  return x;								//根的S[]小于0
}
```

Union 操作（函数求两个不相交子集合的并集）：

```c
void Union(int S[], int Root1, int Root2){
  //要求 Root1 与 Root2 是不同的，且表示子集合的名字
  S[Root2] = Root1;    //将根Root2连接到另一根Root1下面
}
```

## 第 6 章 图

```mermaid
graph LR
F[第6章 图] --> 图的定义
F --> FB[图结构的存储]
FB --> FBA["邻接矩阵法、邻接表法"]
FB --> FBB["邻接多重表、十字链表"]
F --> FC[图的遍历]
FC --> 深度优先遍历
FC --> 广度优先遍历
F --> FD[图的相关应用]
FD --> FDA["最小生成树：Prim算法、Kruskal算法"]
FD --> FDB["最短路径：Dijkstra算法、Floyd算法"]
FD --> FDC["拓扑排序：AOV网"]
FD --> FDD["关键路径：AOE网"]
```

### 6.1 图的基本概念

#### 6.1.1 图的定义

图 $G$ 由顶点集 $V$ 和边集 $E$ 组成，记为 $G=(V,E)$，其中 $V(G)$ 表示图 $G$ 中顶点的有限非空集；$E(G)$ 表示图 $G$ 中顶点之间的关系（边）集合。若 $V=\lbrace v_1,v_2,\cdots,v_n \rbrace$，则用 $\lvert V \rvert$ 表示图 $G$ 中顶点的个数，$E=\lbrace (u,v) \vert u \in V,v \in V \rbrace$，用 $\lvert E \rvert$ 表示图 $G$ 中边的条数。

**注意**：线性表可以是空表，树可以是空树，但图不可以是空图。就是说，图中不能一个顶点也没有，图的顶点集 $V$ 一定非空，但边集 $E$ 可以为空此时图中只有顶点而没有边。

下面是图的一些基本概念及术语。

**1. 有向图**

若 $E$ 是有向边（也称弧）的有限集合时，则图 $G$ 为有向图。弧是顶点的有序对，记为 $\lang v,w \rang$，其中 $v,w$ 是顶点，$v$ 称为弧尾，$w$ 称为弧头，$\lang v,w \rang$ 称为从 $v$ 到 $w$ 的弧，也称 $v$ 邻接到 $w$。

图 6.1(a) 所示的有向图 $G_1$ 可表示为

$$
G_1=(V_1,E_1) \\
V_1=\lbrace 1,2,3 \rbrace \\
E_1=\lbrace \lang 1,2 \rang,\lang 2,1 \rang,\lang 2,3 \rang \rbrace
$$

```mermaid
graph LR
A((1)) --> B((2)) -->C((3))
B --> A
```

<center><font size=2>图6.1 (a)有向图G<sub>1</sub></font></center>

**2. 无向图**

若 $E$ 是无向边（简称边）的有限集合时，则图 $G$ 为无向图。边是顶点的无序对，记为 $(v,w)$ 或 $(w,v)$。可以说 $w$ 和 $v$ 互为邻接点。边 $(v,w)$ 依附于 $w$ 和 $v$，或称边 $(v,w)$ 和 $v,w$ 相关联。

图 6.1(b) 所示的无向图 $G_2$ 可表示为

$$
G_2=(V_2,E_2) \\
V_2=\lbrace 1,2,3,4 \rbrace \\
E_2=\lbrace (1,2),(1,3),(1,4),(2,3),(2,4),(3,4) \rbrace
$$

```mermaid
graph LR
A((1)) --- B((2)) --- D((4))
B --- C((3))
A --- D
A --- C --- D

```

<center><font size=2>图6.1 (b)无向图G<sub>2</sub></font></center>

```mermaid
graph LR
A((1)) --> B((2))
B --> A
```

<center><font size=2>图6.1 (c)有向完全图G<sub>3</sub></font></center>

**3. 简单图、多重图**

一个图 $G$ 如果满足：① 不存在重复边；② 不存在顶点到自身的边，那么称图 $G$ 为简单图。图 6.1 中 $G_1$ 和 $G_2$ 均为简单图。若图 $G$ 中某两个顶点之间的边数大于 1 条，又允许顶点通过一条边和自身关联，则称图 $G$ 为多重图。多重图和简单图的定义是相对的。数据结构中仅讨论简单图。

**4. 完全图（也称简单完全图）**

对于无向图，$\lvert E \rvert$ 的取值范围为 0 到 $n(n-1)/2$，有 $n(n-1)/2$ 条边的无向图称为完全图，在完全图中任意两个顶点之间都存在边。对于有向图， $\lvert E \rvert$ 的取值范围为 0 到 $n(n-1)$，有 $n(n-1)$ 条弧的有向图称为完全图，在邮箱完全图中任意两个顶点之间都存在方向相反的两条弧。图 6.1 中 $G_2$ 为无向完全图，而 $G_3$ 为有向完全图。

**5. 子图**

设有两个图 $G=(V,E)$ 和 $G'=(V',E')$，若 $V'$ 是 $V$ 的子集，且 $E'$ 是 $E$ 的子集，则称 $G'$ 是 $G$ 的子图。若有满足 $V(G') =V(G)$ 的子图 $G'$，则称其为 $G$ 的生成子图。图 6.1 中 $G_3$ 为 $G_1$ 的子图。

**注意**：并非 $V$ 和 $E$ 的任何子集都能构成 $G$ 的子图，因为这样的子集可能不是图，即 $E$ 的子集中的某些关联的顶点可能不在这个 $V$ 的子集中。

**6. 连通、连通图和连通分量**

在无向图中，若从顶点 $v$ 到顶点 $w$ 有路径存在，则称 $v$ 和 $w$ 是连通的。若图 $G$ 中任意两个顶点都是连通的，则称图 $G$ 为连通图，否则称为非连通图。无向图中的极大连通子图称为连通分量，在图 6.2(a) 中，图 $G_4$ 有 3 个连通分量如图 6.2(b) 所示。假设一个图有 n 个顶点，如果边数小于 n-1，那么此图必是非连通图；思考，如果图是非连通图，那么最多可以有多少条边？

<font size=2>非连通情况下边最多的情况：由 n-1 个顶点构成一个完全图，此时再任意加入一条边则变成连通图。</font>

![无向图及其连通分量](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/66.png)

<center><font size=2>图6.2 无向图及其连通分量</font></center>

**7. 强连通图、强连通分量**

在有向图中，如果有一对顶点 $v$ 和 $w$，从 $v$ 到 $w$ 和从 $w$ 到 $v$ 之间都有路径，则称这两个顶点是强联通的。若图中任何一对顶点都是强联通的，则称此图为强连通图。有向图中的极大强联通子图称为有向图的强联通分量，图 $G_1$ 的强连通分量如图 6.3 所示。思考，假设一个有向图有 n 个顶点，如果是强连通图，那么最少需要有多少条边？

<font size=2>有向图强连通情况下边最少的情况：至少需要 n 条边，构成一个环路。</font>

```mermaid
graph LR
A((1)) --> B((2)) -->A
C((3))
```

<center><font size=2>图6.3 图G<sub>1</sub>的强连通分量</font></center>

**8. 生成树、生成森林**

连通图的生成树是包含图中全部顶点的一个极小连通子图。若图中顶点数为 n，则它的生成树含有 n-1 条边。包含图中全部顶点的极小连通子图，只有生成树满足这个极小条件，对生成树而言，若砍去它的一条边，则会变成非连通图，若加上一条边则会形成一个回路。在非连通图中，连通分量的生成树构成了非连通图的生成森林。图 $G_2$ 的一个生成树如图 6.4 所示。

```mermaid
graph TB
A((1)) --- B((2))
A --- C((3))
A --- D((4))
```

<center><font size=2>图6.4 图G<sub>2</sub>的一个生成树</font></center>

**注意**：区分极大连通子图和极小连通子图。极大连通子图是无向图的连通分量，极大即要求该连通子图包含其所有的边；极小连通子图是既要保持图连通又要使得边数最少的子图。

**9. 顶点的度、入度和出度**

在无向图中，顶点 $v$ 的度是指依附于顶点 $v$ 的边的条数，记为 $TD(v)$。在图 6.1(b) 中，每个顶点的度均为 3。对于具有 n 个顶点、e 条边的无向图，$\sum\limits_{i=1}^{n}TD(v_i)=2e$，即无向图的全部顶点的度的和等于边数的 2 倍，因为每条边和两个顶点相关联。

在有向图中，顶点 $v$ 的度分为入度和出度，入度是以顶点 $v$ 为终点的有向边的数目，记为 $ID(v)$；而出度是以顶点 $v$ 为起点的有向边的数目，记为 $OD(v)$。在图 6.1(a) 中，顶点 2 的出度为 2、入度为 1。顶点 $v$ 的度等于其入度与出度之和，即 $TD(v)=ID(v)+OD(v)$。对于具有 n 个顶点、e 条边的有向图，$\sum\limits_{i=1}^nID(v_i)=\sum\limits_{i=1}^nOD(v_i)=e$，即有向图的全部顶点的入度之和与出度之和相等，并且等于边数，这是因为每条有向边都有一个起点和终点。

**10. 边的权和网**

在一个图中，每条边都可以标上具有某种含义的数值，该数值称为该边的权值。这种边上带有权值的图称为带权图，也称网。

**11. 稠密图、稀疏图**

边数很少的图称为稀疏图，反之称为稠密图。稀疏和稠密本身是模糊的概念，稀疏图和稠密图常常是相对而言的。一般当图 $G$ 满足 $\lvert E \rvert \lt \lvert V \rvert\log \lvert V \rvert$ 时，可以将 $G$ 视为稀疏图。

**12. 路径、路径长度和回路**

顶点 $v_p$ 到顶点 $v_q$ 之间的一条路径是指顶点序列 $v_p,v_{i_1},v_{i_2},\cdots,v_{i_m},v_q$，当然关联的边也可理解为路径的构成要素。路径上边的数目称为路径长度。第一个顶点和最后一个顶点相同的路径称为回路或环。若一个图有 n 个顶点，并且有大于 n-1 条边，则此图一定有环。

**13. 简单路径、简单回路**

在路径序列中，顶点不重复出现的路径称为简单路径。除第一个顶点和最后一个顶点外，其余顶点不重复出现的回路称为简单回路。

**14. 距离**

从顶点 $u$ 出发到顶点 $v$ 的最短路径若存在，则此路径的长度称为从 $u$ 到 $v$ 的距离。若从 $u$ 到 $v$ 根本不存在路径，则记该距离为无穷（$\infty$）。

**15. 有向树**

一个顶点的入度为 0、其余顶点的入度均为 1 的有向图，称为有向树。

### 6.2 图的存储及基本操作

图的存储必须要完整、准确地反映顶点集合边集的信息。根据不同图的结构和算法，采用不同的存储方式将对程序的效率产生相当大的影响，因此所选的存储结构应适合于待求解的问题。

#### 6.2.1 邻接矩阵法

所谓邻接矩阵存储，是指用一个一维数组存储图中顶点的信息，用一个二维数组存储图中边的信息（即各顶点之间的邻接关系），存储顶点之间邻接关系的二维数组称为邻接矩阵。

结点数为 n 的图 $G=(V,E)$ 的邻接矩阵 $A$ 是 $n×n$ 的。将 $G$ 的顶点编号为 $v_1,v_2,\cdots,v_n$。若 $(v_i,v_j) \in E$，则 $A[i][j]=1$，否则 $A[i][j]=0$。

$$
A[i][j]=
\begin{cases}
1,\quad 若(v_i,v_j)或<v_i,v_j>是E(G)中的边 \\
0,\quad 若(v_i,v_j)或<v_i,v_j>不是E(G)中的边
\end{cases}
$$

对于带权图而言，若顶点 $v_i$ 和 $v_j$ 之间有边相连，则邻接矩阵中对应项存放着改变对应的权值，若顶点 $v_i$ 和 $v_j$ 不相连，则用 $\infty$ 来代表这两个顶点之间不存在边。

$$
A[i][j]=
\begin{cases}
w_{ij},\quad &若(v_i,v_j)或<v_i,v_j>是E(G)中的边 \\
0或 \infty,\quad &若(v_i,v_j)或<v_i,v_j>不是E(G)中的边
\end{cases}
$$

有向图、无向图和网对应的邻接矩阵示例图如图 6.5 所示。

![有向图、无向图及网的邻接矩阵](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/67.png)

<center><font size=2>图6.5 有向图、无向图及网的邻接矩阵</font></center>

图的邻接矩阵存储结构定义如下：

```c
#define MaxVertexNum 100											//顶点数目的最大值
typedef char VertexType;											//顶点数据类型
typedef int EdgeType;													//带权图中边上权值的数据类型
typedef struct{
  VertexType Vex[MaxVertexNum];								//顶点表
  EdgeType Edge[MaxVertexNum][MaxVertexNum];	//邻接矩阵，边表
  int vexnum, arcnum;													//图的当前顶点数和弧数
}MGraph;
```

**注意**：

① 在简单应用中可直接用二维数组作为图的邻接矩阵（顶点信息等均可省略）。

② 当邻接矩阵的元素仅表示相应边是否存在时，EdgeType 可采用值为 0 和 1 的枚举类型。

③ 无向图的邻接矩阵是对称矩阵，对规模特大的邻接矩阵可采用压缩存储。

④ 邻接矩阵表示法的空间复杂度为 $O(n^2)$，其中 n 为图的定点数 $\lvert V \rvert$。

图的邻接矩阵存储表示法具有以下特点：

① 无向图的邻接矩阵一定是一个对称矩阵（并且唯一）。因此，在实际存储邻接矩阵时只需存储上（或下）三角矩阵的元素。

② 对于无向图，邻接矩阵的第 i 行（或第 i 列）非零元素（或非 $\infty$ 元素）的个数正好是顶点 i 的度 $TD(v_i)$。

③ 对于有向图，邻接矩阵的第 i 行非零元素（或非 $\infty$元素）的个数正好是顶点 i 的出度 $OD(v_i)$；第 i 列非零元素（或非 $\infty$元素）的个数正好是顶点 i 个入度 $ID(v_i)$。

④ 用邻接矩阵存储图，很容易确定图中任意两个顶点之间是否有边相连。但是，要确定图中有多少条边，则必须按行、按列对每个元素进行检测，所花费的时间代价很大。

⑤ 稠密图适合使用邻接矩阵的存储表示。

⑥ 设图 $G$ 的邻接矩阵为 $A$，$A^n$ 的元素 $A^n[i][j]$ 等于由顶点 i 到顶点 j 的长度为 n 的路径的数目。该结论了解即可，证明方法请参考离散数学教材。

#### 6.2.2 邻接表法

当一个图为稀疏图时，使用邻接矩阵法显然要浪费大量的存储空间，而图的邻接表法结合了顺序存储和链式存储方法，大大减少了这种不必要的浪费。

所谓邻接表，是指对图 $G$ 中每个顶点 $v_i$ 建立一个单链表，第 i 个单链表中的结点表示依附于顶点 $v_i$ 的边（对于有向图则是以顶点 $v_i$ 为尾的弧）这个单链表就称为顶点 $v_i$ 的边表（对于有向图则称为出边表）。边表的头指针和顶点的数据信息采用顺序存储（称为顶点表），所以在邻接表中存在两种结点：顶点表结点和边表结点，如图 6.6 所示。

<div style="display: flex">
  <div style="flex: 1; text-align: center">
    <div style="display: flex;line-height: 40px;width: 200px;text-align: center;margin: 0 auto;">
      <span style="flex: 1">顶点域</span>
      <span style="flex: 1">边表头指针</span>
    </div>
    <div style="display: flex;line-height: 40px;width: 200px;text-align: center;margin: 0 auto;">
      <span style="border: 1px solid #000; border-right: 0px; flex: 1">data</span>
      <span style="border: 1px solid #000; flex: 1">firstarc</span>
    </div>
    <font size="2">顶点表结点</font>
  </div>
  <div style="flex: 1; text-align: center">
    <div style="display: flex;line-height: 40px;width: 200px;text-align: center;margin: 0 auto;">
      <span style="flex: 1">邻接点域</span>
      <span style="flex: 1">指针域</span>
    </div>
    <div style="display: flex;line-height: 40px;width: 200px;text-align: center;margin: 0 auto;">
      <span style="border: 1px solid #000; border-right: 0px; flex: 1">adjvex</span>
      <span style="border: 1px solid #000; flex: 1">nextarc</span>
    </div>
    <font size="2">边表结点</font>
  </div>
</div>
<center><font size="2">图6.6 顶点表和边表结点结构</font></center>

顶点表结点由顶点域（data） 和指向第一条邻接边的指针（firstarc）构成，边表（邻接表）结点由邻接点域（adjvex）和指向下一条邻接边的指针域（nextarc）构成。

无向图和有向图的邻接表的实例分别如图 6.7 和图 6.8 所示。

![无向图邻接表表示法实例](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/68.png)

<center><font size="2">图6.7 无向图邻接表表示法实例</font></center>

![有向图邻接表表示法实例](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/69.png)

<center><font size="2">图6.8 有向图邻接表表示法实例</font></center>

图的邻接表存储结构定义如下：

```c
#define MaxVertexNum 100				//图中顶点数目的最大值
typedef struct ArcNode{					//边表结点
  int adjvex;										//该弧指向的顶点的位置
  struct ArcNode *next;					//指向下一条弧的指针
  //InfoType info;							//网的边权值
}ArcNode;
typedef struct VNode{						//顶点表结点
  VertexType data;							//顶点信息
  ArcNode *first;								//指向第一条依附该顶点的弧的指针
}VNode,AdjList[MaxVertexNum];
typedef struct{
  AdjList vertices;							//邻接表
  int vexnum,arcnum;						//图的顶点数和弧数
}ALGraph;												//ALGraph是以邻接表存储的图类型
```

图的邻接表存储方法具有以下特点：

① 若 $G$ 为无向图，则所需的存储空间为 $O(\lvert V \rvert + 2 \lvert E \rvert)$；若 $G$ 为有向图，则所需的存储空间为 $O(\lvert V \rvert + \lvert E \rvert)$。前者的倍数 2 是由于无向图中，每条边在邻接表中出现了两次。

② 对于稀疏图，采用邻接表表示将极大地节省存储空间。

③ 在邻接表中，给定一顶点，能很容易地找出它的所有邻边，因为只需要读取它的邻接表。在邻接矩阵中，相同的操作则需要扫描一行，花费的时间为 $O(n)$。但是，若要确定给定的两个顶点间是否存在边，则在邻接矩阵中可以立刻查到，而在邻接表中则需要在相应结点对应的边表中查找另一结点，效率较低。

④ 在有向图的邻接表表示中，求一个给定顶点的出度只需计算其邻接表中的结点个数；但求其顶点的入度则需要遍历全部的邻接表。因此，也有人采用逆邻接表的存储方式来加速求解给定顶点的入度。当然，这实际上与邻接表存储方式是类似的。

⑤ 图的邻接表表示并不唯一，因为在每个顶点对应的单链表中，各边结点的链接次序可以是任意的，它取决于建立邻接表的算法及边的输入次序。

#### 6.2.3 十字链表

十字链表是**有向图**的一种链式存储结构。在十字链表中，对应有向图中的每条弧有一个结点，对应于每个顶点也有一个结点。这些结点的结构如下图所示。

<div style="display: flex">
  <div style="flex: 2; text-align: center">
    <div style="display: flex;line-height: 40px;width: 400px;text-align: center;margin: 0 auto;">
      <span style="flex: 1">弧结点</span>
    </div>
    <div style="display: flex;line-height: 40px;width: 400px;text-align: center;margin: 0 auto;">
      <span style="border: 1px solid #000; border-right: 0px; flex: 1">tailvex</span>
      <span style="border: 1px solid #000; border-right: 0px; flex: 1">headvex</span>
      <span style="border: 1px solid #000; border-right: 0px; flex: 1">hlink</span>
      <span style="border: 1px solid #000; border-right: 0px; flex: 1">tlink</span>
      <span style="border: 1px solid #000; flex: 1">(info)</span>
    </div>
  </div>
  <div style="flex: 1; text-align: center">
    <div style="display: flex;line-height: 40px;width: 180px;text-align: center;margin: 0 auto;">
      <span style="flex: 1">顶点结点</span>
    </div>
    <div style="display: flex;line-height: 40px;width: 180px;text-align: center;margin: 0 auto;">
      <span style="border: 1px solid #000; border-right: 0px; flex: 1">data</span>
      <span style="border: 1px solid #000; border-right: 0px; flex: 1">firstin</span>
      <span style="border: 1px solid #000; flex: 1">firstout</span>
    </div>
  </div>
</div>

弧结点中有 5 个域：尾域（tailvex）和头域（headvex）分别指示弧尾和弧头这两个顶点在图中的位置；链域 hlink 指向弧头相同的下一条弧；链域 tlink 指向弧尾相同的下一条弧；info 域指向该弧的相关信息。这样，弧头相同的弧就在同一个链表上，弧尾相同的弧也在同一个链表上。

顶点结点中有 3 个域：data 域存放顶点相关的数据信息，如顶点名称；firstin 和 firstout 两个域分别指向以该顶点为弧头或弧尾的第一个弧结点。

图 6.9 为有向图的十字链表表示法。注意，顶点结点之间是顺序存储的。

![有向图的十字链表表示](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/70.png)

<center><font size="2">图6.9 有向图的十字链表表示</font></center>

在十字链表中，既容易找到 $V_i$ 为尾的弧，又容易找到 $V_i$ 为头的弧，因而容易求得顶点的出度和入度。图的十字链表表示是不唯一的，但一个十字链表表示确定一个图。

#### 6.2.4 邻接多重表

邻接多重表是**无向图**的另一种链式存储结构。

在邻接表中，容易求得顶点和边的各种信息，但在邻接表中求两个顶点之间是否存在边而对边执行删除等操作时，需要分别在两个顶点的边表中遍历，效率较低。

与十字链表类似，在邻接多重表中，每条边用一个结点表示，其结构如下所示。

<div style="display: flex;line-height: 40px;width: 400px;text-align: center;margin: 0 auto;">
  <span style="border: 1px solid #000; border-right: 0px; flex: 1">mark</span>
  <span style="border: 1px solid #000; border-right: 0px; flex: 1">ivex</span>
  <span style="border: 1px solid #000; border-right: 0px; flex: 1">ilink</span>
  <span style="border: 1px solid #000; border-right: 0px; flex: 1">jvex</span>
  <span style="border: 1px solid #000; border-right: 0px; flex: 1">jlink</span>
  <span style="border: 1px solid #000; flex: 1">info</span>
</div>
其中，mark 为标志域，可用以标记该条边是否被搜索过；ivex 和 jvex 为该边依附的两个顶点在图中的位置；ilink 指向下一条依附于顶点 ivex 的边；jlink 指向下一条依附于顶点 jvex 的边，info 为指向和边相关的各种信息的指针域。

每个顶点也用一个结点表示，它由如下所示的两个域组成。

<div style="display: flex;line-height: 40px;width: 200px;text-align: center;margin: 0 auto;">
  <span style="border: 1px solid #000; border-right: 0px; flex: 1">data</span>
  <span style="border: 1px solid #000; flex: 1">firstedge</span>
</div>

其中，data 域存储该顶点的相关信息，firstedge 域指示第一条依附于该顶点的边。

在邻接多重表中，所有依附于同一顶点的边串联在同一链表中，由于每条边依附于两个顶点，因此每个边结点同时链接在两个链表中。对无向图而言，其邻接多重表和邻接表的差别仅在于同一条边在邻接表中用两个结点表示，而在邻接多重表中只有一个结点。

图 6.10 为无向图的邻接多重表表示法。邻接多重表的各种基本操作的实现和邻接表类似。

![有向图的十字链表表示](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/71.png)

<center><font size="2">图6.10 无向图的邻接多重表表示</font></center>

#### 6.2.5 图的基本操作

图的基本操作是独立于图的存储结构的。而对于不同的存储方式，操作算法的具体实现会有着不同的性能。在设计具体算法的实现时，应考虑采用何种存储方式的算法效率会更高。

图的基本操作主要包括（仅抽象地考虑，故忽略掉各变量的类型）：

- Adjacent(G, x, y)：判断图 $G$ 是否存在边 $<x,y>$ 或 $(x,y)$。
- Neighbors(G, x)：列出图 $G$ 与结点 $x$ 邻接的边。
- InsertVertex(G, x)：在图 $G$ 中插入顶点 $x$。
- DeleteVertex(G, x)：从图 $G$ 中删除顶点 $x$。
- AddEdge(G, x, y)：若无向边 $(x,y)$ 或有向边 $<x,y>$ 不存在，则向图 $G$ 中添加该边。
- RemoveEdge(G, x, y)：若无向边 $(x,y)$ 或有向边 $<x,y>$ 存在，则从图 $G$ 中删除该边。
- FirstNeighbor(G, x)：求图 $G$ 中顶点 $x$ 的第一个邻接点，若有则返回顶点号。若 $x$ 没有邻接点或图中不存在 $x$，则返回 -1。
- NextNeighbor(G, x, y)：假设图 $G$ 中顶点 $y$ 是顶点 $x$ 的一个邻接点，返回除 $y$ 外顶点 $x$ 的下一个邻接点的顶点号，若 $y$ 是 $x$ 的最后一个邻接点则返回 -1。
- Get_edge_value(G, x, y)：获取图 $G$ 中边 $(x,y)$ 或 $<x,y>$ 对应的权值。
- Set_edge_value(G, x, y, v)：设置图 $G$ 中边 $(x,y)$ 或 $<x,y>$ 对应的权值为 $v$。

此外，还有图的遍历算法：按照某种方式访问图中的每个顶点且仅访问一次。图的遍历算法包括深度优先遍历和广度优先遍历，具体见下一节的内容。

### 6.3 图的遍历

图的遍历是指从图中的某一顶点出发，按照某种搜索方法沿着图中的边对图中的所有顶点访问一次且仅访问一次。注意到树是一种特殊的图，所以树的遍历实际上也可视为一种特殊的图的遍历。图的遍历算法是求解图的连通性问题、拓扑排序和求关键路径等算法的基础。

图的遍历比树的遍历要复杂得多，因为图的任一顶点都可能和其余的顶点相邻接，所以在访问某个顶点后可能沿着某条路径搜索又回到该顶点上。为避免同一顶点被访问多次，在遍历图的过程中，必须记下每个已访问过的顶点，为此可以设一个辅助数组 visited[] 来标记顶点是否被访问过。图的遍历算法主要有两种：广度优先搜索和深度优先搜索。

#### 6.3.1 广度优先搜索

广度优先搜索（Breadth-First-Search，BFS）类似于二叉树的层序遍历算法。基本思想是：首先访问起始顶点 $v$，接着由 $v$ 出发，依次访问 $v$ 的各个未访问过的邻接顶点 $w_1,w_2,\cdots,w_i$，然后依次访问 $w_1,w_2,\cdots,w_i$ 的所有未被访问过的邻接顶点；再从这些访问过的顶点出发，访问它们所有未被访问过的邻接顶点直至图中所有顶点都被访问过为止。若此时图中尚有顶点未被访问，则另选图中一个未曾被访问的顶点作为始点，重复上述过程，直至图中所有顶点都被访问到为止。Dijkstra 单源最短路径算法和 Prim 最小生成树算法也应用了类似的思想。

换句话说，广度优先搜索遍历图的过程是以 $v$ 为起始点，由近至远依次访问和 $v$ 有路径相同且路径长度为 1, 2, … 的顶点。广度优先搜索是一种分层的查找过程，每向前走一步可能访问一批顶点，不像深度优先搜索那样有往回退的情况，因此它不是一个递归的算法。为了实现逐层的访问，算法必须借助一个辅助队列，以记忆正在访问的顶点的下一层顶点。

广度优先搜索算法的伪代码如下：

```c++
bool visited[MAX_VERTEX_NUM];           //访问标记数组
void BFSTraverse(Graph G){              //对图G进行广度优先遍历
  for(i=0; i<G.vexnum; ++i)
    visited[i] = FALSE;                 //访问标记数组初始化
  InitQueue(Q);                         //初始化辅助队列 Q
  for(i=0; i<G.vexnum; ++i)             //从0号顶点开始遍历
    if(!visited[i])                     //对每个连通分量调用一次BFS
      BFS(G, i);                        //vi为访问过，从vi开始BFS
}
void BFS(Graph G, int v){               //从顶点v出发，广度优先遍历图G
  visit(v);                             //访问初始顶点v
  visited[v] = TRUE;                    //对v做已访问标记
  Enqueue(Q, v);                        //顶点v入队列Q
  while(!isEmpty(Q)){
    DeQueue(Q, v);                      //顶点v出队列
    for(w=FirstNeighbor(G, v); w>=0; w=NextNeighbor(G, v, w))
                                        //检测v所有邻接点
      if(!visited[w]){                  //w为v的尚未访问的邻接顶点
        visit(w);                       //访问顶点w
        visited[w] = TRUE;              //对w做已访问标记
        EnQueue(Q, w);                  //顶点w入队列
     }//if
  }//while
}
```

辅助数组 visited[] 标志顶点是否被访问过，其初始状态为 FALSE。在图的遍历过程中，一旦某个顶点 $v_i$ 被访问，就立即置 visited[i] 为 TRUE，防止它被多次访问。

下面通过实例演示广度优先搜索的过程，给定图 $G$ 如图 6.11 所示。

![一个无向图G](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/72.png)

<center><font size="2">图6.11 一个无向图G</font></center>

假设从 $a$ 结点开始访问，$a$ 先入队。此时队列非空，取出队头元素 $a$，由于 $b,c$ 与 $a$ 邻接且未被访问过，于是依次访问 $b,c$，并将 $b,c$ 依次入队。队列非空，取出队头元素 $b$，依次访问与 $b$ 邻接且未被访问的顶点 $d,e$，并将 $d,e$ 入队（注意：$a$ 与 $b$ 也邻接但 $a$ 已置访问标记，故不再重复访问）。此时队列非空，取出队头元素 $c$，访问与 $c$ 邻接且未被访问的顶点 $f,g$，并将 $f,g$ 入队。此时，取出队头元素 $d$，但与 $d$ 邻接且未被访问的顶点为空，故不进行任何操作。继续取出队头元素 $e$，将 $h$ 入队列……最终取出队头元素 $h$ 后，队列为空，从而循环自动跳出。遍历结果为 $abcdefgh$。

从上例不难看出图的广度优先搜索的过程与二叉树的层序遍历是完全一致的，这也说明了图的广度优先搜索遍历算法是二叉树的层次遍历算法的扩展。

图的广度优先遍历还可用于求一些问题的最优解，但初试方面很难涉及。

**1. BFS 算法的性能分析**

无论是邻接表还是邻接矩阵的存储方式，BFS 算法都需要借助一个辅助**队列** Q，n 个顶点均需入队一次，在最坏的情况下，空间复杂度为 $O(\lvert V \rvert)$。

采用邻接表存储方式时，每个顶点均需所搜一次（或入队一次），故时间复杂度为 $O(\lvert V \rvert)$，在搜索任一顶点的邻接点时，每条边至少访问一次，故时间复杂度为 $O(\lvert E \rvert)$，算法总的时间复杂度为 $O(\lvert V \rvert + \lvert E \rvert)$。采用邻接矩阵存储方式时，查找每个顶点的邻接点所需的时间为 $O(\lvert V \rvert)$，故算法总的时间复杂度为 $O(\lvert V \rvert ^2)$。

**2. BFS 算法求解单源最短路径问题**

若图 $G=(V,E)$ 为非带权图，定义从顶点 $u$ 到顶点 $v$ 的最短路径 $d(u,v)$ 为从 $u$ 到 $v$ 的任何路径中最少边数；若从 $u$ 到 $v$ 没有通路，则 $d(u,v)=\infty$。

使用 BFS，我们可以求解一个满足上述定义的非带权图的单源最短路径问题，这是由广度优先搜索总是按照距离由近到远来遍历图中每个顶点的性质决定的。

BFS 算法求解单源最短路径问题的算法如下：

```c
void BFS_MIN_Distance(Graph G, int u){
  //d[i]表示从u到i结点的最短路径
  for(i=0; i<G.vexnum; ++i)
    d[i] = ∞;                 //初始化路径长度
  visited[u] = TRUE;
  d[u] = 0;
  EnQueue(Q, u);
  while(!isEmpty(Q)){         //BFS算法主过程
    DeQueue(Q, u);            //队头元素u出队
    for(w=FirstNeighbor(G,u); w>=0;w=NextNeighbor(G,u,w))
      if(!visited[w]){        //w为u的尚未访问的邻接顶点
        visited[w] = TRUE;    //设已访问标记
        d[w] = d[u] + 1;      //路径长度加1
        EnQueue(Q,w);         //顶点w入队
      }//if
  }//while
}
```

**3. 广度优先生成树**

在广度遍历的过程中，我们可以得到一棵遍历树，称为广度优先生成树，如图 6.12 所示。需要注意的是，一给定图的邻接矩阵存储表示是唯一的，故其广度优先生成树也是唯一的，但由于邻接表存储表示不唯一，故其广度优先生成树也是不唯一的。

![图的广度优先生成树](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/73.png)

<center><font size="2">图6.12 图的广度优先生成树</font></center>

#### 6.3.2 深度优先搜索

与广度优先搜索不同，深度优先搜索（Depth-First-Search，DFS）类似于树的先序遍历。如其名称中所暗含的意思一样，这种搜索算法所遵循的搜索策略是尽可能“深”地搜索一个图。

它的基本思想如下：首先访问图中某一起始顶点 $v$，然后由 $v$ 出发，访问与 $v$ 邻接且未被访问的任一顶点 $w_1$，再访问与 $w_1$ 邻接且未被访问的任一顶点 $w_2 \cdots\cdots$ 重复上述过程。当不能再继续向下访问时，依次退回到最近被访问的顶点，若它还有邻接顶点未被访问过，则从该点开始继续上述搜索过程，直至图中所有顶点均被访问过为止。

一般情况下，其递归形式的算法十分简洁，算法过程如下：

```c
bool visited[MAX_VERTEX_NUM];     //访问标记数组
void DFSTraverse(Graph G){        //对图G进行深度优先遍历
  for(v=0; v<G.vexnum; ++v)
    visited[v] = FALSE;           //初始化已访问标记数据
  for(v=0; v<G.vexnum; ++v)       //本代码是从v=0开始遍历
    if(!visited[v])
      DFS(G,v)
}
void DFS(Graph G, int v){         //从顶点v出发，深度优先遍历图G
  visit(v);                       //访问顶点v
  visited[v]=TRUE;                //设已访问标记
  for(w=FirstNeighbor(G,v); w>=0; w=NextNeighbor(G,v,w))
    if(!visited[w]){              //w为v的尚未访问的邻接顶点
      DFS(G,w)
    }//if
}
```

以图 6.11 的无向图为例，深度优先搜索过程：首先访问 $a$，并置 $a$ 访问标记；然后访问与 $a$ 邻接且未被访问的顶点 $b$，置 $b$ 访问标记；然后访问与 $b$ 邻接且未被访问的顶点 $d$，置 $d$ 访问标记。此时 $d$ 已没有未被访问过的邻接点，故返回上一个访问过的顶点 $b$，访问与其邻接且未被访问过的顶点 $e$，置 $e$ 访问标记 …… 以此类推，直至图中所有的顶点都被访问一次。遍历结果为 $abdehcfg$。

**注意**：图的邻接矩阵表示是唯一的，但对于邻接表来说，若边的输入次序不同，生成的邻接表也不同。因此，对于同样一个图基于邻接矩阵的遍历所得到的 DFS 序列和 BFS 序列是唯一的，基于邻接表的遍历所得到的 DFS 序列和 BFS 序列是不唯一的。

**1. DFS 算法的性能分析**

DFS 算法是一个递归算法，需要借助一个递归工作栈，故其空间复杂度为 $O(\lvert V \rvert)$。

遍历图的过程实质上是对每个顶点查找其邻接点的过程，其耗费的时间取决于所用的存储结构。以邻接矩阵表示时，查找每个顶点的邻接点所需的时间为 $O(\lvert V \rvert)$，故总的时间复杂度为 $O(\lvert V \rvert^2)$。以邻接表表示时，查找所有顶点的邻接点所需的时间为 $O(\lvert E \rvert)$，访问顶点所需的时间为 $O(\lvert V \rvert)$，此时，总的时间复杂度为 $O(\lvert V \rvert + \lvert E \rvert)$。

**2. 深度优先的生成树和生成森林**

与广度优先搜索一样深度优先搜索也会产生一棵深度优先生成树。当然，，这是有条件的，即对连通图调用 DFS 才能产生深度优先生成树，否则产生的将是深度优先生成森林，如图 6.13 所示。与 BFS 类似，基于邻接表存储的深度优先生成树是不唯一的。

![图的深度优先生成森林](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/74.png)

<center><font size="2">图6.13 图的深度优先生成森林</font></center>

#### 6.3.3 图的遍历与图的连通性

图的遍历算法可以用来判断图的连通性。

对于无向图来说，若无向图是连通的，则从任一结点出发仅需一次遍历就能够访问图中的所有顶点；若无向图是非连通的，则从某一个顶点出发，一次遍历只能访问到该顶点所在连通分量的所有顶点，而对于图中其他连通分量的顶点，则无法通过这次遍历访问。对于有向图来说，若从初始点到图中的每个顶点都有路径，则能够访问到图中的所有顶点否则不能访问到所有顶点。

故在 BFSTraverse() 或 DFSTraverse() 中添加了第二个 for 循环，再选取初始点，继续进行遍历，以防止一次无法遍历图的所有顶点。对于无向图，上述两个函数调用 BFS(G, i) 或 DFS(G, i) 的次数等于该图的连通分量数；而对于有向图则不是这样，因为一个连通的有向图分为强连通的和非强连通的，它的连通子图也分为强连通分量和非强连通分量，非强连通分量一次调用 BFS(G, i) 或 DFS(G, i) 无法访问到该连通分量的所有顶点，如图 6.14 所示。

```mermaid
graph LR
A((" ")) --> B((" "))
C((" ")) --> B
```

<center><font size="2">图6.14 有向图的非强连通分量</font></center>

### 6.4 图的应用

本节是历年考查的重点。图应用主要包括：最小生成（代价）树、最短路径、拓扑排序和关键路径。一般而言这部分内容直接以算法设计题形式考查的可能性很小，而更多的是结合图的实例来考查算法的具体操作过程读者必须学会手工模拟给定图的各个算法的执行过程。此外，还需掌握对给定模型建立相应的图去解决问题的方法。

#### 6.4.1 最小生成树

一个连通图的生成树包含图的所有顶点，并且只含尽可能少的边。对于生成树来说，若砍去它的一条边，则会使生成树变成非连通图；若给它增加一条边，则会形成图中的一条回路。

对于一个带权连通无向图 $G=(V,E)$，生成树不同，每棵树的权（即树中所有边上的权值之和）也可能不同。设 $\Re$ 为 $G$ 的所有生成树的集合，若 $T$ 为 $\Re$ 中边的权值之和最小的那棵生成树，则称 $T$ 为 $G$ 的最小生成树（Minimum-Spanning-Tree, MST）。

不难看出，最小生成树具有如下性质：

1）最小生成树不是唯一的，即最小生成树的树形不唯一，$\Re$ 中可能有多个生成树。当图 $G$ 中的各边权值互不相等时，$G$ 的最小生成树是唯一的；若无向连通图 $G$ 的边数比顶点数少 1，即 $G$ 本身是一棵树时，则 $G$ 的最小生成树就是它本身。

2）最小生成树的边的权值之和总是唯一的，虽然最小生成树不唯一，但其对应的边的权值之和总是唯一的，而且是最小的。

3）最小生成树的边数为顶点数减 1。

构造最小生成树有多种算法，但大多数算法都利用了最小生成树的下列性质：假设 $G=(V,E)$ 是一个带权连通无向图， $U$ 是顶点集 $V$ 的一个非空子集。若 $(u,v)$ 是一条具有最小权值的边，其中 $u \in U,v \in V-U$，则必存在一棵包含边 $(u,v)$的最小生成树。

基于该性质的最小生成树算法主要有 Prim 算法和 Kruskal 算法，它们都基于贪心算法的策略。对这两种算法应主要掌握算法的本质含义和基本思想，并能够手工模拟算法的实现步骤。

下面介绍一个通用的最小生成树算法：

```c
GENERIC_MST(G){
  T = NULL;
  while T 未形成一棵生成树;
    do 找到一条最小代价边(u,v)并且加入T后不会产生回路;
      T = T ∪ (u,v);
}
```

通用算法每次加入一条边以逐渐形成一棵生成树，下面介绍两种实现上述通用算法的途径。

**1. Prim 算法**

Prime（普里姆）算法的执行非常类似于寻找图的最短路径的 Dijkstra 算法（见下一节）。

Prim 算法构造最小生成树的过程如图 6.15 所示。初始时从图中任取一顶点（如顶点 1）加入树 $T$，此时树中只含有一个顶点，之后选择一个与当前 $T$ 中顶点集合距离最近的顶点，并将该顶点和相应的边加入 $T$，每次操作后 $T$ 中的顶点数和边数增 1。以此类推，直至图中所有的顶点都并入 $T$，得到的 $T$ 就是最小生成树。此时 $T$ 中必然有 n-1 条边。

![Prim算法构造最小生成树的过程](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/75.png)

<center><font size="2">图6.15 Prim算法构造最小生成树的过程</font></center>

Prim 算法的步骤如下：

假设 $G=\lbrace V,E \rbrace$ 是连通图，其最小生成树 $T=(U,E_T)$，$E_T$ 是最小生成树中边的集合。

初始化：向空树 $T=(U,E_T)$ 中添加图 $G=(V,E)$ 的任一顶点 $u_0$，使 $U=\lbrace u_0 \rbrace,E_T=\empty$。

循环（重复下列操作直至 $U=V$）：从图 $G$ 中选择满足 $\lbrace (u,v) \vert u \in U,v \in V-U \rbrace$ 且具有最小权值的边 $(u,v)$，加入树 $T$，置 $U=U \cup \lbrace v \rbrace$，$E_T=E_T \cup \lbrace (u,v) \rbrace$。

Prim 算法的简单实现如下：

```c
void Prim(G, T){
  T = ∅;                  //初始化空树
  U = {w};                //添加任一顶点w
  while((V-U) != ∅){      //若树中不含全部顶点
    设(u,v)是使u∈U与v∈(V-U)，且权值最小的边；
    T = T ∪ {(u,v)};     //边归入树
    U = U ∪ {v};         //顶点归入树
  }
}
```

Prim 算法的时间复杂度为 $O(\lvert V \rvert ^2)$，不依赖于 $\lvert E \rvert$，因此它适用于求解边稠密的图的最小生成树。虽然采用其他方法能改进 Prim 算法的时间复杂度，但增加了实现的复杂性。

**2. Kruskal 算法**

与 Prim 算法从顶点开始扩展最小生成树不同，Kruskal（克鲁斯卡尔）算法是一种按权值的递增次序选择合适的边来构造最小生成树的方法。

Kruskal 算法构造最小生成树的过程如图 6.16 所示。初始时为只有 n 个顶点而无边的非连通图 $T=\lbrace V,\lbrace \rbrace \rbrace$，每个顶点自成一个连通分量，然后按照边的权值由小到大的顺序不断选取当前未被选取过且权值最小的边，若改变依附的顶点落在 $T$ 中不同的连通分量上，则将此边加入 $T$，否则舍弃此边而选择下一条权值最小的边。以此类推，直至 $T$ 中所有顶点都在一个连通分量上。

![Kruskal算法构造最小生成树的过程](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/76.png)

<center><font size="2">图6.16 Kruskal算法构造最小生成树的过程</font></center>

Kruskal 算法的步骤如下：

假设 $G=(V,E)$ 是连通图，其最小生成树 $T=(U,E_T)$。

初始化：$U=V,E_T=\empty$。即每个顶点构成一棵独立的树，$T$ 此时时候一个仅含 $\lvert V \rvert$ 个顶点的森林。

循环（重复下列操作直至 $T$ 是一棵树）：按 $G$ 的边的权值递增顺序依次从 $E-E_T$ 中选择一条边，若这条边加入 $T$ 后不构成回路，则将其加入 $E_T$，否则舍弃，直到 $E_T$ 中含有 n-1 条边。

Kruskal 算法的简单实现如下：

```c
void Kruskal(V, T){
  T = V;                   //初始化树T,仅含顶点
  numS = n;                //连通分量数
  while(numS > 1){         //若连通分量数大于1
    从E中取出权值最小的边(v,u);
    if(v和u属于T中不同的连通分量){
      T = T ∪ {(v,u)};    //将此边加入生成树中
      numS--;              //连通分量数减1
    }
  }
}
```

根据图的相关性质，若一条边连接了两棵不同树中的顶点，则对这两棵树来说，它必定是连通的，将这条边加入森林中，完成两棵树的合并，直到整个森林合并成一棵树。

通常在 Kruskal 算法中，采用堆（见第 7 章）来存放边的集合，因此每次选择最小权值的边只需 $O(\log_2 \lvert E \rvert)$ 的时间。此外，由于生成树 $T$ 中的所有边可视为一个等价类，因此每次添加新的边的过程类似于求解等价类的过程，由此可以采用**并查集**的数据结构来描述 $T$，从而构造 $T$ 的时间复杂度为 $O(\lvert E \rvert\log \lvert E \rvert)$。因此，Kruskal 算法适合于边稀疏而顶点较多的图。

#### 6.4.2 最短路径

6.3 节所述的广度优先搜索查找最短路径只是对无权图而言的。当图是带权图时，把从一个顶点 $v_0$ 到图中其余任意一个顶点 $v_i$ 的一条路径（可能不止一条）所经过边上的权值之和，定义为该路径的带权路径长度，把带权路径长度最短的那条路径称为最短路径。

求解最短路径的算法通常都依赖于一种性质即两点之间的最短路径也包含了路径上其他顶点间的最短路径。带权有向图 $G$ 的最短路径问题一般可分为两类：一是单源最短路径，即求图中某一顶点到其他各顶点的最短路径，可通过经典的 Dijkstra（迪杰斯特拉）算法求解；而是求每对顶点间的最短路径，可通过 Floyd（弗洛伊德）算法求解。

**1. Dijkstra 算法求单源最短路径问题**

Dijkstra 算法设置一个集合 S 记录已求得的最短路径的顶点，初始时把源点 $v_0$ 放入 $S$，集合 $S$ 每并入一个新顶点 $v_i$，都要修改源点 $v_0$ 到集合 $V-S$ 中顶点当前的最短路径长度值（这里可能不太好理解？没关系，等下就会清楚）。

在构造的过程中还设置了两个辅助数组：

- dist[]：记录从源点 $v_0$ 到其他各顶点当前的最短路径长度，它的初态为：若从 $v_0$ 到 $v_i$ 有弧，则 dist[i] 为弧上的权值；否则置 dist[i] 为 $\infty$。
- path[]：path[i] 表示从源点到顶点 $i$ 之间的最短路径的前驱结点。在算法结束时，可根据其值追溯得到源点 $v_0$ 到顶点 $v_i$ 的最短路径。

假设从顶点 0 出发，即 $v_0=0$，集合 $S$ 最初只包含顶点 0，邻接矩阵 arcs 表示带权有向图，$arcs[i][j]$ 表示有向边 $<i,j>$ 的权值，若不存在有向边 $<i,j>$，则 $arcs[i][j]$ 为 $\infty$。

Dijkstra 算法的步骤如下（不考虑对 path[] 操作）：

1）初始化：集合 $S$ 初始化为 $\lbrace 0 \rbrace$，dist[] 的初始值 $dist[i]=arcs[0][i],i=1,2,\cdots,n-1$。

2）从顶点集合 $V-S$ 中选出 $v_j$，满足 $dist[j]=Min\lbrace dist[i] \vert v_i \in V-S \rbrace$，$v_j$ 就是当前求得的一条从 $v_0$ 出发的最短路径的终点，令 $S=S \cup\lbrace j \rbrace$。

3）修改从 $v_0$ 出发到集合 $V-S$ 上任一顶点 $v_k$ 可达的最短路径长度若 $dist[j]+arcs[j][k] \lt dist[k]$，则更新 $dist[k]=dist[j]+arcs[j][k]$。

4）重复 2）~3）操作共 n-1 次，直到所有的顶点都包含在 $S$ 中。

步骤 3）也就是开头留下的疑问，每当一个顶点加入 $S$ 后，可能需要修改源点 $v_0$ 到集合 $V-S$ 中可达顶点当前的最短路径长度，下面举一简单例子证明。如下图所示，源点为 $v_0$，初始时 $S=\lbrace v_0 \rbrace$，$dist[1]=3$，$dist[2]=7$，当将 $v_1$ 并入集合 $S$ 后，$dist[2]$ 需要更新为 4。

```mermaid
graph LR
A((0)) --3--> B((1)) --1--> C((2))
A --7--> C
```

思考：Dijkstra 算法与 Prim 算法有何相似之处？

![应用Dijkstra算法图](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/77.png)

<center><font size="2">图6.17 应用Dijkstra算法图</font></center>

<center><font size=2><b>表6.1 从v<sub>1</sub>到各终点的dist值和最短路径的求解过程</b></font></center>

|  顶点  |           第 1 轮            |                   第 2 轮                    |                           第 3 轮                           |                          第 4 轮                           |
| :----: | :--------------------------: | :------------------------------------------: | :---------------------------------------------------------: | :--------------------------------------------------------: |
|   2    | 10<br/>$v_1 \rightarrow v_2$ | 8<br/>$v_1 \rightarrow v_5 \rightarrow v_2$  |         8<br/>$v_1 \rightarrow v_5 \rightarrow v_2$         |                                                            |
|   3    |           $\infty$           | 14<br/>$v_1 \rightarrow v_5 \rightarrow v_3$ | 7<br/>$v_1 \rightarrow v_5 \rightarrow v_4 \rightarrow v_3$ | 9<br/>$v_1 \rightarrow v_5 \rightarrow v_ \rightarrow v_3$ |
|   24   |           $\infty$           | 7<br/>$v_1 \rightarrow v_5 \rightarrow v_4$  |                                                             |                                                            |
|   5    | 5<br/>$v_1 \rightarrow v_5$  |                                              |                                                             |                                                            |
| 集合 S |            {1, 5}            |                  {1, 5, 4}                   |                        {1, 5, 4, 2}                         |                      {1, 5, 4, 2, 3}                       |

例如，对图 6.17 中的图应用 Dijkstra 算法求从顶点 1 出发至其余顶点的最短路径的过程，如表 6.1 所示。算法执行过程的说明如下。

初始化：集合 $S$ 初始为 $\lbrace v_1 \rbrace$，$v_1$ 可达 $v_2$ 和 $v_5$，$v_1$ 不可达 $v_3$ 和 $v_4$，因此 dist[] 数组各元素的初值依次设置为 $dist[2]=10$，$dist[3]=\infty$，$dist[4]=\infty$，$dist[5]=5$。

第一轮：选出最小值 dist[5]，将顶点 $v_5$ 并入集合 $S$，即此时已找到 $v_1$ 到 $v_5$ 最短路径。当 $v_5$ 加入 $S$ 后，从 $v_1$ 到集合 $V-S$ 可达顶点的最短路径长度可能会产生变化。因此需要更新 dist[] 数组。$v_5$ 可达 $v_2$，因 $v_1 \rightarrow v_5 \rightarrow v_2$ 的距离 8 比 dist[2] =10 小，更新 dist[2] = 8；$v_5$ 可达 $v_3$，$v_1 \rightarrow v_5 \rightarrow v_3$ 的距离 14，更新 dist[3] = 14；$v_5$ 可达 $v_4$，$v_1 \rightarrow v_5 \rightarrow v_4$ 的距离 7，更新 dist[4] = 7。

第二轮：选出最小值 dist[4]，将顶点 $v_4$ 并入集合 $S$。继续更新 dist[] 数组。$v_4$ 不可达 $v_2$，dist[2] 不变；$v_4$ 可达 $v_3$，$v_1 \rightarrow v_5 \rightarrow v_4 \rightarrow v_3$ 的距离 13 比 dist[3] 小，故更新 dist[3] = 13。

第三轮：选出最小值 dist[2]，将顶点 $v_2$ 并入集合 $S$。继续更新 dist[] 数组。$v_2$ 可达 $v_3$，$v_1 \rightarrow v_5 \rightarrow v_2 \rightarrow v_3$ 的距离 9 比 dist[3] 小，更新 dist[3] = 9。

第四轮：选出唯一最小值 dist[3]，将顶点 $v_3$ 并入集合 $S$，此时全部顶点都已包含在 $S$ 中。

显然，Dijkstra 算法也是基于贪心策略的。

使用邻接矩阵表示时，时间复杂度为 $O(\lvert V \rvert ^2)$。使用带权的邻接表表示时，虽然修改 dist[] 的时间可以减少，但由于在 dist[] 中选择最小分类的时间不变，时间复杂度仍为 $O(\lvert V \rvert ^2)$。

值得注意的是，边上带有负权值时，Dijkstra 算法并不适用。若允许边上带有负权值，则在与 $S$ （已求得最短路径的顶点集，归入 $S$ 内的结点的最短路径不再变更）内某点（记为 a）以负边相连的点（记为 b）确定其最短路径时，其最短路径长度加上这条负边的权值结果可能小于 a 原先确定的最短路径长度，而此时 a 在 DIjkstra 算法下是无法更新的。例如，对于图 6.18 所示的带权有向图，利用 Dijkstra 算法不一定能得到正确的结果。

```mermaid
graph LR
A((0)) --7--> B((1)) --"-5"--> C((2))
A --5--> C
D((0)) --1--> E((1)) --1--> F((2))
E --"-2"--> D
```

<center><font size="2">图6.18 边上带有负权值的有向带权图</font></center>

**2. Floyd 算法求各顶点之间最短路径问题**

求所有顶点之间的最短路径问题描述如下：已知一个各边权值均大于 0 的带权有向图，对任意两个顶点 $v_i \neq v_j$，要求求出 $v_i$ 与 $v_j$ 之间的最短路径与最短路径长度。

Floyd 算法的基本思想是：递推产生一个 n 阶方阵序列 $A^{(-1)},A^{(0)},\cdots,A^{(k)},\cdots,A^{(n-1)}$，其中 $A^{(k)}[i][j]$ 表示从顶点 $v_i$ 到顶点 $v_j$ 的路径长度，k 表示绕行第 k 个顶点的运算步骤。初始时，对于任意两个顶点 $v_i$ 和 $v_j$，若它们之间存在边则以此边上的权值作为它们之间的最短路径长度；若它们之间不存在有向边，则以 $\infty$ 作为它们之间的最短路径长度。以后逐步尝试在原路径中加入顶点 $k(k=0,1,\cdots,n-1)$ 作为中间顶点，得到的路径比原来的路径长度减少了，则以此新路径代替原路径。算法描述如下：

定义一个 n 阶方阵序列 $A^{(-1)},A^{(0)},\cdots,A^{(n-1)}$，其中，

$$
A^{(-1)}[i][j]=arcs[i][j] \\
A^{(k)}[i][j]=Min\lbrace A^{(k-1)}[i][j],A^{(k-1)}[k][j] \rbrace ,k=0,1,\cdots,n-1
$$

式中，$A^{(0)}[i][j]$ 是从顶点 $v_i$ 到 $v_j$、中间顶点是 $v_0$ 的最短路径的长度，$A^{(k)}[i][j]$ 是从顶点 $v_i$ 到 $v_j$、中间顶点的序号不大于 k 的最短路径的长度。Floyd 算法是一个迭代的过程，每迭代一次，在从 $v_i$ 到 $v_j$ 的最短路径上就多考虑了一个顶点；经过 n 次迭代后，所得到的 $A^{(n-1)}[i][j]$ 就是 $v_i$ 到 $v_j$ 的最短路径长度，即方阵 $A^{(n-1)}$ 中就保存了任意一对顶点之间的最短路径长度。

![带权有向图G及其邻接矩阵](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/78.png)

<center><font size="2">图6.19 带权有向图G及其邻接矩阵</font></center>

<center><font size=2><b>表6.2 Floyd算法的执行过程</b></font></center>

<table style="text-align:center;">
  <thead>
    <tr>
      <td>A</td>
      <td colspan="3">A<sup>(-1)</sup></td>
      <td colspan="3">A<sup>(0)</sup></td>
      <td colspan="3">A<sup>(1)</sup></td>
      <td colspan="3">A<sup>(2)</sup></td>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td></td>
      <td>V<sub>0</sub></td>
      <td>V<sub>1</sub></td>
      <td>V<sub>2</sub></td>
      <td>V<sub>0</sub></td>
      <td>V<sub>1</sub></td>
      <td>V<sub>2</sub></td>
      <td>V<sub>0</sub></td>
      <td>V<sub>1</sub></td>
      <td>V<sub>2</sub></td>
      <td>V<sub>0</sub></td>
      <td>V<sub>1</sub></td>
      <td>V<sub>2</sub></td>
    </tr>
    <tr>
      <td>V<sub>0</sub></td>
      <td>0</td>
      <td>6</td>
      <td>13</td>
      <td>0</td>
      <td>6</td>
      <td>13</td>
      <td>0</td>
      <td>6</td>
      <td><u><b>10</b></u></td>
      <td>0</td>
      <td>6</td>
      <td>10</td>
    </tr>
    <tr>
      <td>V<sub>1</sub></td>
      <td>10</td>
      <td>0</td>
      <td>4</td>
      <td>10</td>
      <td>0</td>
      <td>4</td>
      <td>10</td>
      <td>0</td>
      <td>4</td>
      <td><u><b>9</b></u></td>
      <td>0</td>
      <td>4</td>
    </tr>
    <tr>
      <td>V<sub>2</sub></td>
      <td>5</td>
      <td>∞</td>
      <td>0</td>
      <td>5</td>
      <td><u><b>11</b></u></td>
      <td>0</td>
      <td>5</td>
      <td>11</td>
      <td>0</td>
      <td>5</td>
      <td>11</td>
      <td>0</td>
    </tr>
  </tbody>
</table>

图 6.19 所示为带权有向图 $G$ 及其邻接矩阵。应用 Floyd 算法求所有顶点之间的最短路径长度的过程如表 6.2 所示。算法执行过程的说明如下。

初始化：方阵 $A^{(-1)}[i][j]=arcs[i][j]$。

第一轮：将 $v_0$ 作为中间顶点，对于所有顶点对 $\lbrace i,j \rbrace$，如果有 $A^{-1}[i][j] \gt A^{-1}[i][0]+A^{-1}[0][j]$，则将 $A^{-1}[i][j]$ 更新为 $A^{-1}[i][0]+A^{-1}[0][j]$、有 $A^{-1}[2][1] \gt A^{-1}[2][0]+A^{-1}[0][1]=11$，更新 $A^{-1}[2][1]=11$，更新后的方阵标记为 $A^0$。

第二轮：将 $v_1$ 作为中间顶点，继续检测全部顶点对 $\lbrace i,j \rbrace$。有 $A^0[0][1] \gt A^0[0][1]+A^0[1][2]=10$，更新 $A^0[0][2]=10$，更新后的方阵标记为 $A^1$。

第三轮：将 $v_2$ 作为中间顶点，继续检测全部顶点对 $\lbrace i,j \rbrace$。有 $A^1[1][0] \gt A^1[1][2]+A^1[2][0]=9$，更新 $A^1[1][0]=9$，更新后的方阵标记为 $A^2$。此时 $A^2$ 中保存的就是任意顶点对的最短路径长度。

Floyd 算法的时间复杂度为 $O(\lvert V \rvert ^3)$。不过由于其代码很紧凑，且并不包含其他复杂的数据结构，因此隐含的常数系数是很小的即使对于中等规模的输入来说它仍然是相当有效的。

Floyd 算法允许图中有带负权值的边但不允许有包含带负权值的边组成的回路。Floyd 算法同样适用于带权无向图因为带权无向图可视为权值相同往返二重边的有向图。

也可以用单源最短路径算法来解决每对顶点之间的最短路径问题。轮流将每个顶点作为源点，并且在所有边权值均非负时，运行一次 Dijkstra 算法，其时间复杂度为 $O(\lvert V \rvert ^2)·\lvert V \rvert =O(\lvert V \rvert ^3)$。

#### 6.4.3 有向无环图描述表达式

有向无环图：若一个有向图中不存在环，则称为有向无环图，简称 DAG 图。

有向无环图是描述含有公共子式的表达式的有效工具。例如表达式

$$
((a+b)*(b*(c+d))+(c+d)*e)*((c+d)*e)
$$

可以用上一章描述的二叉树来表示如图 6.20 所示。仔细观察该表达式，可发现有一些相同的子表达式 $(c+d)$ 和 $(c+d)*e$，而在二叉树中，它们也重复出现。若利用有向无环图，则可实现对相同子式的共享，从而节省存储空间，图 6.21 所示为该表达式的有向无环图表示。

![二叉树描述表达式](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/79.png)

<center><font size="2">图6.20 二叉树描述表达式</font></center>

![有向无环图描述表达式](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/80.png)

<center><font size="2">图6.21 有向无环图描述表达式</font></center>

#### 6.4.4 拓扑排序

AOV 网：若用 DAG 图表示一个工程，其顶点表示活动，用有向边 $<V_i,V_j>$ 表示活动 $V_i$ 必须先于活动 $V_j$ 进行的这样一种关系，则将这种有向图称为顶点表示活动的网络，记为 AOV 网。在 AOV 网中，活动 $V_i$ 是活动 $V_j$ 的直接前驱，活动 $V_j$ 是活动 $V_i$ 直接后继，这种前驱和后继关系具有传递性且任何活动 $V_i$ 不能以它自己作为自己前驱或后继。

拓扑排序：在图论中，由一个有向无环图的顶点组成的序列，当且仅当满足下列条件时，称为该图的一个拓扑排序：

① 每个顶点出现且只出现一次。

② 若顶点 $A$ 在序列中排在顶点 $B$ 的前面，则在图中不存在从顶点 $B$ 到顶点 $A$ 的路径。

或定义为：拓扑排序是对有向无环图的顶点的一种排序，它使得若存在一条从顶点 $A$ 到顶点 $B$ 的路径，则在排序中顶点 $B$ 出现在顶点 $A$ 的后面。每个 AOV 网都有一个或多个拓扑排序序列。

对一个 AOV 网进行拓扑排序的算法有很多，下面介绍比较常用的一种方法的步骤：

① 从 AOV 网中选择一个没有前驱的顶点并输出。

② 从网中删除该顶点和所有以它为起点的有向边。

③ 重复 ① 和 ② 直到当前的 AOV 网为空或当前网中不存在无前驱的顶点为止。后一种情况说明有向图中必然存在环。

![有向无环图拓扑排序过程](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/81.png)

<center><font size="2">图6.22 有向无环图拓扑排序过程</font></center>

图 6.22 所示为拓扑排序过程的示例。每轮选择一个入度为 0 的顶点并输出，然后删除该顶点和所有以它为起点的有向边，最后得到拓扑排序的结果为 $\lbrace 1,2,4,3,5 \rbrace$。

拓扑排序算法的实现如下：

```c
bool ToplogicalSort(Graph G){
  InitStack(S);                   //初始化栈，存储入度为0的顶点
  for(int i=0; i<G.vexnum; i++)
    if(indegree[i] == 0)
     Push(S, i);                  //将所有入度为0的顶点进栈
  int count = 0;                  //计数，记录当前已经输出的顶点数
  while(!IsEmpty(S)){             //栈不空，则存在入度为0的顶点
    Pop(S, i);                    //栈顶元素出栈
    print[count++] = i;           //输出顶点i
    for(p=G.vertices[i],firstarc; p; p=p->nextarc){
    //将所有i指向的顶点的入度减1，并且将入度减为0的顶点压入栈S
      v = p->adjvex;
      if(!(--indegree[v]))
        Push(S, v);               //入度为0，则入栈
    }
  }//while
  if(count < G.vexnum)
    return false;                 //排序失败，有向图中有回路
  else
    return true;                  //拓扑排序成功
}
```

由于输出每个顶点的同时还要删除以它为起点的边，故拓扑排序时间复杂度为 $O(\lvert V \rvert + \lvert E \vert)$。此外，利用上一节的深度优先遍历也可实现拓扑排序，请读者仔细思考其原因及实现方法。

对一个 AOV 网，如果采用下列步骤进行排序，则称之为逆拓扑排序：

① 从 AOV 网中选择一个没有后继（出度为 0）的顶点并输出。

② 从网中删除该顶点和所有以它为终点的有向边。

③ 重复 ① 和 ② 直到当前的 AOV 网为空。

用拓扑排序算法处理 AOV 网时，应注意以下问题：

① 入度为零的顶点，即没有前驱活动的或前驱活动都已经完成的顶点，工程可以从这个顶点所代表的活动开始或继续。

② 若一个顶点有多个直接后继，则拓扑排序的结果通常不唯一；但若各个顶点已经排在一个线性有序的序列中，每个顶点有唯一的前驱关系，则拓扑排序的结果是唯一的。

③ 由于 AOV 网中各顶点的地位平等，每个顶点编号是人为的，因此可以按拓扑排序的结果重新编号，生成 AOV 网的新的邻接存储矩阵，这种邻接矩阵可以是三角矩阵；但对于一般的图来说，若其邻接矩阵是三角矩阵，则存在拓扑排序；反之则不一定成立。

#### 6.4.5 关键路径

在带权有向图中，以顶点表示事件，以有向边表示活动，以边上的权值表示完成该活动的开销（如完成活动所需的时间），称之为用边表示活动的网络，简称 AOE 网。AOE 网和 AOV 网都是有向无环图，不同之处在于它们的边和顶点所代表的的含义是不同的，AOE 网中的边有权值；而 AOV 网中的边无权值，仅表示顶点之间的前后关系。

AOE 网具有以下两个性质：

① 只有在某顶点所代表的事件发生后，从该顶点出发的各有向边所代表的活动才能开始；

② 只有在进入某顶点的各有向边所代表的的活动都已结束时，该顶点所代表的事件才能发生。

在 AOE 网中仅有一个入度为 0 的顶点，称为开始顶点（源点），它表示整个工程的开始；网中也仅存在一个入度为 0 的顶点，称为结束顶点（汇点），它表示整个工程的结束。

在 AOE 网中，有些活动是可以并行进行的。从源点到汇点的有向路径可能有多条，并且这些路径长度可能不同。完成不同路径上的活动所需的时间虽然不同，但是只有所有路径上的活动都已完成，整个工程才能算结束。因此，从源点到汇点的所有路径中，具有最大路径长度的路径称为关键路径，而把关键路径上的活动称为关键活动。

完成整个工程的最短时间就是关键路径的长度，即关键路径上各活动花费开销的总和。这是因为关键活动影响了整个工程的时间即若关键活动不能按时完成则整个工程的完成时间就会延长。因此，只要找到了关键活动，就找到了关键路径，也就可以得出最短完成时间。

下面给出寻找关键活动时所用到的几个参量的定义

**1. 时间 $v_k$ 的最早发生时间 $ve(k)$**

它是指从源点 $v_1$ 到顶点 $v_k$ 的最短路径长度。事件 $v_k$ 的最早发生时间决定了所有从 $v_k$ 开始的活动能够开工的最早时间。可用下面的递推公式来计算：

$ve(源点)=0$

$ve(k)=Max\lbrace ve(j)+Weight(v_j,v_k) \rbrace$，$v_k$ 为 $v_j$ 的任意后继，$Weight(v_j,v_k)$ 表示 $<v_j,v_k>$ 上的权值

**计算 $ve()$ 值时，按从前往后的顺序进行，可以在拓扑排序的基础上计算**：

① 初始时，令 $ve[1 \dots n]=0$。

② 输出一个入度为 0 的顶点 $v_j$ 时，计算它所有直接后继顶点 $v_k$ 的最早发生时间，若 $ve[j]+Weight(v_j,v_k) \gt ve[k]$，则 $ve[k]=ve[j]+Weight(v_j,v_k)$。以此类推，直至输出全部顶点。

**2. 事件 $v_k$ 的最迟发生时间 $vl(k)$**

它是指在不推迟整个工程完成的前提下即保证它的后继事件 $v_j$ 在其最迟发生时间 $vl(j)$ 能够发生时，该事件最迟必须发生时间。可用下面的递推公式来计算：

$vl(汇点)=ve(汇点)$

$ve(k)=Min \lbrace vl(j)-Weight(v_k,v_j) \rbrace$，$v_k$ 为 $v_j$ 的任意前驱

**注意**：在计算 $vl(k)$ 时，按从后往前的顺序进行，可以在拓扑排序的基础上计算。

计算 $vl()$ 值时，按从后往前的顺序进行，在上述拓扑排序中，增设一个栈以记录拓扑序列，拓扑排序结束后从栈顶至栈底便为逆拓扑有序序列。过程如下：

① 初始时，令 $vl[1 \dots n]=ve[n]$。

② 栈顶顶点 $v_j$ 出栈，计算其所有直接前驱顶点 $v_k$ 的最迟发生时间，若 $vl[j]-Weight(v_k,v_j) \lt vl[k]$，则 $vl[k]=vl[j]-Weight(v_k,v_j)$。以此类推，直至输出全部栈中顶点。

**3. 活动 $a_i$ 的最早开始时间 $e(i)$**

它是指该活动弧的起点所表示的事件的最早发生时间。若边 $<v_k,v_j>$ 表示活动 $a_i$，则有 $e(i)=ve(k)$。

**4. 活动 $a_i$ 的最迟开始时间 $l(i)$**

它是指该活动弧的终点所表示事件的最迟发生时间与该活动所需时间之差。若边 $v_k,v_j>$ 表示活动 $a_i$,则有 $l(i)=vl(i)-Weight(v_k,v_j)$。

**5. 一个活动 $a_i$ 的最迟开始时间 $l(i)$ 和其最早开始时间 $e(i)$ 的差额 $d(i)=l(i)-e(i)$**

它是指该活动完成的时间余量，即在不增加完成整个工程所需总时间的情况下，活动 $a_i$ 可以拖延的时间。若一个活动的时间余量为零，则说明该活动必须要如期完成，否则就会拖延整个工程的进度，所以称 $l(i)-e(i)=0$ 即 $l(i)=e(i)$ 的活动 $a_i$ 是关键活动。

求关键路径的算法步骤如下：

1）从源点出发，令 $ve(源点)=0$，按拓扑排序有序求其余顶点的最早发生时间 $ve()$。

2）从汇点出发，令 $vl(汇点)=ve(汇点)$，按逆拓扑有序求其余顶点的最迟发生时间 $vl()$。

3）根据各顶点的 $ve()$ 值求所有弧的最早开始时间 $e()$。

4）根据各顶点的 $vl()$ 值求所有弧的最迟开始时间 $l()$。

5）求 AOE 网中所有活动的差额 $d()$，找出所有 $d()=0$ 的活动构成关键路径。

图 6.23 所示为求解关键路径的过程，简单说明如下：

![求解关键路径的过程](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/82.png)

<center><font size="2">图6.23 求解关键路径的过程</font></center>

1）求 $ve()$：初始 $ve(1)=0$，在拓扑排序输出顶点过程中，求得 $ve(2)=3$，$ve(3)=2$，$ve(4)=max\lbrace ve(2)+2,ve(3)+4 \rbrace=max\lbrace5,6\rbrace=6$，$ve(5)=6$，$ve(6)=max\lbrace ve(5)+1,ve(4)+2,ve(3)+3\rbrace=max\lbrace7,8,5\rbrace=8$。

如果这是一道选择题，根据上述求 $ve()$ 的过程就已经能知道关键路径。

2）求 $vl()$：初始 $vl(6)=8$，在逆拓扑排序出栈过程中，求得 $vl(5)=7$，$vl(4)=6$，$vl(3)=min\lbrace vl(4)-4,vl(6)-3\rbrace=min\lbrace2,5\rbrace=2$，$vl(2)=min\lbrace vl(5)-3,vl(4)-2\rbrace=min\lbrace4,4\rbrace=4$，$vl(1)$ 必然为 0 而无须再求。

3）弧的最早开始时间 $e()$ 等于该弧的起点的顶点的 $ve()$，求得结果如上表所示。

4）弧的最迟开始时间 $l(i)$ 等于该弧的终点的顶点的 $vl()$ 减去该弧持续的时间，求得结果如上表所示。

5）根据 $l(i)-e(i)=0$ 的关键活动，得到的关键路径为 $(v_1,v_3,v_4,v_6)$。

对于关键路径，需要注意以下几点：

1）关键路径上的所有活动都是关键活动，它是决定整个工程的关键因素，因此可通过加快关键活动来缩短整个工程的工期。但也不能任意缩短关键活动，因为一旦缩短到一定的程度，该关键活动就可能会变成非关键活动。

2）网中的关键路径并不唯一且对于有几条关键路径的网，只提高一条关键路径上的关键活动速度并不能缩短整个工程的工期，只有加快那些包括在所有关键路径上的关键活动才能达到缩短工期的目的。

## 第 7 章 查找

```mermaid
graph LR
G[第7章 查找] --> GA["基本概念：静态查找、动态查找"]
G --> GB[线性结构]
GB --> GBA[顺序查找]
GB --> GBB[折半查找]
GB --> GBC[分块查找]
G --> GC[树形结构]
GC --> GCA[二叉排序树]
GC --> GCB[二叉平衡树]
GC --> GCC[红黑树]
GC --> GCD["B树、B+树"]
G --> GD["散列结构——散列表"]
GD --> GDA[性能分析]
GD --> GDB[冲突处理]
G --> GE["效率指标——平均查找长度"]
GE --> GEA[查找成功]
GE --> GEB[查找失败]
```

### 7.1 查找的基本概念

1）查找。在数据结合中寻找满足某种条件的数据元素的过程称为查找。查找的结果一般分为两种：一是查找成功，即在数据集合中找到了满足条件的数据元素；二是查找失败。

2）查找表（查找结构）。用于查找的数据集合称为查找表，它由同一类型的数据元素（或记录）组成，可以是一个数组或链表等数据类型。对查找表经常进行的操作一般有 4 种：① 查询某个特定的数据元素是否在查找表中；② 检索满足条件的某个特定的数据元素的各种属性；③ 在查找表中插入一个数据元素；④ 从查找表中删除某个数据元素。

3）静态查找表。若一个查找表的操作只涉及上述操作 ① 和 ②，则无须动态地修改查找表，此类查找表称为静态查找表。与此相应，需要动态地插入或删除查找表称为动态查找表。适合静态查找表的查找方法有顺序查找、折半查找、散列查找等；适合动态查找表的查找方法有二叉排序树的查找、散列查找等。二叉平衡树和 B 树都是二叉排序树的改进。

4）关键字。数据元素中唯一标识该元素的某个数据项的值，使用基于关键字的查找，查找结果应该是唯一的。例如，在由一个学生元素构成的数据集合中，学生元素中 “学号” 这一数据项的值唯一地标识一名学生。

5）平均查找长度。在查找过程中，一次查找长度是指需要比较的关键字次数，而平均查找长度则是所有查找过程中进行关键字的比较次数的平均值，其数学定义为

$$
ASL=\sum\limits_{i=1}^nP_iC_i
$$

式中，$n$ 是查找表的长度；$P_i$ 是查找第 $i$ 个数据元素的概率，一般认为每个数据元素的查找概率相等，即 $P_i=\frac1n$；$C_i$ 是找到第 $i$ 个数据元素所需进行的比较次数。平均查找长度是衡量查找算法效率的最主要的指标。

### 7.2 顺序查找和折半查找

#### 7.2.1 顺序查找

顺序查找又称线性查找它对顺序表和链表都是适用的。对于顺序表，可通过数组下标递增来顺序扫描每个元素；对于链表可通过指针 next 来依次扫描每个元素。顺序查找通常分为对一般的无序线性表的顺序查找和对按关键字有序的线性表的顺序查找。下面分别进行讨论。

**1. 一般线性表的顺序查找**

作为一种最直观的查找方法，其基本思想是从线性表的一端开始，逐个检查关键字是否满足给定的条件。若查找到某个元素的关键字满足给定条件，则查找成功，返回该元素在线性表中的位置；若已经查找到表的另一端，但还没有查找到符合给定条件的元素则返回查找失败的信息。下面给出其算法，主要是为了说明其中引入的 “哨兵” 的作用。

```c
typedef struct{     //查找表的数据结构
  ElemType *elem;   //元素存储空间基址，建表时按实际长度分配，0号单元留空
  int TableLen;     //表的长度
}SSTable;
int Search_Seq(SSTable ST, ElemType key){
  ST.elem[0] = key;                         //“哨兵”
  for(i=ST.TableLen; ST.elem[i]!=key; --i); //从后往前找
  retuurn i;        //若表中不存在关键字为key的元素，将查找到i为0时退出for循环
}
```

在上述算法中，将 `ST.elem[0]` 称为 “哨兵”。引入它的目的是使得 `Search_Seq` 内的循环不必判断数组是否会越界，因为满足 `i==0` 时，循环一定会跳出。需要说明的是，在程序中引入 “哨兵” 并不是这个算法独有的。引入 “哨兵” 可以避免很多不必要的判断语句，从而提高程序效率。

对于有 $n$ 个元素的表，给定值 key 与表中第 $i$ 个元素相等，即定位第 $i$ 个元素时，需进行 $n-i+1$ 次关键字比较，即 $C_i=n-i+1$。查找成功时，顺序查找的平均长度为

$$
ASL_{成功}=\sum\limits_{i=1}^nP_i(n-i+1)
$$

当每个元素的查找概率相等，即 $P_i=\frac1n$ 时，有

$$
ASL_{成功}=\sum\limits_{i=1}^nP_i(n-i+1)=\frac{n+1}2
$$

查找不成功时，与表中各关键字的比较次数显然是 n+1 次，从而顺序查找不成功的平均查找长度为 $ASL_{不成功}=n+1$。

通常，查找表中记录的查找概率并不相等。若能预先得知每个记录的查找概率则应先对记录的查找概率进行排序，使表中记录按查找概率由大至小重新排列。

综上所述，顺序查找的缺点是当 n 较大时，平均查找长度较大，效率低；优点是对数据元素的存储没有要求顺序存储或链式存储皆可。对表中记录的有序性也没有要求，无论记录是否按关键字有序，均可应用同时还需注意，对线性的链表只能进行顺序查找。

**2. 有序表的顺序查找**

若在查找之前就已经知道表是关键字有序的，则查找失败时可以不用再比较到表的另一端就能返回查找失败的信息从而降低顺序查找失败的平均查找长度。

假设表 L 是按关键字从小到大排列的，查找的顺序是从前往后，待查找的关键字为 key，当查找到第 $i$ 个元素时，发现第 $i$ 个元素对应的关键字小于 key，但第 $i+1$ 个元素对应的关键字大于 key，这时就可返回查找失败的信息，因为第 $i$ 个元素之后的元素的关键字均大于 key，所以表中不存在关键字为 key 的元素。

可以用如图 7.1 所示的判定树来描述有序线性表的查找过程。树中的圆形结点表示有序线性表中存在的元素；树中矩形结点称为失败结点（若有 $n$ 个结点，则相应地有 $n+1$ 个查找失败结点），它描述的是那些不在表中的数据值的集合。若查找到失败结点则说明查找不成功。

![有序顺序表上的顺序查找判定树](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/83.png)

<center><font size="2">图7.1 有序顺序表上的顺序查找判定树</font></center>

在有序线性表顺序查找中，查找成功的平均查找长度和一般线性表的查找一样查找失败时查找一定走到了某个失败的结点。这些失败结点是我们虚构的空结点实际上是不存在的，所以到达失败结点时所查找的长度等于它上面一个圆形结点的所在层数。查找不成功的平均长度在相等查找概率的情形下为

$$
ASL_{不成功}=\sum_{j=1}^nq_j(l_j-1)=\frac{1+2+\cdots+n+n}{n+1}=\frac n2+\frac n{n+1}
$$

式中，$q_j$ 是到达第 $j$ 个失败结点概率，在相等查找概率的情形下，它为 $\frac1{n+1}$；$l_j$ 是第 $j$ 个失败结点所在的层数。当 $n=6$ 时，$ASL_{不成功}=\frac62+\frac67=3.86$，比一般的顺序查找算法好一些。

注意，有序线性表的顺序查找和后面的折半查找的思想是不一样的，且有序线性表的顺序查找中的线性表可以是链式存储结构。

#### 7.2.2 折半查找

折半查找又称二分查找，它仅适用于**有序的顺序表**。

折半查找的基本思想：首先将给定值 key 与表中中间位置的元素比较，若相等，则查找成功，返回该元素的存储位置；若不等，则所需查找的元素只能在中间元素以外的前半部分或后半部分（例如，在查找表升序排列时，若给定值 key 大于中间元素，则所查找的元素只可能在后半部分）。然后在缩小的范围内继续进行同样的查找，如此重复，直到找到为止，或确定表中没有所需要查找元素，则查找不成功返回查找失败信息。算法如下：

```c
int Binary_Search(SeqList L, ElemType key){
  int low=0, high=L.TableLen-1,mid;
  while(low <= high){
    mid = (low + high) / 2;       //取中间位置
    if(L.elem[mid] == key)
      return mid;                 //查找成功则返回所在位置
    else if(L.elem[mid] > key)
      high = mid - 1;             //从前半部分继续查找
    else
      low = mid + 1;              //从后半部分继续查找
  }
  return -1;                      //查找失败，返回-1
}
```

例如，已知 11 个元素的有序表 $\lbrace 7,10,13,16,19,29,32,33,37,41,43\rbrace$，要查找值为 11 和 32 的元素，指针 low 和 high 分别指向表的下界和上界，mid 则指向表的中间位置 $\lfloor (low+high)/2\rfloor$。以下说明查找 11 的过程（查找 32 的过程请读者自行分析）：

$$
&7\quad &10\quad &13\quad &16\quad &19\quad &29\quad &32\quad &33\quad &37\quad &41\quad &43 \\
&\quad\uparrow low & & & & &\quad\uparrow mid & & & & &\quad\uparrow high
$$

第一次查找，将中间位置元素与 key 值比较。因为 11 < 29，说明待查元素若存在，则必在范围 $[low,mid-1]$ 内，令指针 high 指向位置 mid-1，high = mid - 1 = 5，重新求得 mid = (1 + 5) / 2 = 3，第二次的查找范围为 $[1,5]$。

$$
&7\quad &10\quad &13\quad &16\quad &19\quad &29\quad &32\quad &33\quad &37\quad &41\quad &43 \\
&\quad\uparrow low & &\quad\uparrow mid & &\quad\uparrow high & & & & & &
$$

第二次查找，同样将中间元素与 key 值比较。因为 11< 13，说明待查元素若存在，则必在范围 $[low,mid-1]$ 内，令指针 high 指向位置 mid - 1，high = mid - 1 = 2，重新求得 mid =(1 + 2) / 2 = 1，第三次的查找范围为 $[1,2]$。

$$
&7\quad &10\quad &13\quad &16\quad &19\quad &29\quad &32\quad &33\quad &37\quad &41\quad &43 \\
&\quad\uparrow low &\quad\uparrow high & & & & & & & & & \\
&\quad\uparrow mid & & & & & & & & & &
$$

第三次查找，将中间位置元素与 key 值比较。因为 11 > 7，说明待查元素若存在，则必在范围 $[mid+1,high]$ 内。令 low = mid + 1 = 2，mid = (2 + 2) / 2 = 2，第四次的查找范围为 $[2,2]$。

$$
&7\quad &10\quad &13\quad &16\quad &19\quad &29\quad &32\quad &33\quad &37\quad &41\quad &43 \\
& &\quad low\uparrow \quad\uparrow high & & & & & & & & & \\
& &\quad\uparrow mid & & & & & & & & &
$$

第四次查找，此时子表只含有一个元素，且 $10\neq11$，故表中不存在待查元素。

折半查找的过程可用图 7.2 所示的二叉树来描述，称为判定树。树中每个圆形结点表示一个记录，结点中的值为该记录的关键字值；树中最下面的叶结点都是方形的，它表示查找不成功的情况。从判定树可以看出查找成功时的查找长度为从根结点到目的结点的路径上的结点数，而查找不成功时的查找长度为从根结点到对应失败结点的父结点的路径上的结点数；每个结点值均大于其左子结点值且均小于其右子结点值。若有序序列有 n 个元素，则对应的判定树有 n 个圆形的非叶结点和 n + 1 个方形的叶结点。显然，判定树是一棵平衡二叉树。

![描述折半查找过程的判定树](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/84.png)

<center><font size="2">图7.2 描述折半查找过程的判定树</font></center>

由上述分析可知，用折半查找法查找到给定值的比较次数最多不会超过树的高度。在等概率查找时，查找成功的平均查找长度为

$$
ASL=\frac1n\sum\limits_{i=1}^nl_i=\frac1n(1\times1+2\times2+\cdots+h\times2^{h-1})=\frac{n+1}n\log_2(n+1)-1\approx\log_2(n+1)-1
$$

式中，$h$ 是树的高度，并且元素个数为 $n$ 时树高 $h=\lceil\log_2(n+1)\rceil$。所以折半查找的时间复杂度为 $O(log_2n)$，平均情况下比顺序查找的效率高。

在图 7.2 所示的判定树中，在等概率情况下，查找成功（圆形结点）的 $ASL=(1\times1+2\times2+3\times4+4\times4)/11=3$，查找不成功（方形结点）的 $ASL=(3\times4+4\times8)/12=11/3$。

因为折半查找需要方便地定位查找区域，所以它要求线性表必须具有随机存取的特性。因此，该查找法仅适合于顺序存储结构，不适合于链式存储结构，且要求元素按关键字有序排列。

#### 7.2.3 分块查找

分块查找又称索引顺序查找，它吸取了顺序查找和折半查找各自的优点，既有动态结构，又适于快速查找。

分块查找基本思想：将查找表分为若干子块。块内的元素可以无序，但块之间是有序的，即第一个块中的最大关键字小于第二个块中的所有记录的关键字，第二个块中的最大关键字小于第三个块中的所有记录关键字，以此类推。再建立一个索引表，索引表中的每个元素含有各块的最大关键字和各块中的第一个元素的地址，索引表按关键字有序排列。

分块查找的过程分为两步：第一步是在索引表中确定待查记录所在的块可以顺序查找或折半查找索引表；第二步是在块内顺序查找。

例如，关键码集合为 $\lbrace88,24,72,61,21,6,32,11,8,31,22,83,78,54\rbrace$，按照关键码值 $24,54,78,88$，分为 4 个块和索引表，如图 7.3 所示。

![分块查找示意图](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/85.png)

<center><font size="2">图7.3 分块查找示意图</font></center>

分块查找的平均查找长度为索引查找和块内查找平均长度之和。设索引查找和块内查找的平均查找长度分别为 $L_I$，$L_S$，则分块查找的平均查找长度为

$$
ASL=L_I+L_S
$$

将长度为 n 个查找表均匀地分为 b 块，每块有 s 个记录，在等概率情况下，若在块内和索引表中均采用顺序查找，则平均查找长度为

$$
ASL=L_I+L_S=\frac{b+1}2+\frac{s+1}2=\frac{s^2+2s+n}{2s}
$$

此时，若 $s= \sqrt n$，则平均查找长度取最小值 $\sqrt n+1$；若对索引表采用折半查找时，则平均查找长度为

$$
ASL=L_I+L_S=\lceil\log_2(b+1)\rceil+\frac{s+1}2
$$

### 7.3 树型查找

#### 7.3.1 二叉排序树（BST）

构造一棵二叉排序树的目的并不是为了排序，而是为了提高查找、插入和删除关键字速度，二叉排序树这种非线性结构也有利于插入和删除的实现。

**1. 二叉排序树的定义**

二叉排序树（也称二叉查找树）或者是一棵空树，或者是具有下列特性的二叉树：

1）若左子树非空，则左子树上所有结点的值均小于根结点的值。

2）若右子树非空，则右子树上所有结点的值均大于根结点的值。

3）左、右子树也分别是一棵二叉排序树。

根据二叉排序树的定义，左子树结点值 < 根结点值 < 右子树结点值，所以二叉排序树进行中序遍历，可以得到一个递增的有序序列。例如，图 5.21 所示二叉排序树的中序遍历序列为 1 2 3 4 6 8。

![一棵二叉排序树](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/50.png)

<center><font size=2>图5.21 一棵二叉排序树</font></center>

**2. 二叉排序树的查找**

二叉排序树的查找是从根结点开始，沿某个分支逐层向下比较的过程。若二叉排序树非空，先将给定值与根结点的关键字比较，若相等，则查找成功；若不等，如果小于根结点的关键字，则在根结点的左子树上查找，否则在根结点的右子树上查找。这显然是一个递归的过程。

二叉排序树的非递归查找算法：

```c
BSTNode *BST_Search(BiTree T, ElemType key){
  while(T !=NULL && key != T->data){			//若数空或等于根结点值，则结束循环
    if(key < T->data)
      T = T->lchild;											//小于，则在左子树上查找
    else
      T = T->rchild;											//大于，则在右子树上查找
  }
  return T;
}
```

例如，在图 5.21 查找值为 4 的结点。首先 4 与根结点 6 比较。由于 4 小于 6，所以在根结点 6 的左子树中继续查找。由于 4 大于 2，所以在结点 2 的右子树中查找，查找成功。

同样，二叉排序树的查找也可用递归算法实现，递归算法比较简单，但执行效率较低。具体的代码实现，留给读者思考。

**3. 二叉排序树的插入**

二叉排序树作为一种动态树表，其特点是树的结构通常不是一次生成的，而是在查找过程中，当树中不存在关键字值等于给定值的结点时再进行插入的。

插入结点的过程如下：若原二叉排序树为空，则直接插入结点；否则，若关键字 k 小于根结点值，则插入到左子树，若关键字 k 大于根结点值，则插入到右子树。插入的结点一定是一个新添加的叶结点，且是查找失败时的查找路径上访问的最后一个结点的左孩子或右孩子。如图 5.22 所示在一个二叉排序树中依次插入结点 28 和结点 58，虚线表示的边是其查找的路径。

![向二叉排序树中插入结点](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/51.png)

<center><font size=2>图5.22 向二叉排序树中插入结点</font></center>

二叉排序树插入操作的算法描述如下：

```c
int BST_Insert(BiTree &T, KeyType k){
  if(T == NULL){													//原树为空，新插入的记录为根结点
    T = (BiTree)malloc(sizeof(BSTNode));
    T->key = k;
    T->lchild = T->rchild = NULL;
    return 1;															//返回1，插入成功
  }
  else if(k == T->key)										//树中存在相同关键字结点，插入失败
    return 0;
  else if(k < T->key)											//插入到T的左子树
    return BST_Insert(T->lchild, k);
  else																		//插入到T的右子树
    return BST_Insert(T->rchild, k);
}
```

**4. 二叉排序树的构造**

从一棵空树出发，一次输入元素，将它们插入二叉排序树中的合适位置。设查找的关键字序列为{45, 24, 53, 45, 12, 24}，则生成的二叉排序树如图 5.23 所示。

![二叉排序树的构成过程](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/52.png)

<center><font size=2>图5.23 二叉排序树的构成过程</font></center>

构造二叉排序树的算法描述如下：

```c
void Creat_BST(BiTree &T, KeyType str[], int n){
  T = NULL;											//初始时T为空树
  int i = 0;
  while(i < n){									//依次将每个关键字插入到二叉排序树中
    BST_Insert(T, str[i]);
    i++;
  }
}
```

**5. 二叉排序树的删除**

在二叉排序树中删除一个结点时，不能把以该结点为根的子树上的结点都删除，必须先把被删除结点从存储二叉排序树的链表上摘下，将因删除结点而断开的二叉链表重新链接起来，同时确保二叉排序树的性质不会丢失。删除操作的实现过程按 3 种情况来处理：

① 若被删除结点 z 是叶结点，则直接删除，不会破坏二叉排序树的性质。

② 若结点 z 只有一棵左子树或右子树，则让 z 的子树成为 z 父结点的子树，替代 z 的位置。

③ 若结点 z 有左、右两棵子树，则令 z 的直接后继（或直接前驱）替代 z，然后从二叉排序树中删去这个直接后继（或直接前驱），这样就转换成了第一或第二种情况。

图 5.24 显示了在 3 种情况下分别删除结点 45, 78, 78 的过程。

![3种情况下的删除过程](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/53.png)

<center><font size=2>图5.24 3种情况下的删除过程</font></center>

**6. 二叉排序树的查找效率分析**

二叉排序树的查找效率，主要取决于树的高度。若二叉排序树的左、右子树的高度之差的绝对值不超过 1，则这样的二叉排序树称为平衡二叉树，它的平均查找长度为 $O(\log _2 n)$。若二叉排序树是一个只有右（左）孩子的单支树（类似于有序的单链表），则其平均查找长度为 $O(n)$。

![相同关键字组成不同二叉排序树](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/54.png)

<center><font size=2>图5.25 相同关键字组成不同二叉排序树</font></center>

在最坏情况下，即构造二叉排序树的输入序列是有序的，则会形成一个倾斜的单支树，此时二叉排序树的性能显著变坏，树的高度也增加为元素个数 n，如图 5.25(b) 所示。

在等概率情况下，图 5.25(a) 查找成功的平均查找长度为

$$
ASL_a=(1+2 \times 2+3 \times 4+4 \times 3)/10=2.9
$$

而图 5.25(b) 查找成功的平均查找长度为

$$
ASL_b=(1+2+3+4+5+6+7+8+9+10)/10=5.5
$$

从查找过程看，二叉排序树与二分查找相似。就平均时间性能而言，二叉排序树上的查找和二分查找差不多。但二分查找的判定树唯一，而二叉排序树的查找不唯一，相同的关键字其插入顺序不同可能生成不同的二叉排序树，如图 5.25 所示。

就维护表的有序性而言，二叉排序树无须移动结点，只需修改指针即可完成插入和删除操作，平均执行时间为 $O(\log_2n)$。二分查找的对象是有序顺序表，若有插入和删除结点的操作，所花的代价是 $O(n)$。当有序表是静态查找表时，宜用顺序表作为其存储结构，而采用二分查找实现其查找操作；若有序表是动态查找表，则应选择二叉排序树作为其存储结构。

#### 7.3.2 平衡二叉树

**1. 平衡二叉树的定义**

为避免树的高度增长过快，降低二叉排序树的性能，规定在插入和删除二叉树结点时，要保证任意结点的左、右子树高度差的绝对值不超过 1，将这样的二叉树称为平衡二叉树（Balanced Binary Tree），简称平衡树，AVL 树。定义结点左子树与右子树的高度差为该结点的平衡因子，则平衡二叉树结点的平衡因子的值只可能是-1、0 或 1。

因此，平衡二叉树可定义为或者是一棵空树，或者是具有下列性质的二叉树：它的左子树和右子树都是平衡二叉树，且左子树和右子树的高度差的绝对值不超过 1。图 5.26(a) 所示是平衡二叉树，图 5.26(b) 所示是不平衡的二叉树。结点中的值为该结点的平衡因子。

![平衡二叉树和不平衡二叉树](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/55.png)

<center><font size=2>图5.26 平衡二叉树和不平衡二叉树</font></center>

**2. 平衡二叉树的插入**

二叉排序树保证平衡的基本思想如下：每当在二叉排序树中插入（或删除）一个结点时，首先检查其插入路径上的结点是否因为此次操作而导致了不平衡。若导致了不平衡，则先找到插入路径上离插入结点最近的平衡因子的绝对值大于 1 的结点 A，再对以 A 为根的子树，在保持二叉排序树特性的前提下，调整各结点的位置关系，使之重新达到平衡。

**注意**：每次调整的对象都是最小不平衡子树，即以插入路径上离插入结点最近的平衡因子的绝对值大于 1 的结点作为根的子树。 图 5.27 中的虚线框内为最小不平衡子树。

![最小不平衡子树示意](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/56.png)

<center><font size=2>图5.27 最小不平衡子树示意</font></center>

平衡二叉树的插入过程的前半部分与二叉排序树相同，但在新结点插入后，若造成查找路径上的某个结点不再平衡，则需要做出相应的调整。可将调整的规律归纳为下列 4 种情况：

1）LL 平衡旋转（右单旋转）。由于在结点 A 的左孩子（L）的左子树（L）上插入了新结点，A 的平衡因子由 1 增至 2，导致以 A 为根的子树失去平衡，需要一次向右的旋转操作。将 A 的左孩子 B 向上旋转代替 A 成为根结点，将 A 结点向下旋转成为 B 的右子树的根结点，而 B 的原右子树则作为 A 结点的左子树。

如图 5.28 所示，结点旁的数值代表结点的平衡因子，而用方块表示相应结点的子树，下方数值代表该子树的高度。

![LL平衡旋转](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/57.png)

<center><font size=2>图5.28 LL平衡旋转</font></center>

2）RR 平衡旋转（左单旋转）。由于在结点 A 的右孩子（R）和右子树（R）上插入了新结点，A 的平衡因子由 -1 减至 -2，导致以 A 为根的子树失去平衡，需要一次向左的旋转操作。将 A 的右孩子 B 向左上旋代替 A 称为根结点，将 A 结点向左下旋转成为 B 的左子树的根结点，而 B 的原左子树则作为 A 结点的右子树，如图 5.29 所示。

![RR平衡旋转](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/58.png)

<center><font size=2>图5.29 RR平衡旋转</font></center>

3）LR 平衡旋转（先左后右双旋转）。由于在 A 的左孩子（L）的右子树（R）上插入新结点，A 的平衡因子由 1 增至 2，导致以 A 为根的子树失去平衡，需要进行两次旋转操作，先左旋转后右旋转。先将 A 结点的左孩子 B 的右子树的根结点 C 向左上旋转提升到 B 结点的位置，然后把该 C 结点向右上旋转提升到 A 结点的位置，如图 5.30 所示。

![LR平衡旋转](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/59.png)

<center><font size=2>图5.30 LR平衡旋转</font></center>

4）RL 平衡旋转（先右后左双旋转）。由于在 A 的右孩子（R）的左子树（L）上插入新结点，A 的平衡因子由 -1 减至 -2，导致以 A 为根的子树失去平衡，需要进行两次旋转操作，先右旋转后左旋转。先将 A 结点的右孩子 B 的左子树的根结点 C 向右上旋转提升到 B 结点的位置，然后把该 C 结点向左上旋转提升到 A 结点的位置，如图 5.31 所示。

![RL平衡旋转](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/60.png)

<center><font size=2>图5.31 RL平衡旋转</font></center>

**注意**：LR 和 RL 旋转时，新结点究竟是插入 C 的左子树还是插入 C 的右子树不影响旋转过程，而图 5.30 和图 5.31 中以插入 C 的左子树中为例。

假设关键字序列为 {15, 3, 7, 10, 9, 8}，通过该序列生成平衡二叉树的过程如图 5.32 所示。图 5.32(d) 插入 7 后导致不平衡，最小不平衡子树的根为 15，插入位置为其左孩子的右子树，故执行 LR 旋转，先左后右双旋转，调整后的结果如图 5.32(e) 所示。图 5.32(g) 插入 4—— 9 后导致不平衡，最小不平衡子树的根为 15，插入位置为其左孩子的左子树，故执行 LL 旋转，右单旋转，调整后的结果如图 5.32(h) 所示。图 5.32(i) 插入 8 后导致不平衡，最小不平衡子树的根为 7，插入位置为其右孩子的左子树，故执行 RL 旋转，先右后左双旋转，调整后的结果如图 5.32(j) 所示。

![RL平衡旋转](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/61.png)

<center><font size=2>图5.32 平衡二叉树的生成过程</font></center>

**3. 平衡二叉树的删除**

与平衡二叉树的插入操作类似，以删除结点 为例来说明平衡二叉树删除操作步骤：

1）用二叉排序树的方法对结点 w 执行删除操作。

2）若导致了不平衡，则从结点 w 开始相向上回溯，找到第一个不平衡的结点 z（即最小不平衡子树）；y 为结点 z 的高度最高的孩子结点；x 是结点 y 的最高的孩子结点。

3）然后对以 z 为根的子树进行平衡调整，其中 x、y 和 z 可能的位置有 4 种情况：

- y 是 z 的左孩子，x 是 y 的左孩子（LL，右单旋转）；
- y 是 z 的左孩子，x 是 y 的右孩子（LR，先左后右双旋转）；
- y 是 z 的右孩子，x 是 y 的右孩子（RR，左单旋转）；
- y 是 z 的右孩子，x 是 y 的左孩子（RL，先右后左双旋转）。

这四种情况与插入操作的调整方式一样。不同之处在于，插入操作仅需要对以 z 为根的子树进行平衡调整；而删除操作就不一样，先对以 z 为根子树进行平衡调整，如果调整后子树的高度减 1，则可能需要对 z 的祖先结点进行平衡调整，甚至回溯到根结点（导致树高减 1）。

以删除图 7.16(a) 的结点 32 为例，由于 32 为叶结点，直接删除即可，向上回溯找到第一个不平衡结点 44（即 z），z 的高度最高的孩子结点为 78（y），y 的高度最高的孩子结点为 50（x），满足 RL 情况，先右后左双旋转，调整后的结果如图 7.16(c) 所示。

![平衡二叉树的删除](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/115.png)

<center><font size=2>图7.16 平衡二叉树的删除</font></center>

**4. 平衡二叉树的查找**

在平衡二叉树上进行查找的过程与二叉排序树的相同。因此，在查找过程中，与给定值进行比较的关键字个数不超过树的深度。假设以 $n_h$ 表示深度为 h 的平衡树中含有的最少结点数。显然，有 $n_0=0$，$n_1=1$，$n_2=2$，并且有 $n_h=n_{h-1}+n_{h-2}+1$。可以证明，含有 n 个结点的平衡二叉树的最大深度为 $O(\log_2n)$，因此平衡二叉树的平均查找长度为 $O(\log_2n)$，如图 5.33 所示。

![结点个数n最少的平衡二叉树](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/62.png)

<center><font size=2>图5.33 结点个数n最少的平衡二叉树</font></center>

**注意**：该结论可用于求解给定结点数的平衡二叉树的查找所需的最多比较次数（或树的最大高度）。在含有 12 个结点的平衡二叉树中查找某个结点的最多比较次数是多少？

#### 7.3.3 红黑树

**1. 红黑树的定义**

为了保持 AVL 树的平衡性，插入和删除操作后，非常频繁地调整全树整体拓扑结构，代价较大。为此在 AVL 树的平衡标准上进一步放宽条件，引入了红黑树的结构。

一棵红黑树是满足如下红黑性质的二叉排序树：

① 每个结点或是红色，或是黑色的。

② 根结点是黑色的。

③ 叶结点（虚构的外部结点、NULL 结点）都是黑色的。

④ 不存在两个相邻的红结点（即红结点的父结点和孩子结点均是黑色的）。

⑤ 对每个结点，从该结点到任意一个叶结点的简单路径上，所含黑色结点数量相同。

与折半查找树和 B 树类似，为了便于对红黑树的实现和理解，引入了 n+1 个外部叶结点，以保证红黑树中每个结点（内部结点）的左、右孩子均非空。图 7.18 所示是一棵红黑树。

![一棵红黑树](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/116.png)

<center><font size=2>图7.18 一棵红黑树</font></center>

从某结点出发（不含该结点）到达一个叶结点的任意一个简单路径上的黑结点总数称为该结点的黑高（记为 bh），黑高的概念是由性质 ⑤ 确定的。根结点的黑高称为红黑树的黑高。

**结论 1：从根到叶结点的最长路径不大于最短路径的 2 倍。**

由性质 ⑤，当从根到任意一个叶结点的简单路径最短时，这条路径必然全由黑结点构成。由性质 ④，当某条路径最长时，这条路径必然是由黑结点和红结点相间构成的，此时红结点和黑结点的数量是相同。图 7.18 中的 6-2 和 6-15-18-20 就是这样的两条路径。

**结论 2：有 n 个内部结点的红黑树的高度 h ≤ 2log~2~(n+1)。**

**证明：**由结论 1 可知，从根到叶结点（不含叶结点）的任何一条简单路径上都至少有一半是黑结点，因此，根的黑高至少为 h/2，于是有 n ≥ 2^h/2^-1，即可求得结论。

可见，红黑树的 “适度平衡”，由 AVL 树的 “高度平衡”，降低到 “任意一个结点左右子树的高度，相差不超过 2 倍”，也降低了动态操作时调整的频率。对于一棵动态查找树，如果插入和删除操作比较少，查找操作比较多，采用 AVL 树比较合适，否则采用红黑树更合适。但由于维护这种高度平衡所付出的代价比获得的效益大得多，红黑树的实际应用更广泛，C++ 中的 map 和 set（Java 中的 TreeMap 和 TreeSet）就是用红黑树实现的。

**2. 红黑树的插入**

红黑树的插入过程和二叉查找树的插入过程基本类似，不同之处在于，在红黑树中插入新结点后需要进行调整（主要通过重新着色或旋转操作进行），以满足红黑树的性质。

**结论 3：新插入红黑树中的结点初始着为红色。**

假设新插入的结点初始着为黑色，那么这个结点所在的路径比其他路径多出一个黑结点（几乎每次插入都破坏性质 ⑤），调整起来也比较麻烦。如果插入的结点是红色的，此时所有路径上的黑结点数量不变，仅在出现连续两个红结点时才需要调整，而且这种调整也比较简单。

设结点 z 为新插入的结点。插入过程描述如下：

1）用二叉查找树插入法插入，并将结点 z 着为红色。若结点 z 的父结点是黑色的，无须做任何调整，此时就是一棵标准的红黑树。

2）如果结点 z 是根结点，将 z 着为黑色（树的黑高增 1），结束。

3）如果结点 z 不是根结点，并且 z 的父结点 z.p 是红色的，则分为下面三种情况，区别在于 z 的叔结点 y 的颜色不同，因 z.p 是红色的，插入前的树是合法的，根据性质 ② 和 ④，爷结点 z.p.p 必然存在且为黑色。性质 ④ 只在 z 和 z.p 之间被破坏了。

情况 1：z 的叔结点 y 是黑色的，且 z 是一个右孩子。

情况 2：z 的叔结点 y 是黑色的，且 z 是一个左孩子。

每棵子树 T~1~、T~2~、T~3~ 和 T~4~ 都有哦一个黑色根结点，且具有相同的黑高。

情况 1（LR，先左旋，再右旋），即 z 是其爷结点的左孩子的右孩子。先做一次左旋将此情形转变为情况 2（变为情况 2 后再做一次右旋），左旋后 z 和父结点 z.p 交换位置。因为 z 和 z.p 都是红色的，所以左旋操作对结点的黑高和性质 ⑤ 都无影响。

情况 2（LL，右单旋），即 z 是其爷结点的左孩子的左孩子。做一次右旋，并交换 z 的原父结点和原爷结点的颜色，就可以保持性质 ⑤，也不会改变树的黑高。这样，红黑树中也不再有连续两个红结点，结束。情况 1 和情况 2 的调整方式如图 7.19 所示。

![情况1和情况2的调整方式](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/117.png)

<center><font size=2>图7.19 情况1和情况2的调整方式</font></center>

若父结点 z.p 是爷结点 z.p.p 的右孩子，则还有两种对称的情况：RL（先右旋，再左旋）和 RR（左单旋），这里不再赘述。红黑树的调整方法和 AVL 树的调整方法有异曲同工之妙。

情况 3：如果 z 的叔结点 y 是红色。

情况 3（z 是左孩子或右孩子无影响），z 的父结点 z.p 和叔结点 y 都是红色的，因为爷结点 z.p.p 是黑色的，将 z.p 和 y 都着为黑色，将 z.p.p 着为红色，以在局部保持性质 ④ 和 ⑤。然后，把 z.p.p 作为新结点 z 来重复循环，指针 z 在树中上移两层。调整方式如图 7.20 所示。

![情况3的调整方式](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/118.png)

<center><font size=2>图7.20 情况3的调整方式</font></center>

若父结点 z.p 是爷结点 z.p.p 的右孩子，也还有两种对称的情况，不再赘述。

只要满足情况 3 的条件，就会不断循环，每次循环指针 z 都会上移两层，直到满足 2）（表示 z 上移到根结点）或情况 1 或情况 2 的条件。

可能的疑问：虽然插入的初始位置一定是红黑树的某个叶结点，但因为在情况 3 中，结点 z 存在不断上升的可能，所以对于三种情况，结点 z 都有存在子树的可能。

以图 7.21(a) 中的红黑树为例（虚线表示插入后的状态），先后插入 5、4 和 12 的过程如图 7.21 所示。插入 5，为情况 3，将 5 的父结点 3 和叔结点 10 着为黑色，将 5 的爷结点变为红色，此时因为 7 已是根，故又重着为黑色，树的黑高家 1，结束。插入 4，为情况 1 的对称情况（RL），此时特别注意虚构黑色空结点的存在，先对 5 做右旋；转变为情况 2 的对称情况（RR），交换 3 和 4 的颜色，再对 3 做左旋，结束。插入 12，父结点是黑色的，无须任何调整，结束。

![红黑树的插入过程](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/119.png)

<center><font size=2>图7.21 红黑树的插入过程</font></center>

**3. 红黑树的删除**

红黑树的插入操作容易导致连续的两个红结点，破坏性质 ④。而删除操作容易造成子树黑高的变化（删除黑结点会导致根结点到叶结点间的黑结点数量减少），破坏性质 ⑤。

删除过程也是先执行二叉查找树的删除方法。若待删结点有两个孩子，不能直接删除，而要找到该结点的中序后继（或前驱）填补，即右子树中最小的结点，然后转换为删除该后继结点。由于后继结点至多只有一个孩子，这样就转换为待删结点是终端结点或仅有一个孩子的情况。

最终，删除一个结点有以下两种情况：

- 待删结点只有右子树或左子树。

- 待删结点没有孩子。

1）如果待删结点只有右子树或左子树，则只有两种情况，如图 7.22 所示。

![只有右子树或左子树的删除情况](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/120.png)

<center><font size=2>图7.22 只有右子树或左子树的删除情况</font></center>

只有这两种情况存在。子树只有一个结点，且必然是红色，否则会破坏性质 ⑤。

2）如果待删结点没有孩子，若该结点是红色的，直接删除，无须做任何调整。

3）如果待删结点没有孩子，并且该结点是黑色的。假设待删结点为 y，x 是用来替换 y 的结点（注意，当 y 是终端结点时，x 是黑色的 NULL 结点）。删除 y 后将导致先前包含 y 的任何路径上的黑结点数量减 1，因此，y 的任何祖先都不再满足性质 ⑤，简单的修正办法就是将替换 y 的结点 x 视为还有额外一重黑色，定义为双黑结点。也就是说，如果将任何包含结点 x 的路径上的黑结点数量加 1，在此假设下，性质 ⑤ 得到满足，但破坏了性质 ①。于是，删除操作的任务就转化为将双黑结点恢复为普通结点。

分为以下四种情况，区别在于 x 的兄弟结点 w 及 w 的孩子结点的颜色不同。

情况 1：x 的兄弟结点 w 是红色的。

情况 1，w 必须有黑色左右孩子和父结点。交换 w 和父结点 x.p 的颜色，然后对 x.p 做一次左旋，而不会破坏红黑树的任何规则。现在，x 的新兄弟结点是旋转之前 w 的某个孩子结点，其颜色为黑色，这样，就将情况 1 转换为情况 2、3 或 4 处理。调整方式如图 7.23 所示。

![情况1的调整方式](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/121.png)

<center><font size=2>图7.23 情况1的调整方式</font></center>

情况 2：x 的兄弟结点 w 是黑色的，且 w 的右孩子是红色的。

情况 3：x 的兄弟结点 w 是黑色的，w 的左孩子是红色的，w 的右孩子是黑色的。

情况 2（RR，左单旋），即这个红结点是其爷结点的右孩子的右孩子。交换 w 和父结点 x.p 的颜色，把 w 的右孩子着为黑色，并对 x 的父结点 x.p 做一次左旋，将 x 变为单重黑色，此时不再破坏红黑树的任何性质，结束。调整方式如图 7.24 所示。

![情况2的调整方式](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/122.png)

<center><font size=2>图7.24 情况2的调整方式</font></center>

情况 3（RL，先右旋，再左旋），即这个红结点是其爷结点的右孩子的左孩子。交换 w 和其左孩子的颜色，然后对 w 做一次右旋，而不破坏红黑树的任何性质。现在，x 的新兄弟结点 w 的右孩子是红色的，这样就将情况 3 转换为了情况 2。调整方式如图 7.25 所示。

![情况3的调整方式](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/123.png)

<center><font size=2>图7.25 情况3的调整方式</font></center>

情况 4：x 的兄弟结点 w 是黑色的，且 w 的两个孩子结点都是黑色的。

情况 4 中，因 w 也是黑色的，故可从 x 和 w 上去掉一重黑色，使得 x 只有一重黑色而 w 变为红色。为了补偿从 x 和 w 中去掉的一重黑色，把 x 的父结点 x.p 额外着一层黑色，以保持局部的黑高不变。通过将 x.p 作为新结点 x 来循环，x 上升一层。如果是通过情况 1 进入情况 4 的，因为原来的 x.p 是红色的，将新结点 x 变为黑色，终止循环，结束。调整方式如图 7.26 所示。

![情况4的调整方式](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/124.png)

<center><font size=2>图7.26 情况4的调整方式</font></center>

若 x 是父结点 x.p 的右孩子，则还有四种对称的情况，处理方式类似，不再赘述。

归纳总结：在情况 4 中，因 x 的兄弟结点 w 及左右孩子都是黑色，可以从 x 和 w 中各提取一重黑色（以让 x 变为普通黑结点），不会破坏性质 ④，并把调整任务向上 “推” 给它们的父结点 x.p。在情况 1、2 和 3 中，因为 x 的兄弟结点 w 或 w 左右孩子中有红结点，所以只能在 x.p 子树内用调整和重新着色的方式，且不能改变 x 原根结点的颜色（否则向上可能破坏性质 ④）。情况 1 虽然可能会转换为情况 4，但因为新 x 的父结点 x.p 是红色的，所以执行一次情况 4 就会结束。情况 1、2 和 3 在各执行常数次的颜色改变和至多 3 次旋转后便终止。情况 4 可能重复执行的唯一情况，每执行一次指针 x 上升一层，至多 O(log~2~n) 次。

以图 7.27(a) 中的红黑树为例（虚线表示删除前的状态），依次删除 5 和 15 的过程如图 7.27 所示。删除 5，用虚构的黑色 NULL 结点替换，视为双黑 NULL 结点，为情况 1，交换兄弟结点 12 和父结点 8 的颜色，对 8 做一次左旋；转变为情况 4，从双黑 NULL 结点和 10 中各提取一重黑色（提取后，双黑 NULL 结点变为普通 NULL 结点，图中省略，10 变为红色），因原父结点 8 是红色，故将 8 变为黑色，结束，删除 15，为情况 3 的对称情况（LR），变换 8 和 10 的颜色，对 8 做左旋；转变为情况 2 的对称情况（LL），交换 10 和 12 的颜色（两者颜色一样，无变化），将 10 的左孩子 8 着为黑色，对 12 做右旋，结束。

![红黑树的删除过程](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/125.png)

<center><font size=2>图7.27 红黑树的删除过程</font></center>

### 7.4 B 树和 B+ 树

考研大纲对 B 树和 B+树的要求各不相同，重点在于考查 B 树，不仅要求理解 B 树的基本特点，还要求掌握 B 树的建立、插入和删除，而对 B+ 树则只考查基本概念。

#### 7.4.1 B 树及其基本操作

B 树，又称多路平衡查找树，B 树中所有结点的孩子个数的最大值称为 B 树的阶，通常用 m 表示。所谓 m 阶 B 树是所有结点的平衡因子均等于 0 的 m 路平衡查找树。一棵 m 阶 B 树或为空树，或为满足如下特性的 m 叉树：

1）树中每个结点至多有 m 棵子树，即至多含有 m-1 个关键字。

2）若根结点不是终端结点，则至少有两棵子树。

3）除根结点外的所有非叶结点至少有 $\lceil\frac m2\rceil$ 棵子树，即至少含有 $\lceil\frac m2\rceil-1$ 个关键字。

4）所有非叶结点的结构如下：

$$
\begin{array}
{|c|c|c|c|c|c|c|c|c|}\hline
{n}&{P_0}&{K_1}&{P_1}&{K_2}&{P_2}&{\dots}&{K_n}&{P_n}\\ \hline
\end{array}
$$

其中，$K_i(i=1,2,\cdots,n)$ 为结点的关键字，且满足 $K_1\lt K_2 \lt\cdots\lt K_n$；$P_i(i=0,1,\cdots,n)$ 为指向子树根结点的指针，且指针 $p_{i-1}$ 所指子树中所有结点的关键字均小于 $K_i$，$P_i$ 所指子树中所有结点的关键字均大于 $K_i$，$n(\lceil m/2\rceil-1\leq n\leq m-1)$ 为结点中关键字个数。

5）所有的叶结点都出现在同一层次上，并且不带信息（可以视为外部结点或类似于折半查找判定树的查找失败结点，实际上这些结点不存在指向这些结点的指针为空）。

B 树是所有结点平衡因子均等于 0 的多路平衡查找树。

图 7.4 所示的 B 树中所有结点的最大孩子树 m = 5，因此它是一棵 5 阶 B 树，在 m 阶 B 树中结点最多可以有 m 个孩子。可以借助该实例来分析上述性质：

![一棵5阶B树实例](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/86.png)

<center><font size="2">图7.4 一棵5阶B树实例</font></center>

1）结点的孩子个数等于该结点中关键字个数加 1。

2）如果根结点没有关键字就没有子树，此时 B 树为空；如果根结点有关键字，则其子树必然大于等于两棵，因为子树个数等于关键字个数加 1。

3）除根结点外的所有非终端结点至少有 $\lceil m/2\rceil=\lceil5/2\rceil=3$ 棵子树（即至少有 $\lceil m/2\rceil-1=\lceil5/2\rceil-1=2$ 个关键字），至多有 5 棵子树（即至多有 4 个关键字）。

4）结点中关键字从左到右递增有序，关键字两侧均有指向子树的指针，左边指针所指子树的所有关键字均小于该关键字，右边指针所指子树的所有关键字均大于该关键字。或者看成下层结点关键字总是落在由上层结点关键字所划分的区间内，如第二层最左结点的关键字划分成了 3 个区间：$(-\infty,5),(5,11),(11,+\infty)$，该结点 3 个指针所指子树关键字均落在这 3 个区间内。

5）所有叶结点均在第 4 层代表查找失败的位置。

**1. B 树的高度（磁盘存取次数）**

由下一节将得知，B 树中大部分操作所需的磁盘存取次数与 B 树的高度成正比。

下面来分析 B 树在不同情况下的高度。当然，首先应明确 B 树的高度不包括最后的不带任何信息的叶结点所处的那一层（有些书对 B 树的高度的定义中，包含最后的那一层）。

若 $n\geq1$，则对任意一棵包含 n 个关键字、高度为 h、阶数为 m 的 B 树：

1）因为 B 树中每个结点最多有 m 棵子树，m - 1 个关键字，所以在一棵高度为 h 的 m 阶 B 树中关键字的个数应满足 $n\leq(m-1)(1+m+m^2+\cdots+m^{h-1})=m^h-1$，因此有

$$
h\geq\log_m(n+1)
$$

2）若让每个结点中的关键字个数达到最少，则容纳同样多关键字的 B 树的高度达到最大。由 B 树的定义：第一层至少有 1 个结点；第二层至少有 2 个结点；除根结点外的每个非终端结点至少有 $\lceil m/2\rceil$ 棵子树，则第三层至少有 $2\lceil m/2\rceil$ 个结点……第 h + 1 层至少有 $2(\lceil m/2\rceil)^{h-1}$ 个结点，注意到第 h + 1 层是不包含任何信息的叶结点。对于关键字个数为 n 的 B 树，叶结点即查找不成功的结点为 n + 1，由此有 $n+1\geq2(\lceil m/2\rceil)^{h-1}$，即 $h\leq\log_{\lceil m/2\rceil}((n+1)/2)+1$。

例如，假设一棵 3 阶 B 树共有 8 个关键字则其高度范围为 $2\leq h\leq3.17$。

**2. B 树的查找**

在 B 树上进行查找与二叉查找树很类似，只是每个结点都是多个关键字的有序表，在每个结点上所作的不是两路分支决定，而是根据该结点的子树所做的多路分支决定。

B 树的查找包含两个基本操作：① 在 B 树中找结点；② 在结点内查找关键字由于 B 树常存储在磁盘上，因此前一个查找操作是在磁盘上进行的，而后一个查找操作是在内存中进行的，即在找到目标结点后，先将结点信息读入内存，然后在结点内采用顺序查找法或折半查找法。

在 B 树上查找到某个结点后，先在有序表中进行查找，若找到则查找成功，否则按照对应的指针信息到所指的子树中去查找（例如在图 7.4 中查找关键字 42，首先从根结点开始，根结点只有一个关键字，且 42 > 22，若存在，必在关键字 22 的右边子树上，右孩子结点有两个关键字，而 36 < 42 < 45，则若存在，必在 36 和 45 中间的子树上，在该结点中查到关键字 42，查找成功）。查找到叶结点时（对应指针为空指针），则说明树中没有对应的关键字，查找失败。

**3. B 树的插入**

与二叉查找树的插入操作相比，B 树的插入操作要复杂得多。在二叉查找树中，仅需查找到需插入的终端结点的位置。但是，在 B 树中找到插入的位置后，并不能简单地将其添加到终端结点中，因此此时可能会导致整棵树不再满足 B 树定义中的要求。将关键字 key 插入 B 树的过程如下：

1）定位。利用前述的 B 树查找算法，找出插入该关键字的最低层中的某个非叶结点（在 B 树中查找 key 时，会找到表示查找失败的叶结点，这样就确定了最底层非叶结点的插入位置。注意：插入位置一定是最低层中的某个非叶结点）。

2）插入。在 B 树中，每个非失败结点的关键字个数都在区间 $[\lceil m/2\rceil-1,m-1]$ 内。插入后的结点关键字个数小于 m，可以直接插入；插入后检查被插入结点内关键字的个数，当插入后的结点关键字个数大于 m - 1 时，必须对结点进行分裂。

分裂的方法是：取一个新结点，在插入 key 后的原结点，从中间位置（$\lceil m/2\rceil$）将其中的关键字分为两部分，左部分包含关键字放在原结点中，右部分包含关键字放到新结点中，中间位置（$\lceil m/2\rceil$）的结点插入原结点的父结点。若此时导致其父结点关键字个数也超过了上限，则继续进行这种分裂操作，直至这个过程传到根结点位置，进到导致 B 树高度增 1。

对于 m = 3 的 B 树，所有结点中最多有 m - 1 = 2 个关键字，若某结点中已有两个关键字，则结点已满，如图 7.5(a) 所示。插入一个关键字 60 后，结点内的关键字个数超过了 m - 1，如图 7.5(b) 所示，此时必须进行结点分裂分裂的结果如图 7.5(c) 所示。

![结点的“分裂”示意](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/87.png)

<center><font size="2">图7.5 结点的“分裂”示意</font></center>

**4. B 树的删除**

B 树中的删除操作与插入操作类似，但要稍微复杂一些，即要使得删除后的结点中的关键字个数 $\geq\lceil m/2\rceil-1$，因此将涉及结点的 “合并” 问题。

当被删关键字 k 不在终点结点（最低层非叶结点）中国时可以用 k 的前驱（或后继）k‘ 来替代 k，然后在相应结点中删除 k'，关键字 k' 必定落在某个终端结点中，则转换成被删关键字在终端结点中的情形。在 图 7.6 的 4 阶 B 树中，删除关键字 80，用其前驱 78 替代，然后在终端结点中删除 78.因此只需讨论删除终端结点中关键字的情形。

![B树中删除非终端结点关键字的取代](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/88.png)

<center><font size="2">图7.6 B树中删除非终端结点关键字的取代</font></center>

当被删关键字在终端结点（最低层非叶结点）中时有下列三种情况：

1）直接删除关键字。若被删除关键字所在结点的关键字个数 $\geq\lceil m/2\rceil$，表明删除该关键字后仍满足 B 树的定义，则直接删去该关键字。

2）兄弟够借。若被删除关键字所在结点删除前关键字个数 $=\lceil m/2\rceil-1$，且与此结点相邻的右（或左）兄弟结点的关键字个数 $\geq\lceil m/2\rceil$，则需要调整该结点、右（或左）兄弟结点及其双亲结点（父子换位法），以达到新的平衡。在图 7.7(a) 中删除 4 阶 B 树的关键字 65，右兄弟关键字个数 $\geq\lceil m/2\rceil=2$，将 71 取代原 65 的位置，将 74 调整到 71 的位置。

![B树中删除终端结点关键字的示意图](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/89.png)

<center><font size="2">图7.7 B树中删除终端结点关键字的示意图</font></center>

3）兄弟不够借。若被删除关键字所在结点删除前的关键字个数 $=\lceil m/2\rceil-1$，且此时与该结点相邻的左、右兄弟结点的关键字个数均 $=\lceil m/2\rceil-1$，则将关键字删除后与左或右）兄弟结点及双亲结点中的关键字进行合并。在图 7.7(b) 中删除 4 阶 B 树的关键字 5，它及其右兄弟结点的关键字个数 $=\lceil m/2\rceil-1=1$，故在 5 删除后将 60 合并到 65 结点中。

在合并过程中，双亲结点中的关键字个数会减 1。若其双亲结点是根结点且关键字个数减少至 0（根结点关键字个数为 1 时，有 2 棵子树），则直接将根结点删除，合并后的新结点成为根；若双亲结点不是根结点，且关键字个数减少到 $\lceil m/2\rceil-2$，则又要与它自己的兄弟结点进行调整或合并操作，并重复上述步骤，直至符合 B 树的要求为止。

#### 7.4.2 B+ 树的基本概念

B+树是应数据库所需而出现的一种 B 树的变形树。

一棵 m 阶的 B+ 树需满足下列条件：

1）每个结点最多有 m 棵子树（孩子结点）。

2）非叶根结点至少有两棵子树，其他每个分支结点至少有 $\lceil m/2\rceil$ 棵子树。

3）结点的子树个数与关键字个数相等。

4）所有叶结点包含全部关键字及其指向相应记录的指针，叶结点中将关键字按大小顺序排列，并且相邻叶结点按大小顺序相互链接起来。

5）所有分支结点（可视为索引的索引）中仅包含它的各个结点（即下一级的索引块）中关键字的最大值及指向其子结点的指针。

m 阶的 B+ 树与 m 阶的 B 树主要差异如下：

1）在 B+树中，具有 n 个关键字的结点只含有 n 棵子树，即每个关键字对应一棵子树；而在 B 树中，具有 n 个关键字的结点含有 n+1 棵子树。

2）在 B+ 树中，每个结点（非根内部结点）的关键字个数 n 的范围是 $\lceil m/2\rceil\leq n\leq m$（根结点：$1\leq n\leq m$）；在 B 树中，每个结点（非根内部结点）的关键字个数 n 的范围是 $\lceil m/2\rceil=1\leq n\leq m-1$（根结点：$1\leq n\leq m-1$）。

3）在 B+ 树中，叶结点包含信息，所有非叶结点仅起索引作用非叶结点中的每个索引项只含有对应子树的最大关键字和指向该子树的指针，不含有该关键字对应记录的存储地址。

4）在 B+树中，叶结点包含了全部关键字即在非叶结点中出现的关键字也会出现在叶结点中；而在 B 树中，叶结点（最外层内部结点）包含的关键字是不重复的。

图 7.8 所示为一棵 4 阶 B+ 树。可以看出，分支结点的某个关键字是其子树中最大关键字的副本。通常在 B+树中有两个头指针：一词个指向根结点，另一个指向关键字最小的叶结点。因此，可以对 B+ 树进行两种查找运算：一种是从最小关键字开始的顺序查找，另一种是从根结点开始的多路查找。

![B+树结构示意图](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/90.png)

<center><font size="2">图7.8 B+树结构示意图</font></center>

B+ 树的查找、插入和删除操作和 B 树的基本类似。只是在查找过程中，非叶结点上的关键字值等于给定值时并不终止，而是继续向下查找，直到叶结点上的该关键字为止。所以，在 B+ 树中查找时，无论查找成功与否，每次查找都是一条从根结点到叶结点的路径。

### 7.5 散列表

#### 7.5.1 散列表的基本概念

在前面介绍的线性表的树表的查找中，记录在表中的位置与记录的关键字之间不存在确定关系，因此，在这些表中查找记录时需进行一系列的关键字比较。这类查找方法建立在 “比较” 的基础上，查找的效率取决于比较次数。

散列函数：一个把查找表中的关键字映射成该关键字对应的地址的函数，记为 $Hash(key)=Addr$（这里地址可以是数组下标、索引或内存地址等）。

散列函数可能会把两个或两个以上的不同关键字映射到同一地址，称这种情况为冲突，这些发生碰撞的不同关键字称为同义词。一方面，设计得好的散列函数应尽量减少这样的冲突；另一方面，由于这样的冲突总是不可避免的，所以还要设计好处理冲突方法。

散列表：根据关键字而直接进行访问的数据结构。也就是说，散列表建立了关键字和存储地址直接的一种直接映射关系。

理想情况下，对散列表进行查找时间复杂度为 $O(1)$ 即与表中元素的个数无关。下面分别介绍常用的散列函数和处理冲突的方法。

#### 7.5.2 散列函数的构造方法

在构造散列函数时，必须注意以下几点：

1）散列函数的定义域必须包含全部需要存储的关键字，而值域的范围则依赖于散列表的大小或地址范围。

2）散列函数计算出来的地址应该能等概率、均匀地分布在整个地址空间中，从而减少冲突发发生。

3 散列函数应尽量简单，能够在较短的时间内计算出任一关键字对应的散列地址。

**1. 直接定址法**

直接取关键字某个线性函数值为散列地址，散列函数为

$$
H(key)=key\quad或\quad H(key)=a\times key+b
$$

式中，a 和 b 是常数。这种方法计算最简单，且不会产生冲突。它适合关键字分布基本连续的情况，若关键字分布不连续，空位较多，则会造成存储空间的浪费。

**2. 除留余数法**

这是一种最简单、最常用的方法，假定散列表表长为 m，取一个不大于 m 但最接近或等于 m 的质数 p，利用以下公式把关键字转换成散列地址。散列函数为

$$
H(key)=key\%p
$$

除留余数法的关键是选好 p，使得每个关键字通过该函数转换后等概率地映射到散列空间上的任一地址，从而尽可能减少冲突的可能性。

**3. 数字分析法**

设关键字是 r 进制数（如十进制数），而 r 个数码在各位上出现的频率不一定相同，可能在某些位上分布均匀一些每种数码出现的机会均等；而在某些位上分布不均匀，只有某几种数码经常出现，此时应选取数据分布较为均匀的若干位作为散列地址。这种方法适合于已知的关键字集合，若更换了关键字，则需要重新构造新的散列函数。

**4. 平方取中法**

顾名思义，这种方法取关键字的平方值的中间几位作为散列地址。具体取多少位要视实际情况而定。这种方法得到的散列地址与关键字的每个都有关系，因此使得散列地址分布比较均匀。适用于关键字每位取值都不够均匀或均小于散列地址所需的位数。

在不同的情况下，不同的散列函数具有不同的性能，因此不能笼统地说哪种散列函数最好。在实际选择中，采用何种构造散列函数的方法取决于关键字集合的情况，但目标是尽量降低产生冲突的可能性。

#### 7.5.3 处理冲突方法

应该注意到，任何设计出来的散列函数都不可能绝对地避免冲突为此，必须考虑在发生冲突时应该如何处理，即为产生冲突的关键字寻找下一个 “空” 的 Hash 地址。用 $H_i$ 表示处理冲突中第 $i$ 次探测得到的散列地址，假设得到的另一个散列地址 $H_1$ 仍然发生冲突，只得继续求下一个地址 $H_2$，以此类推直到 $H_k$ 不发生冲突为止，则 $H_k$ 为关键字在表中的地址。

**1. 开放定址法**

所谓开放定址法，是指可存放新表项的空闲地址既向它的同义词表项开放，又向它的非同义词表项开放。其数学递推公式为

$$
H_i=(H(key)+d_i)\% m
$$

式中，$H(key)$ 为散列函数；$i=0,1,2\cdots,k(k\leq m-1)$；$m$ 表示散列表表长；$d_i$为增量序列。

取定某一增量序列后，对应的处理方法就是确定的。通常有以下 4 种取法：

1）线性探测法。当 $d_i=0,1,2,\cdots,m-1$ 时，称为线性探测法。这种方法的特点是：冲突发生时，顺序查看表中下一个单元（探测到表尾地址 m-1 时，下一个探测地址是表首地址 0），直到找出一个空闲单元（当表未填满时一定能找到一个空闲单元）或查遍全表。

线性探测法可能使第 i 个散列地址的同义词存入第 i+1 个散列地址这样本应存入第 i+1 个散列地址的元素就争夺第 i+2 个散列地址的元素地址……从而造成大量元素在相邻的散列地址上 “聚集”（或堆积）起来，大大降低了查找效率。

2）平方探测法。当 $d_i=0^2,1^2,-1^2,2^2,-2^2,\cdots,k^2,-k^2$ 时，称为平方探测法，其中 $k\leq m/2$，散列表长度 m 必须是一个可以表示成 4k+3 的素数，又称二次探测法。

平方探测法是一种处理冲突的较好方法，可以避免出现 “堆积” 问题，它的缺点是不能探测到散列表上所有单元，但至少能探测到一半单元。

3）再散列法。当 $d+i=Hash_2(key)$ 时，称为再散列法，又称双散列法。需要使用两个散列函数，当通过第一个散列函数 $H(key)$得到的地址发生冲突时，则利用第二个散列函数 $Hash_2(key)$ 计算该关键字的地址增量。它的具体散列函数形式如下：

$$
H_i=(H(key)+i\times Hash_2(key))\%m
$$

初始探测位置 $H_0=H(key)\%m$。i 是冲突的次数，初始为 0。在再散列法中，最多经过 m-1 次探测就会遍历表中所有位置，回到 $H_0$ 位置。

4）伪随机序列法。当 $d_i=$ 伪随机序列时，称为伪随机序列法。

**注意**：在开放定址的情形下，不能随便物理删除表中的已有元素，因为若删除元素，则会截断其他具有相同散列地址的元素查找地址。因此，要删除一个元素时，可给它做一个删除标记，进行逻辑删除。但这样做的副作用是：执行多次删除后，表面上看起来散列表很满实际上有许多位置未利用，因此需要定期维护散列表，要把删除标记的元素物理删除。

**2. 拉链法（链接法，chaining）**

显然，对于不同的关键字可能会通过散列函数映射到同一地址，为了避免非同义词发生冲突，可以把所有的同义词存储在一个线性链表中，这个线性链表由其散列地址唯一标识。假设散列地址为 i 的同义词链表的头指针存放在散列表第 i 个单元中，因而查找、插入和删除操作主要在同义词链中进行。拉链法适用于经常进行插入和删除的情况。

例如，关键字序列为 $\lbrace19,14,23,01,68,20,84,27,55,11,10,79\rbrace$，散列函数 $H(key)=key\%13$，用拉链法处理冲突，建立的表如图 7.9 所示（学完下节内容后，可以尝试计算本例的平均查找长度 ASL）。

![拉链法处理冲突的散列表](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/91.png)

<center><font size="2">图7.9 拉链法处理冲突的散列表</font></center>

#### 7.5.4 散列查找及性能分析

散列表的查找过程与构造散列表的过程基本一致。对于一个给定的关键字 key，根据散列函数可以计算出散列地址，执行步骤如下：

初始化：$Addr=Hash(key)$；

① 检测查找表中地址为 Addr 的位置上是否有记录，若无记录，返回**查找失败**；若有记录，比较它与 key 的值，若相等，则返回\**查找成功*的标志，否则执行步骤 ②。

② 用给定的处理冲突方法计算 “下一个散列地址”，并把 Addr 置为此地址，转入步骤 ①。

例如，关键字序列 $\lbrace19,14,23,01,68,20,84,27,55,11,10,79\rbrace$ 按散列函数 $H(key)=key\%13$ 和线性探测处理冲突构造所得的散列表 L 如图 7.10 所示。

<div style="display: flex;line-height: 40px;width: 600px;text-align: center;margin: 0 auto;">
	<span style="flex: 1">0</span>
	<span style="flex: 1">1</span>
  <span style="flex: 1">2</span>
  <span style="flex: 1">3</span>
  <span style="flex: 1">4</span>
  <span style="flex: 1">5</span>
  <span style="flex: 1">6</span>
  <span style="flex: 1">7</span>
  <span style="flex: 1">8</span>
	<span style="flex: 1">9</span>
  <span style="flex: 1">10</span>
  <span style="flex: 1">11</span>
  <span style="flex: 1">12</span>
  <span style="flex: 1">13</span>
  <span style="flex: 1">14</span>
  <span style="flex: 1">15</span>
</div>
<div style="display: flex;line-height: 40px;width: 600px;text-align: center;margin: 0 auto;">
  <span style="border: 1px solid #000; border-right: 0px; flex: 1"></span>
  <span style="border: 1px solid #000; border-right: 0px; flex: 1">14</span>
  <span style="border: 1px solid #000; border-right: 0px; flex: 1">01</span>
  <span style="border: 1px solid #000; border-right: 0px; flex: 1">68</span>
  <span style="border: 1px solid #000; border-right: 0px; flex: 1">27</span>
  <span style="border: 1px solid #000; border-right: 0px; flex: 1">55</span>
  <span style="border: 1px solid #000; border-right: 0px; flex: 1">19</span>
  <span style="border: 1px solid #000; border-right: 0px; flex: 1">20</span>
  <span style="border: 1px solid #000; border-right: 0px; flex: 1">84</span>
  <span style="border: 1px solid #000; border-right: 0px; flex: 1">79</span>
  <span style="border: 1px solid #000; border-right: 0px; flex: 1">23</span>
  <span style="border: 1px solid #000; border-right: 0px; flex: 1">11</span>
  <span style="border: 1px solid #000; border-right: 0px; flex: 1">10</span>
  <span style="border: 1px solid #000; border-right: 0px; flex: 1"></span>
  <span style="border: 1px solid #000; border-right: 0px; flex: 1"></span>
  <span style="border: 1px solid #000; flex: 1"></span>
</div>
<center><font size=2>图7.10 用线性探测法得到的散列表L</font></center>

给定值 84 的查找过程为：首先求得散列地址 $H(84)=6$，因 $L[6]$ 不空且 $L[6]\neq84$，则找第一次冲突处理后的地址 $H_1=(6+1)\%16=7$，而 $L[7]$ 不空且 $L[7]\neq84$，则找第二次冲突处理后的地址 $H_2=(6+2)\%16=8$，$L[8]$ 不空且 $L[8]=84$，查找成功，返回记录在表中的序号 8。

给定值 38 的查找过程为：先求散列地址 $H(38)=12$，$L[12]$ 不空且 $L[12]\neq38$，找下一个地址 $H_1=(12+1)\%16=13$，由于 $L[13]$ 是空记录，故表中不存在关键字为 38 的记录。

查找各关键字的比较次数如图 7.11 所示。

<div style="display: flex;line-height: 40px;width: 600px;text-align: center;margin: 0 auto;">
  <span style="border: 1px solid #000; border-right: 0px; flex: 2">关键字</span>
  <span style="border: 1px solid #000; border-right: 0px; flex: 1">14</span>
  <span style="border: 1px solid #000; border-right: 0px; flex: 1">01</span>
  <span style="border: 1px solid #000; border-right: 0px; flex: 1">68</span>
  <span style="border: 1px solid #000; border-right: 0px; flex: 1">27</span>
  <span style="border: 1px solid #000; border-right: 0px; flex: 1">55</span>
  <span style="border: 1px solid #000; border-right: 0px; flex: 1">19</span>
  <span style="border: 1px solid #000; border-right: 0px; flex: 1">20</span>
  <span style="border: 1px solid #000; border-right: 0px; flex: 1">84</span>
  <span style="border: 1px solid #000; border-right: 0px; flex: 1">79</span>
  <span style="border: 1px solid #000; border-right: 0px; flex: 1">23</span>
  <span style="border: 1px solid #000; border-right: 0px; flex: 1">11</span>
  <span style="border: 1px solid #000; flex: 1">10</span>
</div>
<div style="display: flex;line-height: 40px;width: 600px;text-align: center;margin: 0 auto;">
  <span style="border: 1px solid #000; border-right: 0px; border-top: 0px; flex: 2">比较次数</span>
  <span style="border: 1px solid #000; border-right: 0px; border-top: 0px; flex: 1">1</span>
  <span style="border: 1px solid #000; border-right: 0px; border-top: 0px; flex: 1">2</span>
  <span style="border: 1px solid #000; border-right: 0px; border-top: 0px; flex: 1">1</span>
  <span style="border: 1px solid #000; border-right: 0px; border-top: 0px; flex: 1">4</span>
  <span style="border: 1px solid #000; border-right: 0px; border-top: 0px; flex: 1">3</span>
  <span style="border: 1px solid #000; border-right: 0px; border-top: 0px; flex: 1">1</span>
  <span style="border: 1px solid #000; border-right: 0px; border-top: 0px; flex: 1">1</span>
  <span style="border: 1px solid #000; border-right: 0px; border-top: 0px; flex: 1">3</span>
  <span style="border: 1px solid #000; border-right: 0px; border-top: 0px; flex: 1">9</span>
  <span style="border: 1px solid #000; border-right: 0px; border-top: 0px; flex: 1">1</span>
  <span style="border: 1px solid #000; border-right: 0px; border-top: 0px; flex: 1">1</span>
  <span style="border: 1px solid #000; border-top: 0px; flex: 1">3</span>
</div>
<center><font size=2>图7.11 查找各关键字的比较次数</font></center>

平均查找长度 ASL 为

$$
ASL=(1\times6+2+3\times3+4+9)/12=2.5
$$

对同一组关键字，设定相同的散列函数，则不同的处理冲突的方法得到的散列表不同，它们的平均查找长度也不同，本例与上节采用拉链法的平均查找长度不同。

从散列表的查找过程可见：

（1）虽然散列表在关键字与记录的存储位置之间建立了直接映像，但由于 “冲突” 的产生，使得散列表的查找过程仍然是一个给定值和关键字进行比较的过程。因此，仍需要以平均查找长度作为衡量散列表的查找效率的衡量。

（2）散列表的查找效率取决于三个因素：散列函数、处理冲突的方法和装填因子。

装填因子。散列表的装填因子一般记为 $\alpha$，定义为一个表的装满程度。即

$$
\alpha=\frac{表中记录数n}{散列表长度m}
$$

散列表的查找长度依赖于散列表的装填因子 $\alpha$，而不直接依赖于 n 或 m。直观地看，$\alpha$ 越大， 表示装填的记录越 “满”，发生冲突的可能性越大，反之发生冲突的可能性越小。

读者应能在给出散列表的长度、元素个数及散列函数和解决冲突的方法后，在求出散列表的基础上计算出查找成功时的平均查找长度和查找不成功的平均查找长度。

## 第 8 章 排序

```mermaid
graph LR
H[第8章 排序]--> HA[基本概念]
HA --> HAA[稳定性]
HA --> HAB["衡量标准：时、空复杂度"]
H --> HB[内部排序]
HB --> HBA[插入排序]
HBA --> HBAA[直接插入排序]
HBA --> HBAB[折半插入排序]
HBA --> HBAC[希尔排序]
HB --> HBB[交换排序]
HBB --> HBBA[冒泡排序]
HBB --> HBBB[快速排序]
HB --> HBC[选择排序]
HBC --> HBCA[简单选择排序]
HBC --> HBCB[堆排序]
HB --> HBD[归并排序]
HB --> HBE[基数排序]
H --> HC["外部排序——多路归并排序"]
```

### 8.1 排序的基本概念

#### 8.1.1 排序的定义

排序，就是重新排列表中的元素，使表中的元素满足按关键字有序的过程。为了查找方便，通常希望计算机中的表是按关键字有序的。排序的确切定义如下：

输入：n 个记录 $R_1，R_2,\cdots,R_n$，对应的关键字为 $k_1,k_2,\cdots,k_n$。

输出：输入序列的一个重排 $R_1',R_2',\cdots,R_n'$，使得 $k_1'\leq k_2'\leq\cdots\leq k_n'$（其中 “$\leq$” 可以换成其他的比较大小的符号）。

算法的稳定性。若待排序表中有两个元素 $R_i$ 和 $R_j$，其对应的关键字相同即 $key_i=key_j$，且在排序前 $R_i$ 在 $R_j$ 的前面，若使用某一排序算法排序后，$R_i$ 仍然在 $R_j$ 的前面则称这个排序算法是稳定的，否则称排序算法是不稳定的。需要注意是，算法是否具有稳定性并不能衡量一个算法优劣，它主要是对算法的性质进行描述。如果待排序表中的关键字不允许重复，则排序结果是唯一的，那么选择排序算法时的稳定与否就无关紧要。

**注意**：对于不稳定的排序算法，只需举出一组关键字的实例，说明它的不稳定性即可。

在排序过程中，根据数据元素是否完全在内存中，可将排序算法分为两类：① 内部排序，是指在排序期间元素全部存放在内存中的排序；② 外部排序，是指在排序期间元素无法全部同时存放在内存中，必须在排序的过程中根据要求不断地在内、外存之间移动的排序。

一般情况下，内部排序算法在执行过程中都要进行两种操作：比较和移动。通过比较两个关键字的大小，确定对应元素的前后关系，然后通过移动元素以达到有序。当然，并非所有的内部排序算法都要基于比较操作，事实上，基数排序就不基于比较。

每种排序算法都有各自优缺点，适合在不同环境下使用，就其全面性能而言，很难提出一种被认为是最好算法通常可以将排序算法分为插入排序、交换排序、选择排序、归并排序和基数排序五大类，后面几节会分别进行详细介绍。内部排序算法的性能取决于算法的时间复杂度和空间复杂度，而时间复杂度一般是由比较和移动的次数决定的。

### 8.2 插入排序

插入排序是一种简单直观的排序方法，其基本思想是每次将一个待排序的记录按其关键字大小插入前面已排好序的子序列，直到全部记录插入完成。由插入排序的思想可以引申出三个重要的排序算法：直接插入排序、折半插入排序和希尔排序。

#### 8.2.1 直接插入排序

<font size=2>凡在书中未加特殊说明的，通常默认排序结果为非递减有序序列。</font>

根据上面的插入排序思想，不难得出一种最简单也最直接插入排序算法。假设在排序过程中，待排序表 $L[1\dots n]$ 在某次排序过程中的某一时刻状态如下：

$$
\begin{array}
{|c|c|c|}\hline
{有序序列L[1\dots i-1]}&{L(i)}&{无序序列L[i+1\dots n]}\\ \hline
\end{array}
$$

要将元素 $L(i)$ 插入已有序的子序列 $L[1\dots i-1]$，需要执行以下操作（为避免混淆，下面用 $L[]$ 表示一个表，而用 $L()$ 表示一个元素）：

1）查找出 $L(i)$ 在 $L[1\dots i-1]$ 中的插入位置 $k$。

2）将 $L[k\dots i-1]$ 中的所有元素依次后移一个位置。

3）将 $L(i)$ 复制到 $L(k)$。

为了实现对 $L[1\dots n]$ 的排序，可以将 $L(2)$ ~ $L(n)$ 依次插入前面已排好序的子序列，初始 $L[1]$ 可以视为是一个已排好序的子序列。上述操作执行 n-1 次就能得到一个有序的表。插入排序在实现上通常采用就地排序（空间复杂度为 $O(1)$），因而在从后向前的比较过程中，需要反复把已排序元素逐步向后挪位，为新元素提供插入空间。

下面是直接插入排序的代码，其中再次用到了我们前面提到的 “哨兵”（作用相同）。

```c
void InsertSort(ElemType A[], int n){
  int i, j;
  for(i=2; i<=n; i++)             //依次将A[2]~A[n]插入前面已排序序列
    if(A[i]<A[i-1]){              //若A[i]关键码小于其前驱，将A[i]插入有序表
      A[0] = A[i];                //复制为哨兵，A[0]不存放元素
      for(j=i-1; A[0]<A[j]; --j)  //从后往前查找待插入位置
        A[j+1] = A[j];            //向后挪位
      A[j+1] = A[0];              //复制到插入位置
    }
}
```

假定初始序列为 $49,38,65,97,76,13,27,\overline{49}$，初始时 49 可以视为一个已排好序的子序列，按照上述算法进行直接插入排序的过程如图 8.1 所示，括号内是已排好序的子序列。

![直接插入排序示例](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/92.png)

<center><font size="2">图8.1 直接插入排序示例</font></center>

直接插入排序算法的性能分析如下：

空间效率：仅使用了常数个辅助单元，因而空间复杂度为 $O(1)$。

时间效率：在排序过程中，向有序子表中逐个地插入元素的操作进行了 n-1 趟，每趟操作都分为比较关键字和移动元素，而比较次数和移动次数取决于待排序表的初始状态。

在最好情况下，表中元素已经有序，此时每插入一个元素，都只需比较一次而不用移动元素，因而时间复杂度为 $O(n)$。

最坏情况下，表中元素顺序刚好与排序结果中的元素顺序相反（逆序），总的比较次数达到最大，总移动次数也达到最大。

平均情况下，考虑待排序表中元素是随机的此时可以取上述最好与最坏情况的平均值作为平均情况下的时间复杂度，总的比较次数与总的移动次数均约为 $\frac{n^2}4$。

因此，直接插入排序算法的时间复杂度为 $O(n^2)$。

稳定性：由于每次插入元素时总是从后向前比较再移动，所以不会出现相同元素相对位置发生变化的情况，即直接插入排序是一个稳定的排序方法。

适用性：直接插入排序算法适用于顺序存储和链式存储的线性表。为链式存储时，可以从前往后查找指定元素的位置。

**注意**：大部分排序算法都仅适用于顺序存储的线性表。

#### 8.2.2 折半插入排序

从直接插入排序算法中，不难看出每趟插入的过程中都进行两项工作：① 从前面的有序子表中查找出待插入元素应该被插入的位置；② 给插入位置腾出空间，将待插入元素复制到表中的插入位置。注意到该算法中，总是边比较移动元素。下面将比较和移动操作分离即先折半查找出元素的待插入位置，然后统一地移动待插入位置之后的所有元素。当排序表为顺序表时，可以对直接插入排序算法做如下改进：由于是顺序存储的线性表所以查找有序子表时可以用折半查找来实现。确定待插入位置后，就可统一地向后移动元素。算法代码如下：

```c
void InsertSort(ElemType A[], int n){
  int i, j, low, high, mid;
  for(i=2; i<=n; i++){          //依次将A[2]~A[n]插入前面的已排序序列
    A[0] = A[i];                //将A[i]暂存到A[0]
    low = 1; high = i-1;        //设置折半查找的范围
    while(low <= high){         //折半查找（默认递增有序）
      mid = (low+high)/2;       //取中间点
      if(A[mid] > A[0])
        high = mid - 1;         //查找左半子表
      else
        low = mid + 1;          //查找右半子表
    }
    for(j=i-1; j>=high+1; --j)
      A[j+1] = A[j];            //统一后移元素，空出插入位置
    A[high+1] = A[0];           //插入操作
  }
}
```

从上述算法中，不难看出折半插入排序仅减少了比较元素次数，约为 $O(n\log_2n)$，该比较次数与待排序表的初始状态无关，仅取决于表中的元素个数 n；而元素的移动次数并未改变，它依赖于待排序表初始状态。因此，折半插入排序时间复杂度仍为 $O(n^2)$，但对于数据量不很大的排序表，折半插入排序往往能表现出很好的性能折半插入排序是一种稳定的排序方法。

#### 8.2.3 希尔排序

从前面的分析可知，直接插入排序算法的时间复杂度为 $O(n^2)$，但若待排序列为 “正序” 时，其时间复杂度可提高至 $O(n)$，由此可见它更适用于基本有序的排序表和数据量不大排序表。希尔排序正是基于这两点分析对直接插入排序进行改进而得来的，又称缩小增量排序。

希尔排序基本思想是：先将待排序表分割成若干形如 $L[i,i+d,i+2d,\cdots,i+kd]$ 的 “特殊” 子表，即把相隔某个 “增量” 顶点记录组成一个子表，对各个子表分别进行**直接插入排序**当整个表中元素已呈 “基本有序” 时，再对全体记录进行一次直接插入排序。

希尔排序的过程如下：先取一个小于 n 的步长 $d_1$，把表中的全部记录分成 $d_1$ 组，所有距离为 $d_1$ 的倍数记录放在同一组，在各组内进行直接插入排序；然后取第二个步长 $d_2\lt d_1$，重复上述过程直到所取到的 $d_t=1$，即所有记录已放在同一组中，再进行直接插入排序，由于此时已经具有较好的局部有序性，故可以很快得到最终结果。到目前为止尚未求得一个最好增量序列，希尔提出的方法是 $d_1=n/2$，$d_{i+1}=\lfloor d_i/2\rfloor$，并且最后一个增量等于 1。仍以 8.2.1 节的关键字为例，第一趟取增量 $d_1=5$，将该序列分成 5 个子序列，即图中第 2 行至第 6 行，分别对各子序列进行直接插入排序，结果如第 7 行所示；第二趟取增量 $d_2=3$，分别对 3 个子序列进行直接插入排序，结果如第 11 行所示；最后对整个序列进行一趟直接插入排序，整个排序过程如图 8.2 所示。

![希尔排序示例](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/93.png)

<center><font size="2">图8.2 希尔排序示例</font></center>

希尔排序算法的代码如下：

```c
void ShellSort(ElemType A[], int n){
//A[0]只是暂存单元，不是哨兵，当j<=0时，插入位置已到
  for(dk=n/2; dk>=1; dk=dk/2)               //步长变化
    for(i=dk+1; i<=n; ++i)
      if(A[i] < A[i-dk]){                   //需将A[i]插入有序增量子表
        A[0] = A[i];                        //暂存在A[0]
        for(j=i-dk; j>0&&A[0]<A[j]; j-=dk)
          A[j+dk] = A[j];                   //记录后移，查找插入的位置
        A[j+dk] = A[0];                     //插入
      }//if
}
```

希尔排序算法的性能分析如下：

空间效率：仅使用了常数个辅助单元，因而空间复杂度为 $O(1)$。

时间效率：由于希尔排序的时间复杂度依赖于增量序列的函数，这涉及数学上尚未解决的难题，所以其时间复杂度分析比较困难。当 n 在某个特定范围时，希尔排序的时间复杂度约为 $O(n^{1.3})$。在最坏情况下希尔排序的时间复杂度为 $O(n^2)$。

稳定性：当相同关键字的记录被划分到不同的子表时，可能会改变它们之间的相对次序，因此希尔排序是一种不稳定排序方法。例如，图 8.2 中 49 与 $\overline{49}$ 的相对次序发生了变化。

适用性：希尔排序算法仅适用于线性表为顺序存储的情况。

### 8.3 交换排序

所谓交换是指根据序列中两个元素关键字比较结果来对换这两个记录在序列中位置。基于交换的排序算法很多，本书主要介绍冒泡排序和快速排序，其中冒泡排序算法比较简单，一般不会单独考查，通常会重点考查快速排序算法的相关内容。

#### 8.3.1 冒泡排序

冒泡排序基本思想是：从后往前（或从前往后）两两比较相邻元素的值，若为逆序（即 $A[i-1]\gt A[i]$），则交换它们，直到序列比较完。我们称它为第一趟冒泡，结果是将最小的元素交换到待排序列的第一个位置（或将最大的元素交换到待排序列的最后一个位置），关键字最小的元素如气泡一般逐渐往上 “漂浮” 直至 “水面”（或关键字最大元素如石头一般下沉至水底）。下一趟冒泡时，前一趟确定的最小元素不再参与比较，每趟冒泡结果是把序列中的最小元素（或最大元素）放到了序列最终位置……这样最多做 n-1 趟冒泡就能把所有元素排好序。

图 8.3 所示为冒泡排序过程，第一趟冒泡时：$27\lt\overline{49}$，不交换；$13\lt27$，不交换；$76\gt13$，交换；$97\gt13$，交换；$65\gt13$，交换；$38\gt13$，交换；$49\gt13$，交换。通过第一趟冒泡后最小元素已交换到第一个位置，也是它的最终位置。第二趟冒泡时对剩余子序列采用同样方法进行排序，以此类推，到第五趟结束后没有发生交换，说明表已有序，冒泡排序结束。

![冒泡排序示例](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/94.png)

<center><font size="2">图8.3 冒泡排序示例</font></center>

冒泡排序算法的代码如下：

```c
void BubbleSort(ELemType A[], int n){
  for(i=0; i<n-1; i++){
    flag = false;           //表示本趟冒泡是否发生交换的标志
    for(j=n-1; j>i; j--)    //一趟冒泡过程
      if(A[j-1] > A[j]){    //若为逆序
        swap(A[j-1], A[j]); //交换
        flag = true;
      }
      if(flag == false)     //本趟遍历后没有发生交换，说明表已经有序
       return
  }
}
```

冒泡排序的性能分析如下：

空间效率：仅使用了常数个辅助单元，因而空间复杂度为 $O(1)$。

时间效率：当初始序列有序时，显然第一趟冒泡后 flag 依然为 false（本趟冒泡没有元素交换），从而直接跳出循环，比较次数为 n-1，移动次数为 0，从而最好情况下的时间复杂度为 $O(n)$；当初始序列为逆序时，需要进行 n-1 趟排序，第 i 趟排序要进行 n-i 次关键字的比较，而且每次比较后都必须移动元素 3 次来交换元素位置。这种情况下，

$$
比较次数=\sum\limits_{i=1}^{n-1}(n-i)=\frac{n(n-1)}2,移动次数=\sum\limits_{i=1}^{n-1}3(n-i)=\frac{3n(n-1)}2
$$

从而，最坏情况下的时间复杂度为 $O(n^2)$，其平均时间复杂度也为 $O(n^2)$。

稳定性：由于 $i\gt j$ 且 $A[i]=A[j]$ 时，不会发生交换，因此冒泡排序是一种稳定的排序方法。

**注意**：冒泡排序中所产生的有序子序列一定是全局有序的（不同于直接插入排序），也就是说，有序子序列中的所有元素的关键字一定小于或大于无序子序列中所有元素关键字，这样每趟排序都会将一个元素放置到其最终的位置上。

#### 8.3.2 快速排序

快速排序的基本思想是基于分治法的：在待排序表 $L[1\dots n]$ 中任取一个元素 pivot 作为枢轴（或基准，通常取首元素），通过一趟排序将待排序表划分为独立的两部分 $L[1\dots k-1]$ 和 $L[k+1\dots n]$，使得 $L[1\dots k-1]$ 中所有元素小于 pivot，$L[k+1\dots n]$ 中的所有元素大于等于 pivot，则 pivot 放在了其最终位置 $L(k)$ 上，这个过程称为一趟快速排序（或一次划分）。然后分别递归地对两个子表重复上述过程，直至每部分内只有一个元素或空为止，即所有元素放在了其最终位置上。

一趟快速排序的过程是一个交替搜索和交换的过程下面通过实例来介绍，附设两个指针 i 和 j，初值分别为 low 和 high，取第一个元素 49 为枢轴赋值到变量 pivot。

指针 j 从 high 往前搜索找到第一个小于枢轴的元素 27，将 27 交换到 i 所指位置。

![快速排序](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/95.png)

指针 i 从 low 往后搜索找到第一个大于枢轴元素 65，将 65 交换到 j 所指位置。

![快速排序](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/96.png)

指针 j 继续往前搜索找到小于枢轴元素 13，将 13 交换到 i 所指位置。

![快速排序](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/97.png)

指针 i 继续往后搜索找到大于枢轴的元素 97，将 97 交换到 j 所指位置。

![快速排序](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/98.png)

指针 j 继续往前搜索小于枢轴的元素，直至 i ==j。

![快速排序](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/99.png)

此时，指针 i（== j）之前的元素均小于 49，指针 i 之后元素均大于等于 49，将 49 放在 i 所指位置即其最终位置，经过一趟划分，将原序列分割成了前后两个子序列。

$$
\lbrace27\quad38\quad13\rbrace\quad49\quad\lbrace76\quad97\quad65\quad\overline{49}\rbrace
$$

按照同样的方法对各子序列进行快速排序，若待排序列中只有一个元素，显然已有序。

$$
&\lbrace13\rbrace\quad & 27\quad&\lbrace38\rbrace\quad &\quad&\lbrace\overline{49}\quad &65\rbrace\quad &76\quad&\lbrace 97\rbrace\\
&结束 & &结束 & &\overline{49}\quad &\lbrace65\rbrace & &结束\\
&&&&&&结束&& \\
&\lbrace13&27&38&49&\overline{49}&65&76&97\rbrace \\
$$

对算法最好理解方式是手动地模拟一遍这些算法。

假设划分算法已知，记为 Partition()，返回的是上述的 k，注意到 $L(k)$ 已在最终的位置，因此可以先对表进行划分，而后对两个表调用同样的排序操作。因此可以递归地调用快速排序算法进行排序，具体的程序结构如下：

```c
void QUickSort(ElemType A[], int low, int high){
  if(low < high){                           //递归跳出的条件
    //partition()就是划分操作，将表A[low…high]划分为满足上述条件的两个子表
    int pivotpos = Partition(A, low, high); //划分
    QuickSort(A, low, pivotpos-1);          //依次对两个子表进行递归排序
    QuickSort(A, pivotpos+1, high);
  }
}
```

从上面的代码不难看出快速排序算法的关键在于划分操作，同时快速排序算法的性能也主要取决于划分操作的好坏。从快速排序算法提出至今，已有许多不同的划分操作版本，但考研所考查的快速排序的划分操作基本以严蔚敏的教材《数据结构》为主。假设每次总以当前表中第一个元素作为枢轴来对表进行划分，则将表中比枢轴大的元素向右移动，将比枢轴小的元素向左移动，使得一趟 partition() 操作后，表中的元素被枢轴值一分为二。代码如下：

```c
int Partition(ElemType A[], int low, int high){//一趟划分
  ElemType pivot = A[low];    //将当前表中第一个元素设为枢轴，对表进行划分
  while(low < high){          //循环跳出条件
    while(low<high && A[high]>=pivot) --high;
    A[low] = A[high];         //将比枢轴小的元素移动到左端
    while(low<high && A[low]<=pivot) ++low;
    A[high] = A[low];         //将比枢轴大的元素移动到右端
  }
  A[low] = pivot;             //枢轴元素存放到最终位置
  return low;                 //返回存放枢轴的最终位置
}
```

快速排序算法的性能分析如下：

空间效率：快速排序是递归的，需要借助一个递归工作栈来保存每层递归调用的必要信息，其容量应与递归调用的最大深度一致。最好情况下为 $O(\log_2n)$；最坏情况下，因为要进行 n-1 次递归调用，所以栈的深度为 $O(n)$；平均情况下，栈的深度为 $O(\log_2n)$。

时间效率：快速排序的运行时间与划分是否对称有关，快速排序最坏情况发生在两个区域分别包含 n-1 个元素和 0 个元素时，这种最大限度的不对称性若发生在每层递归上，即对应于初始排序表基本有序或基本逆序时，就得到最坏情况下的时间复杂度为 $O(n^2)$。

有很多方法可以提高算法的效率：一种方法是尽量选取一个可以将数据中分的枢轴元素，如从序列的头尾及中间选取三个元素，再取这三个元素的中间值作为最终的枢轴元素；或者随机地从当前表中选取枢轴元素，这样做可使得最坏情况在实际排序中几乎不会发生。

在最理想的状态下，即 Partition() 可能做到最平衡的划分得到两个子问题的大小都不可能大于 n/2，在这种情况下，快速排序的运行速度将大大提升，此时，时间复杂度为 $O(n\log_2n)$。好在快速排序平均情况下的运行时间与其最佳情况下的运行时间很接近，而不是接近其最坏情况下的运行时间。**快速排序是所有内部排序算法中平均性能最优的排序算法**。

稳定性：在划分算法中若右端区间有两个关键字相同，且均小于基准值记录，则在交换到左端区间后，它们的相对位置会发生变化即快速排序是一种不稳定的排序方法。例如，表 $L=\lbrace3,\bar2,2\rbrace$，经过一趟排序后 $L=\lbrace2,\bar2,3\rbrace$，最终排序系列也是 $L=\lbrace2,\bar2,3\rbrace$，显然 2 与 $\bar2$ 的相对次序已发生了变化。

**注意**：在快速排序算法中，并不产生有序子序列但每趟排序后会将枢轴（基准）元素放到其最终的位置上。

### 8.4 选择排序

选择排序的基本思想是：每一趟（如第 i 趟）在后面 $n-i+1(i=1,2,\cdots,n-1)$ 个待排序元素中选取关键字最小元素，作为有序子序列第 i 个元素，直到第 n-1 趟做完，待排序元素只剩下 1 个，就不用再选了。选择排序中的堆排序算法是历年考查的重点。

#### 8.4.1 简单选择排序

根据上面的选择排序的思想，可以很直观地得出简单选择排序算法思想：假设排序表为 $L[1\dots n]$，第 i 趟排序即从 $L[i\dots n]$ 中选择关键字最小的元素与 $L(i)$ 交换，每一趟排序可以确定一个元素最终位置，这样经过 n-1 趟排序就可使得整个排序表有序。

简单选择排序算法的代码如下：

```c
void SelectSort(ElemType A[], int n){
  for(i=0; i<n-1; i++){              //一共进行n-1趟
    min = i;                         //记录最小元素位置
    for(j=i+1; j<n; j++)             //在A[i...n-1]中选择最小的元素
      if(A[j] < A[min]) min = j;     //更新最小元素位置
    if(min != i) swap(A[i], A[min]); //封装的swap()函数共移动元素3次
  }
}
```

简单选择排序算法的性能分析如下：

空间效率：仅使用常数个辅助单元，故空间效率为 $O(1)$。

时间效率：从上述伪码中不难看出，在简单选择排序过程中，元素移动的操作次数很少，不会超过 $3(n-1)$ 次，最好情况是移动 0 次，此时对应的表已经有序；但元素间比较次数与序列初始状态无关，始终是 $n(n-1)/2$ 次，因此时间复杂度始终是 $O(n^2)$。

稳定性：在第 i 趟找到最小元素后，和第 i 个元素交换可能会导第 i 个元素与其含有相同关键字元素的相对位置发生改变。例如，表 $L=\lbrace2,\bar2,1\rbrace$，经过一趟排序后 $L=\lbrace1,\bar2,2\rbrace$，最终排序序列也是 $L=\lbrace1,\bar2,2\rbrace$，显然，2 与 $\bar2$ 的相对次序已发生变化。因此，简单选择排序是一种不稳定排序方法。

#### 8.4.2 堆排序

堆的定义如下，n 个关键字序列 $L=[1\dots n]$ 称为堆，当且仅当该序列满足：

① $L(i)\geq L(2i)$ 且 $L(i)\geq L(2i+1)$ 或

② $L(i)\leq L(2i)$ 且 $L(i)\leq L(2i+1)$（$1\leq i\leq\lfloor n/2\rfloor$）

可以将该一维数组视为一棵完全二叉树，满足条件 ① 的堆称为大根堆（大顶堆），大根堆的最大元素存放在根结点且其任一非根结点的值小于等于其双亲结点值。满足条件 ② 的堆称为小根堆（小顶堆），小根堆的定义刚好相反，根结点是最小元素。图 8.4 所示为一个大根堆。

![一个大根堆示意图](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/100.png)

<center><font size="2">图8.4 一个大根堆示意图</font></center>

堆排序的思路很简单：首先将存放在 $L[1\dots n]$ 中的 n 个元素建成初始堆，由于堆本身的特点（以大顶堆为例），堆顶元素就是最大值。输出堆顶元素后，通常将堆底元素送入堆顶，此时根结点已不满足大顶堆的性质，堆被破坏，将堆顶元素向下调整使其继续保持大顶堆的性质，再输出堆顶元素。如此重复，直到堆中仅剩一个元素为止。可见堆排序需要解决两个问题：① 如何将无序序列构造成初始堆？② 输出堆顶元素后，如何将剩余元素调整成新的堆？

堆排序的关键是构造初始堆。n 个结点的完全二叉树，最后一个结点是第 $\lfloor n/2\rfloor$ 个结点的孩子。对第 $\lfloor n/2\rfloor$ 个结点为根的子树筛选（对于大根堆，若根结点的关键字小于左右孩子中关键字较大者，则交换），使该子树成为堆。之后向前依次对各结点（$\lfloor n/2\rfloor-1$ ~ $1$）为根的子树进行筛选，看该结点值是否大于其左右子结点的值，若不大于，则将左右子结点中的较大值与之交换，交换后可能会破坏下一级的堆，于是继续采用上述方法构造下一级堆，直到以该结点为根的子树构成堆为止反复利用上述调整堆的方法建堆，直到根结点。

如图 8.5 所示，初始时调整 $L(4)$ 子树，09 < 32，交换，交换后满足堆的定义；向前继续调整 $L(3)$ 子树，78 < 左右孩子的较大者 87，交换，交换后满足堆的定义；向前调整 $L(2)$ 子树，17 < 左右孩子的较大者 45，交换后满足堆的定义；向前调整至根结点 $L(1)$，53 < 左右孩子的较大者 87，交换，交换后破坏了 $L(3)$ 子树堆，采用上述方法对 $L(3)$ 进行调整，53 < 左右孩子的较大者 78，交换至此该完全二叉树满足堆的定义。

![自下往上逐步调整为大根堆](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/101.png)

<center><font size="2">图8.5 自下往上逐步调整为大根堆</font></center>

输出堆顶元素后，将堆的最后一个元素与堆顶元素交换此时堆的性质被破坏，需要向下进行筛选。将 09 和左右孩子的较大者 78 交换，交换后破坏了 $L(3)$ 子树堆，继续对 $L(3)$ 子树向下筛选，将 09 和左右孩子的较大者 65 交换，交换后得到了新堆，调整过程如图 8.6 所示。

![输出堆顶元素后再将剩余元素调整成新堆](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/102.png)

<center><font size="2">图8.6 输出堆顶元素后再将剩余元素调整成新堆</font></center>

下面是建立大根堆算法：

```c
void BuildMaxHeap(ElemType A[], int len){
  for(int i = len/2; i>0; i--)    //从i=[n/2]~1，反复调整堆
    HeadAdjust(A, i, len);
}
void HeadAdjust(ElemType A[], int k, int len){
//函数HeadAdjust将元素k为根的子树进行调整
  A[0] = A[k];                //A[0]暂存子树的根结点
  for(i=2*k; i<=len; i*=2){   //沿key较大的子结点向下筛选
    if(i<len && A[i]<A[i+1])
      i++;                    //取key较大的子结点的下标
    if(A[0] >= A[i]) break;   //筛选结束
    else{
      A[k] = A[i];            //将A[i]调整到双亲结点上
      k = i;                  //修改k值，以便继续向下筛选
    }
  }
  A[k] = A[0];                //被筛选结点的值放入最终位置
}
```

调整的时间与树高有关，为 $O(h)$。在建含 n 个元素的堆时，关键字的比较总次数不超过 4n，时间复杂度为 $O(n)$，这说明可以在线性时间内将一个无序数组建成一个堆。

下面是堆排序算法：

```c
void HeapSort(ELemType A[], int len){
  BuildMaxHeap(A, len);      //初始建堆
  for(i=len; i>1; i--){      //n-1趟的交换和建堆过程
    Swap(A[i], A[1]);        //输出堆顶元素（和堆底元素交换）
    HeadAdjust(A, 1, i-1);   //调整，把剩余的i-1个元素整理成堆
  }
}
```

同时，堆也支持插入操作。对堆进行插入操作时，先将新结点放在堆的末端，再对这个新结点向上执行调整操作。大根堆的插入操作示例如图 8.7 所示。

![大根堆的插入操作示例](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/103.png)

<center><font size="2">图8.7 大根堆的插入操作示例</font></center>

堆排序适合关键字较多的情况。例如，在 1 亿个数中选出前 100 个最大值？首先使用一个大小为 100 的数组，读入前 100 个数，建立小顶堆，而后依次读入余下的数，若小于堆顶则舍弃，否则用该数取代堆顶并重新调整堆，待数据读取完毕，堆中 100 个数即为所求。

堆排序算法的性能分析如下：

空间效率：仅使用了常数个辅助单元，所以空间复杂度为 $O(1)$。

时间效率：建堆时间为 $O(n)$，之后有 n-1 次向下调整操作，每次调整的时间复杂度为 $O(h)$，故在最好、最坏和平均情况下，堆排序时间复杂度为 $O(n\log_2n)$。

稳定性：进行筛选时，有可能把后面相同关键字的元素调整到前面，所以堆排序算法是一种不稳定排序方法。例如，表 $L=\lbrace1,\bar2,2\rbrace$，构造初始堆时可能将 $\bar2$ 交换到堆顶，此时 $L=\lbrace\bar2,1,2\rbrace$，最终排序序列为 $L=\lbrace1,2,\bar2\rbrace$，显然，2 与 $\bar2$ 的相对次序已发生变化。

### 8.5 归并排序和基数排序

#### 8.5.1 归并排序

归并排序与上述基于交换、选择等排序的思想不一样，“归并“ 的含义是将两个或两个以上的有序表组合成一个新的有序表。假定待排序表含有 n 个记录，则可将其视为 n 个有序子表，每个子表长度为 1，然后两两归并，得到 $\lceil n/2\rceil$ 个长度为 2 或 1 的有序表；继续两两归并……如此重复，直到合并为一个长度为 n 的有序表为止，这种排序方法称为 2 路归并排序。

图 8.8 所示为 2 路归并排序的一个例子，经过三趟归并后合并成了有序序列。

![2路归并排序示例](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/104.png)

<center><font size="2">图8.8 2路归并排序示例</font></center>

Merge() 的功能是将前后相邻的两个有序表归并为一个有序表。设两段有序表 $A[low\dots mid]$、$A[mid+1\dots high]$ 存放在同一顺序表中的相邻位置，先将它们复制到辅助数组 B 中。每次从对应 B 中的两个段取出一个记录进行关键字比较，将较小者放入 A 中，当数组 B 中有一段的下标超出其对应表长（即该段的所有元素都已复制到 A 中）时，将另一段中的剩余部分直接复制到 A 中。算法如下：

```c
ElemType *B = (ElemType *)malloc((n+1)*sizeof(ElemType));//辅助数组B
void Merge(ElemType A[], int low, int mid, int high){
//表A的两段A[low...high]和A[mid+1...high]各自有序，将它们合并成一个有序表
  for(int k = low; k<high; k++)
    B[k] = A[k];                    //将A中所有元素复制到B中
  for(i=low, j=mid+1,k=i; i<=mid&&j<=high;k++){
    if(B[i] <= B[j])                //比较B的左右两段中的元素
      A[k] = B[i++];                //将较小值复制到A中
    else
      A[k] = B[j++];
  }//for
  while(i <= mid) A[k++] = B[i++];  //若第一个表未检测完，复制
  while(j <= high) A[k++] = B[j++]; //若第二个表未检测完，复制
}
```

**注意**：上面的代码中，最后两个 while 循环只有一个会执行。

一趟归并排序的操作是，调用 $\lceil n/2h\rceil$ 次算法 merge()，将 $L[1\dots n]$ 中前后相邻且长度为 h 的有序段进行两两归并，得到前后相邻、长度为 2h 的有序段，整个归并排序需要进行 $\lceil\log_2n\rceil$ 趟。

递归形式的 2 路归并排序算法是基于分治的，其过程如下。

分解：将含有 n 个元素待排序分成各含 n/2 个元素的子表，采用 2 路归并排序算法对两个子表递归地进行排序。

合并：合并两个已排序子表得到排序结果。

```c++
void MergeSort(ElemType A[], int low, int high){
  if(low < high){
    int mid = (low+high)/2;       //从中间划分两个子序列
    MergeSort(A, low, mid);       //对左侧子序列进行递归排序
    MergeSort(A, mid+1, high);    //对右侧子序列进行递归排序
    Merge(A, low, mid, high);     //归并
  }
}
```

2 路归并排序算法的性能分析如下：

空间效率：Merge() 操作中，辅助空间刚好为 n 个单元，所以算法的空间复杂度为 $O(n)$。

时间效率：每趟归并的时间复杂度为 $O(n)$，共需进行 $\lceil\log_2n\rceil$ 趟归并，所以算法的时间复杂度为 $O(n\log_2n)$。

稳定性：由于 Merge() 操作不会改变相同关键字记录的相对次序，所以 2 路归并排序算法是一种稳定的排序方法。

**注意**：一般而言，对于 N 个元素进行 k 路归并排序时，排序的趟数 m 满足 $k^m=N$，从而 $m=\log_kN$，又考虑到 m 为整数，所以 $m=\lceil\log_kN\rceil$。这和前面的 2 路归并是一致的。

#### 8.5.2 基数排序

基数排序是一种很特别的排序方法，它不基于比较和移动进行排序，而基于关键字各位的大小进行排序。基数排序是一种借助多关键字排序的思想对单逻辑关键字进行排序方法。

假设长度为 n 的线性表中每个结点 $a_j$ 关键字由 d 元组（$k_j^{d-1},k_j^{d-2},\cdots,k_j^1,k_j^0$）组成，满足 $0\leq k_j^i\leq r-1(0\leq j\lt n,0\leq i\leq d-1)$。其中 $k_j^{d-1}$ 为最主位关键字，$k_j^0$ 为最次位关键字。

为实现多关键字排序通常有两种方法：第一种是**最高位优先（MSD）**法，按关键字位权重递减依次逐层划分成若干更小的子序列，最后将所有子序列依次连接成一个有序序列。第二种是**最低位优先（LSD）**法，按关键字权重递增依次进行排序，最后形成一个有序序列。

下面描述以 r 为基数的最低位优先基数排序过程，在排序过程中，使用 r 个队列 $Q_0,Q_1,\cdots,Q_{r-1}$。基数排序的过程如下：

对 $i=0,1,\cdots,d-1$，依次做一次 “分配” 和 “收集”（其实是一次稳定的排序过程）。

分配：开始时把 $Q_0,Q_1,\cdots,Q_{r-1}$ 各个队列置成空队列，然后依次考察线性表中的每个结点 $a_j(j=0,1,\cdots,n-1)$，若 $a_j$ 的关键字 $k_j^i=k$，就把 $a_j$ 放进 $Q_k$ 队列中。

收集：把 $Q_0,Q_1,\cdots,Q_{r-1}$ 各个队列中的结点依次首尾相接，得到新的结点序列从而组成新的线性表。

通常采用链式基数排序，假设对如下 10 个记录进行排序：

![链式基数排序](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/105.png)

每个关键字是 1000 以下的正整数，基数 r = 10，在排序过程中需要借助 10 个链队列，每个关键字由 3 位子关键字构成 $K^1K^2K^3$，分别代表百位、十位和个位，一共需要进行三趟 “分配” 和 “收集” 操作。第一趟分配用最低位子关键字 $K^3$ 进行将所有最低位子关键字（个位）相等的记录分配到同一个队列，如图 8.9(a) 所示，然后进行收集操作，第一趟收集后的结果如图 8.9(b) 所示。

![第一趟链式基数排序操作](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/106.png)

<center><font size="2">图8.9 第一趟链式基数排序操作</font></center>

第二趟分配用次低位子关键字 $K^2$ 进行，将所有次低位子关键字（十位）相等的记录分配到同一个队列，如图 8.10(a) 所示，第二趟收集后的结果如图 8.10(b) 所示。

![第二趟链式基数排序操作](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/107.png)

<center><font size="2">图8.10 第二趟链式基数排序操作</font></center>

第三趟分配用最高位子关键字 $K^1$ 进行，将所有最高位子关键字（百位）相等的记录分配到同一个队列，如图 8.11(a) 所示，第三趟收集后的结果如图 8.11(b) 所示，至此整个排序结束。

![第三趟链式基数排序操作](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/108.png)

<center><font size="2">图8.11 第三趟链式基数排序操作</font></center>

基数排序算法的性能分析如下。

空间效率：一趟排序需要的辅助存储空间为 r（r 个队列：r 个队头指针和 r 个队尾指针），但以后的排序中会重复使用这些队列，所以基数排序的空间复杂度为 $O(r)$。

时间效率：基数排序需要进行 d 趟分配和收集，一趟分配需要 $O(n)$，一趟收集需要 $O(r)$，所以基数排序的时间复杂度为 $O(d(n+r))$，它与序列的初始状态无关。

稳定性：对于基数排序算法而言，很重要一点就是按位排序时必须是稳定的。因此，这也保证了基数排序稳定性。

### 8.6 各种内部排序算法的比较及应用

#### 8.6.1 内部排序算法比较

前面讨论的排序算法很多，对各算法的比较是考研中必考的内容。一般基于三个因素进度对比：时空复杂度、算法的稳定性、算法的过程特征。

从**时间复杂度**看：简单选择排序、直接插入排序和冒泡排序平均情况下的时间复杂度都为 $O(n^2)$，且实现过程也较简单，但直接插入排序和冒泡排序最好情况下的时间复杂度可以达到 $O(n)$，而简单选择排序则与序列初始状态无关。希尔排序作为插入排序的拓展，对较大规模的排序都可以达到很高的效率，但目前未得出其精确渐近时间。堆排序利用了一种称为堆数据结构，可在线性时间内完成建堆，且在 $O(n\log_2n)$ 内完成排序过程。快速排序基于分治的思想，虽然最坏情况下快速排序时间会达到 $O(n^2)$，但快速排序平均性能可以达到 $O(n\log_2n)$，在实际应用中常常优于其他排序算法。归并排序同样基于分治的思想，但由于其分割子序列与初始序列的排列无关，因此它的最好、最坏和平均时间复杂度均为 $O(n\log_2n)$。

从**空间复杂度**看：简单选择排序、插入排序、冒泡排序、希尔排序和堆排序都仅需要借助常数个辅助空间。快速排序在空间上只使用一个小的辅助栈，用于实现递归，平均情况下大小为 $O(\log_2n)$，当然在最坏情况下可能会增长到 $O(n)$。 2 路归并排序在合并操作中需要借助较多的辅助空间用于元素复制，大小为 $O(n)$，虽然有方法能克服这个缺点，但其代价是算法会很复杂而且时间复杂度会增加。

从**稳定性**看：插入排序、冒泡排序、归并排序和基数排序是稳定的排序方法，而简单选择排序、快速排序、希尔排序和堆排序都是不稳定排序方法对于排序方法的稳定性，读者应能从算法本身的原理上去理解，而不应拘泥于死记硬背。

从**过程特征**看：采用不同排序算法，在一次循环或几次循环后排序结果可能是不同的，考研题中经常出现给出一个待排序的初始序列和已经部分排序的序列问其采用何种排序算法。这就要对各类排序算法的过程特征十分熟悉，如冒泡排序和堆排序在每趟处理后都能产生当前的最大值或最小值，而快速排序一趟处理就能确定一个元素的最终位置等。

表 8.1 列出了各种排序算法的时空复杂度和稳定性情况，其中空间复杂度仅列举了平均情况复杂度，由于希尔排序的时间复杂度依赖于增量函数，所以无法准确给出其时间复杂度。

<center><font size=2><b>表8.1 各种排序算法的性质</b></font></center>

<table style="text-align:center;">
  <tr>
    <td rowspan="2">算法的种类</td>
    <td colspan="3">时间复杂度</td>
    <td rowspan="2">空间复杂度</td>
  	<td rowspan="2">是否稳定</td>
  </tr>
  <tr>
    <td>最好情况</td>
    <td>平均情况</td>
    <td>最坏情况</td>
  </tr>
  <tr>
    <td>直接插入排序</td>
    <td>O(n)</td>
    <td>O(n<sup>2</sup>)</td>
    <td>O(n<sup>2</sup>)</td>
    <td>O(1)</td>
    <td>是</td>
  </tr>
  <tr>
    <td>冒泡排序</td>
    <td>O(n)</td>
    <td>O(n<sup>2</sup>)</td>
    <td>O(n<sup>2</sup>)</td>
    <td>O(1)</td>
    <td>是</td>
  </tr>
  <tr>
    <td>简单选择排序</td>
    <td>O(n<sup>2</sup>)</td>
    <td>O(n<sup>2</sup>)</td>
    <td>O(n<sup>2</sup>)</td>
    <td>O(1)</td>
    <td>否</td>
  </tr>
  <tr>
    <td>希尔排序</td>
    <td colspan="3"></td>
    <td>O(1)</td>
    <td>否</td>
  </tr>
  <tr>
    <td>快速排序</td>
    <td>O(nlog<sub>2</sub>n)</td>
    <td>O(nlog<sub>2</sub>n)</td>
    <td>O(n<sup>2</sup>)</td>
    <td>O(log<sub>2</sub>n)</td>
    <td>否</td>
  </tr>
  <tr>
    <td>堆排序</td>
    <td>O(nlog<sub>2</sub>n)</td>
    <td>O(nlog<sub>2</sub>n)</td>
    <td>O(nlog<sub>2</sub>n)</td>
    <td>O(1)</td>
    <td>否</td>
  </tr>
  <tr>
    <td>2 路归并排序</td>
    <td>O(nlog<sub>2</sub>n)</td>
    <td>O(nlog<sub>2</sub>n)</td>
    <td>O(nlog<sub>2</sub>n)</td>
    <td>O(n)</td>
    <td>是</td>
  </tr>
  <tr>
    <td>基数排序</td>
    <td>O(d(n+r))</td>
    <td>O(d(n+r))</td>
    <td>O(d(n+r))</td>
    <td>O(r)</td>
    <td>是</td>
  </tr>
</table>

#### 8.6.2 内部排序算法的应用

通常情况下，对排序算法的比较和应用考虑以下情况。

1）选取排序方法需要考虑的因素

① 待排序的元素数目 n。

② 元素本身信息量的大小。

③ 关键字的结构及其分布情况。

④ 稳定性的要求。

⑤ 语言工具的条件，存储结构及辅助空间的大小等。

2）排序算法小结

① 若 n 较小，可采用直接插入排序或简单选择排序。由于直接插入排序所需的记录移动次数较简单选择排序的多，因而当记录本身信息量较大时，用简单选择排序较好。

② 若文件的初始状态已按关键字基本有序，则选用直接插入或冒泡排序为宜。

③ 若 n 较大，则应采用时间复杂度为 $O(n\log_2n)$ 的排序方法：快速排序、堆排序或归并排序。快速排序被认为是目前基于比较的内部排序方法中最好的方法，当待排序的关键字随机分布时，快速排序的平均时间最短。堆排序所需的辅助空间少于快速排序，并且不会出现快速排序可能出现的最坏情况，这两种排序都是不稳定的。若要求排序稳定且时间复杂度为 $O(n\log_2n)$，则可选用归并排序。但本章介绍的从单个记录起进行两两归并的排序算法并不值得提倡，通常可以将它和直接插入排序结合在一起使用。先利用直接插入排序求得较长的有序子文件，然后两两归并。直接插入排序是稳定的，因此改进后的归并排序仍是稳定的。

④ 在基于比较的排序方法中，每次比较两个关键字的大小之后，仅出现两种可能的转移，因此可以用一棵二叉树来描述比较判定过程，由此可以证明：当文件的 n 个关键字随机分布时，任何借助于 “比较” 的排序算法，至少需要 $O(n\log_2n)$ 的时间。

⑤ 若 n 很大，记录的关键字位数较少且可以分解时，采用基数排序较好。

⑥ 当记录本身信息量较大时，为避免耗费大量时间移动记录，可用链表作为存储结构。

### 8.7 外部排序

外部排序可能会考查相关概念、方法和排序过程，外部排序的算法比较复杂，不会在算法设计上进行考查。本节的主要内容有：

① 外部排序指待排序文件较大，内存一次放不下，需存放在外存的文件的排序。

② 为减少平衡归并中外存读写次数所采取的方法：增大归并路数和减少归并段个数。

③ 利用败者树增大归并路数。

④ 利用置换-选择排序增大归并段长度来减少归并段个数。

⑤ 由长度不等的归并段，进行多路平衡归并，需要构造最佳归并树。

#### 8.7.1 外部排序的基本概念

前面介绍过的排序方法都是在内存中进行的（称为内部排序）。而在许多应用中，经常需要对大文件进行排序，因为文件中的记录很多、信息量庞大，无法将整个文件复制进内存中进行排序。因此，需要将待排序的记录存储在外存上，排序时再把数据一部分一部分地调入内存进行排序，在排序过程中需要多次进行内存和外存之间的交换。这种排序方法就称为外部排序。

#### 8.7.2 外部排序的方法

文件通常是按块存储在磁盘上的，操作系统也是按块对磁盘上的信息进行读写的。因为磁盘读/写的机械动作所需的时间远远超过内存运算的时间（相比而言可以忽略不计），因此在外部排序过程中的时间代价主要考虑访问磁盘的次数，即 I/O 次数。

外部排序通常采用归并排序法。它包括两个相对独立的阶段：① 根据内存缓冲区大小，将外存上的文件分成若干长度为 $\ell$ 的子文件，依次读入内存并利用内部排序方法对它们进行排序，并将排序后得到的有序子文件重新写回外存，称这些有序子文件为归并段或顺串； ② 对这些归并段进行逐趟归并，使归并段（有序子文件）逐渐由小到大，直至得到整个有序文件为止。

例如，一个含有 2000 个记录的文件，每个磁盘块可容纳 125 个记录，首先通过 8 次内部排序得到 8 个初始归并段 R1~R8，每个段都含 250 个记录。然后对该文件做如图 8.13 所示的两两归并，直至得到一个有序文件。

```mermaid
graph LR
A[输入缓冲区1] --> B[输出缓冲区]
C[输入缓冲区2] --> B
```

<center><font size=2>图 8.12 2路归并</font></center>

![2路平衡归并的排序过程](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/109.png)

<center><font size="2">图8.13 2路平衡归并的排序过程</font></center>

把内存工作区等分为 3 个缓冲区，如图 8.12 所示，其中的两个为输入缓冲区，一个为输出缓冲区。首先，从两个输入归并段 R1 和 R2 中分别读入一个块，放在输入缓冲区 1 和输入缓冲区 2 中。然后，在内存中进行 2 路归并，归并后的对象顺序存放在输出缓冲区中。若输出缓冲区中对象存满，则将其顺序写到输出归并段（R1'）中，再清空输出缓冲区，继续存放归并后的对象。若某个输入缓冲区中的对象取空，则从对应的输入归并段中再读取下一块，继续参加归并。如此继续，直到两个输入归并段中对象全部读入内存并都归并完成为止。当 R1 和 R2 归并完后，再归并 R3 和 R4、R5 和 R6、最后归并 R7 和 R8，这是一趟归并。再把上趟的结果 R1' 和 R2‘、R3’ 和 R4' 两两归并，这又是一趟归并。最后把 R1'' 和 R2'' 两个归并段归并结果得到最终的有序文件，一共进行了 3 趟归并。

在外部排序中实现两两归并时，由于不可能将两个有序段及归并结果段同时存放在内存中，因此需要不停地将数据读出写入磁盘，而这会耗费大量时间。一般情况下：

_外部排序的总时间 = 内部排序所需的时间 + 外存信息读写的时间 + 内部归并所需的时间_

显然，外存信息读写的时间远大于内部排序和内部归并的时间，因此应着力减少 I/O 次数。由于外存信息读/写是以 “磁盘块” 为单位的，可知每一趟归并需进行 16 次 “读” 和 16 次 “写”，3 趟归并加上内部排序时所需进行的读/写，使得总共需进行 32 × 3 + 32 = 128 次读写。

若改用 4 路归并排序，则只需 2 趟归并，外部排序时的总读、写次数便减至 32 × 2 + 32 =96。因此，增大归并路数，可减少归并趟数，进而减少总的磁盘 I/O 次数，如图 8.14 所示。

![4路平衡归并的排序过程](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/110.png)

<center><font size="2">图8.14 4路平衡归并的排序过程</font></center>

一般地，对 r 个初始归并段，做 k 路平衡归并，归并树可用严格 k 叉树（即只有度为 k 与度为 0 的结点的 k 叉树）来表示。第一趟可将 r 个初始归并段归并为 $\lceil r/k\rceil$ 个归并段，以后每趟归并将 m 个归并段归并成 $\lceil m/k\rceil$ 个归并段，直至最后形成一个大的归并段为止。树的高度 = $\lceil\log_kr\rceil$ = 归并趟数 $S$。可见，只要增大归并路数 k，或减少初始归并段个数 r，都能减少归并趟数 $S$，进而减少读写磁盘的次数，达到提高外部排序速度的目的。

#### 8.7.3 多路平衡归并与败者树

上节讨论过，增加归并路数 k 能减少归并趟数 $S$，进而减少 I/O 次数。然而增加归并路数 k 时，内部归并时间将增加。做内部归并时，在 k 个元素中选择关键字最小记录需要比较 k-1 次。每趟归并 n 个元素需要做 $(n-1)(k-1)$ 次比较，$S$ 趟归并总共需要的比较次数为

$$
S(n-1)(k-1)=\lceil\log_kr\rceil(n-1)(k-1)=\lceil\log_2r\rceil(n-1)(k-1)/\lceil\log_2k\rceil
$$

式中，$(k-1)/\lceil\log_2k\rceil$ 随 $k$ 增长而增长，因此内部归并时间亦随 $k$ 的增长而增长。这将抵消由于增大 $k$ 而减少外存访问次数所得到的效益因此，不能使用普通内部归并排序算法。

为了使内部归并不受 $k$ 的增大的影响，引入了败者树。败者树是树形选择排序的一种变体，可视为一棵完全二叉树。$k$ 个叶结点分别存放 $k$ 个归并段在归并过程中当前参加比较的记录，内部结点用来记忆左右子树中的 “失败者”，而让胜者往上继续进行比较，一直到根结点。若比较两个数，大的为失败者、小的为胜利者，则根结点指向的数为最小数。

如图 8.15(a) 所示，b3 与 b4 比较，b4 是败者，将段号 4 写入父结点 $ls[4]$。b1 与 b2 比较，b2 是败者，将段号 2 写入 $ls[3]$。b3 与 b4 的胜者 b3 与 b0 比较，b0 是败者，将段号 0 写入 $ls[2]$。最后两个胜者 b3 与 b1 比较，b1 是败者，将段号 1 写入 $ls[1]$。而将胜者 b3 的段号 3 写入 $ls[0]$。此时，根结点 $ls[0]$ 所指的段的关键字最小。b3 中的 6 输出后将下一关键字填入 b3，继续比较。

![实现5路归并的败者树](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/111.png)

<center><font size="2">图8.15 实现5路归并的败者树</font></center>

因为 $k$ 路归并的败者树深度为 $\lceil\log_2k\rceil$，因此 $k$ 个记录中选择最小关键字，最多需要 $\lceil\log_2k\rceil$ 次比较所以总的比较次数为

$$
S(n-1)\lceil\log_2k\rceil=\lceil\log_kr\rceil(n-1)\lceil\log_2k\rceil=(n-1)\lceil\log_2r\rceil
$$

可见，使用败者树后，内部归并的比较次数与 $k$ 无关了。因此，只要内存空间允许，增大归并路数 $k$ 将有效地减少归并树的高度，从而减少 I/O 次数，提高外部排序的速度。

值得说明的是，归并路数 $k$ 并不是越大越好。归并路数 $k$ 增大时相应地需要增加输入缓冲区的个数。若可供使用的内存空间不变，势必要减少每个输入缓冲区容量，使得内存、外存交换数据的次数增大。当 $k$ 值过大时，虽然归并趟数会减少，但读写外存的次数仍会增加。

#### 8.7.4 置换选择排序（生成初始归并段）

从 8.7.2 节的讨论可知，减少初始归并段个数 r 也可以减少归并趟数 $S$。若总的记录个数为 n，每个归并段的长度为 $\ell$，则归并段的个数 $r=\lceil n/\ell\rceil$。采用内部排序方法得到的各个初始归并段长度都相同（除最后一段外），它依赖于内部排序时可用内存工作区的大小。因此，必须探索新的方法，用来产生更长的初始归并段，这就是本节要介绍的置换-选择算法。

设初始待排文件为 FI，初始归并段输出文件为 FO，内存工作区为 WA，FO 和 WA 初始状态为空，WA 可容纳 $w$ 个记录。置换-选择算法的步骤如下：

1）从 FI 输入 $w$ 个记录到工作区 WA。

2）从 WA 中选出其中关键字取最小值记录，记为 MINIMAX 记录。

3）将 MINIMAX 记录输出到 FO 中去。

4）若 FI 不空，则从 FI 输入下一个记录到 WA 中。

5）从 WA 中所有关键字比 MINIMAX 记录的关键字大的记录中选出最小关键字记录，作为新的 MINIMAX 记录。

6）重复 3）~ 5），直至在 WA 中选不出新的 MINIMAX 记录为止，由此得到一个初始归并段，输出一个归并段结束标志到 FO 中去。

7）重复 2）~ 6），直至 WA 为空。由此得到全部初始归并段。

设待排文件 $FI=\lbrace17,21,05,44,10,12,56,32,29\rbrace$，WA 容量为 3。排序过程如表 8.2 所示。

<center><font size=2><b>表8.2 置换-选择排序过程示例</b></font></center>

|   输出文件 FO    | <span style="border:1px solid #000; font-weight:600;">工作区 WA</span> |        输入文件 FI         |
| :--------------: | :--------------------------------------------------------------------: | :------------------------: |
|        —         |                                   —                                    | 17,21,05,44,10,12,56,32,29 |
|        —         | 17 21 <span style="border:1px solid #000; font-weight:600;">05</span>  |     44,10,12,56,32,29      |
|        05        | <span style="border:1px solid #000; font-weight:600;">17</span> 21 44  |       10,12,56,32,29       |
|      05 17       | 10 <span style="border:1px solid #000; font-weight:600;">21</span> 44  |        12,56,32,29         |
|     05 17 21     |  10 12<span style="border:1px solid #000; font-weight:600;">44</span>  |          56,32,29          |
|   05 17 21 44    | 10 12 <span style="border:1px solid #000; font-weight:600;">56</span>  |           32,29            |
|  05 17 21 44 56  |                                10 12 32                                |             29             |
| 05 17 21 44 56 # | <span style="border:1px solid #000; font-weight:600;">10</span> 12 32  |             29             |
|        10        | 29 <span style="border:1px solid #000; font-weight:600;">12</span> 32  |             —              |
|      10 12       |   <span style="border:1px solid #000; font-weight:600;">29</span> 32   |             —              |
|     10 12 29     |    <span style="border:1px solid #000; font-weight:600;">32</span>     |             —              |
|   10 12 29 32    |                                   —                                    |             —              |
|  10 12 29 32 #   |                                   —                                    |             —              |

上述算法，在 WA 中选择 MINIMAX 记录的过程需利用败者树来实现。

#### 8.7.5 最佳归并树

文件经过置换选择排序后，得到的是长度不等的初始归并段。下面讨论如何组织长度不等的初始归并段的归并顺序，使得 I/O 次数最少？假设由置换选择得到 9 个初始归并段，其长度（记录数）依次为 9,30,12,18,3,17,2,6,24。现做 3 路平衡归并，其归并树如图 8.16 所示。

![3路平衡归并的归并树](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/112.png)

<center><font size="2">图8.16 3路平衡归并的归并树</font></center>

在图 8.16 中，各叶结点表示一个初始归并段，上面的权值表示该归并段的长度，叶结点到根的路径长度表示其参加归并的趟数，各非叶结点代表归并成的新归并段，根结点表示最终生成的归并段。树的带权路径长度 WPL 为归并过程中的总读记录数，故 I/O 次数 = 2 × WPL = 484。

显然，归并方案不同，所得归并树亦不同，树的带权路径长度（I/O 次数）亦不同。为了优化归并树的 WPL，可将第 4 章中哈夫曼树的思想推广到 m 叉树的情形，在归并树中，让记录数少的初始归并段最先归并，记录数多的初始归并段最晚归并，就可以建立总的 I/O 次数最少的最佳归并树。上述 9 个初始归并段可构成一棵如图 8.17 所示的归并树，按此树进行归并，仅需对外存进行 446 次读/写，这棵归并树便称为最佳归并树。

![3路平衡归并的最佳归并树](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/113.png)

<center><font size="2">图8.17 3路平衡归并的最佳归并树</font></center>

在图 8.17 中的哈夫曼树是一棵严格 3 叉树，即树中只有度为 3 或 0 的结点。若只有 8 个初始归并段，如上例中少了一个长度为 30 的归并段。若在设计归并方案时，缺额的归并段留在最后，即除最后一次做 2 路归并外，其他各次归并仍是 3 路归并，此归并方案的外存读/写次数为 386。显然，这不是最佳方案。

正确的做法是：若初始归并段不足以构成一棵严格 $k$ 叉树时，需添加长度为 0 的 “虚段”，按照哈夫曼树的原则，权为 0 的叶子应离树根最远。因此，最佳归并树应如图 8.18 所示。

![8个归并段的最佳归并树](https://raw.githubusercontent.com/LBJhui/image-host/master/images/note/%E8%80%83%E7%A0%94/408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/114.png)

<center><font size="2">图8.18 8个归并段的最佳归并树</font></center>

如何判定添加虚段的数目？

设度为 0 的结点有 $n_0(=n)$ 个，度为 $k$ 的结点有 $n_k$ 个，则对严格 $k$ 叉树有 $n_0=(k-1)n_k+1$，由此可得 $n_k=(n_0-1)/(k-1)$。

- 若 $(n_0-1)\%(k-1)=0$（%为取余运算），则说明这 $n_0$ 个叶结点（初始归并段）正好可以构造 $k$ 叉树归并树。此时，内结点有 $n_k$ 个。

- 若 $(n_0-1)\%(k-1)=u\neq0$，则说明对于这 $n_0$ 个叶结点，其中有 u 个多余，不能包含在 k 叉归并树中。为构造包含所有 $n_0$ 个初始归并段的 $k$ 叉归并树，应在原有 $n_k$ 个内结点的基础上再增加 1 个内结点。它在归并树中代替了一个叶结点的位置，被代替的叶结点加上刚才多出的 u 个叶结点，即再加上 k-u-1 个空归并段，就可以建立归并树。

以图 8.18 为例，用 8 个归并段构成 3 叉树，$(n_0-1)\%(k-1)=(8-1)\%(3-1)=1$，说明 7 个归并段刚好可以构成一棵严格 3 叉树（假设把以 5 为根的树视为一个叶子）。为此，将叶子 5 变成一个内结点，再添加 3- 1 - 1 = 1 个空归并段，就可以构成一棵严格 $k$ 叉树。
